{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb50b63c-f7bd-4232-a80c-7665f0839f2a",
   "metadata": {},
   "source": [
    "# CNN1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1177e-b53c-4e78-b71d-3d2c09aa784a",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda/envs/DynoMTGBM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda:0\n",
      "[Info] Starting parameter search with MSE_Loss...\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \r{'batch_size': 128, 'drop_ratio': 0.10686821642720742, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0008377730909737842, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rFold: 1/5\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.290 Val loss 17.325\n",
      "\r  0%|          | 0/60 [00:07<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.535 Val loss 8.811\n",
      "\r  0%|          | 0/60 [01:00<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 139 best_val_loss 8.454\n",
      "\r  0%|          | 0/60 [01:36<?, ?trial/s, best loss=?]\r                                                      \rFold: 2/5\n",
      "\r  0%|          | 0/60 [01:36<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.304 Val loss 16.602\n",
      "\r  0%|          | 0/60 [01:40<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.479 Val loss 8.289\n",
      "\r  0%|          | 0/60 [02:32<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 136 best_val_loss 8.148\n",
      "\r  0%|          | 0/60 [03:07<?, ?trial/s, best loss=?]\r                                                      \rFold: 3/5\n",
      "\r  0%|          | 0/60 [03:07<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.334 Val loss 16.491\n",
      "\r  0%|          | 0/60 [03:11<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.656 Val loss 8.558\n",
      "\r  0%|          | 0/60 [04:06<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 3.565 Val loss 8.479\n",
      "\r  0%|          | 0/60 [05:04<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 215 best_val_loss 8.178\n",
      "\r  0%|          | 0/60 [05:31<?, ?trial/s, best loss=?]\r                                                      \rFold: 4/5\n",
      "\r  0%|          | 0/60 [05:31<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.391 Val loss 16.430\n",
      "\r  0%|          | 0/60 [05:37<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.749 Val loss 8.877\n",
      "\r  0%|          | 0/60 [06:41<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 3.747 Val loss 8.577\n",
      "\r  0%|          | 0/60 [07:44<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 184 best_val_loss 8.416\n",
      "\r  0%|          | 0/60 [07:52<?, ?trial/s, best loss=?]\r                                                      \rFold: 5/5\n",
      "\r  0%|          | 0/60 [07:52<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.371 Val loss 17.102\n",
      "\r  0%|          | 0/60 [07:57<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 5.053 Val loss 8.843\n",
      "\r  0%|          | 0/60 [08:54<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 3.862 Val loss 8.275\n",
      "\r  0%|          | 0/60 [09:54<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 202 best_val_loss 8.171\n",
      "\r  0%|          | 0/60 [10:15<?, ?trial/s, best loss=?]\r                                                      \rval MSE loss mean: 8.27345\n",
      "\n",
      "\r  0%|          | 0/60 [10:15<?, ?trial/s, best loss=?]\r  2%|▏         | 1/60 [10:15<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \r{'batch_size': 256, 'drop_ratio': 0.32016842685844393, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0002874855729350046, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r  2%|▏         | 1/60 [10:15<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 1/5\n",
      "\r  2%|▏         | 1/60 [10:15<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.686 Val loss 17.723\n",
      "\r  2%|▏         | 1/60 [10:19<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 12.508 Val loss 13.210\n",
      "\r  2%|▏         | 1/60 [11:00<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 10.817 Val loss 12.185\n",
      "\r  2%|▏         | 1/60 [11:43<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 281 best_val_loss 11.835\n",
      "\r  2%|▏         | 1/60 [12:27<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 2/5\n",
      "\r  2%|▏         | 1/60 [12:27<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.906 Val loss 16.978\n",
      "\r  2%|▏         | 1/60 [12:30<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 12.333 Val loss 12.565\n",
      "\r  2%|▏         | 1/60 [12:53<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 10.568 Val loss 10.988\n",
      "\r  2%|▏         | 1/60 [13:29<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 278 best_val_loss 10.649\n",
      "\r  2%|▏         | 1/60 [14:08<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 3/5\n",
      "\r  2%|▏         | 1/60 [14:08<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.903 Val loss 16.782\n",
      "\r  2%|▏         | 1/60 [14:12<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 12.483 Val loss 13.774\n",
      "\r  2%|▏         | 1/60 [14:58<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 10.757 Val loss 11.723\n",
      "\r  2%|▏         | 1/60 [15:41<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEarly stopped at epoch 256 best_val_loss 11.496\n",
      "\r  2%|▏         | 1/60 [16:20<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 4/5\n",
      "\r  2%|▏         | 1/60 [16:20<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.922 Val loss 16.532\n",
      "\r  2%|▏         | 1/60 [16:26<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 12.312 Val loss 12.678\n",
      "\r  2%|▏         | 1/60 [17:13<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 10.663 Val loss 11.805\n",
      "\r  2%|▏         | 1/60 [17:56<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 294 best_val_loss 11.487\n",
      "\r  2%|▏         | 1/60 [18:40<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 5/5\n",
      "\r  2%|▏         | 1/60 [18:40<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.769 Val loss 17.021\n",
      "\r  2%|▏         | 1/60 [18:45<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 12.487 Val loss 13.081\n",
      "\r  2%|▏         | 1/60 [19:30<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 10.874 Val loss 12.129\n",
      "\r  2%|▏         | 1/60 [20:08<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 284 best_val_loss 11.664\n",
      "\r  2%|▏         | 1/60 [20:42<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r                                                                                   \rval MSE loss mean: 11.42619\n",
      "\n",
      "\r  2%|▏         | 1/60 [20:42<10:05:27, 615.72s/trial, best loss: 8.273451538085938]\r  3%|▎         | 2/60 [20:42<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \r{'batch_size': 256, 'drop_ratio': 0.2174443947532174, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0002170487771919524, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r  3%|▎         | 2/60 [20:42<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 1/5\n",
      "\r  3%|▎         | 2/60 [20:42<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.484 Val loss 17.590\n",
      "\r  3%|▎         | 2/60 [20:48<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 11.450 Val loss 12.741\n",
      "\r  3%|▎         | 2/60 [21:25<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 9.377 Val loss 11.305\n",
      "\r  3%|▎         | 2/60 [22:06<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 297 best_val_loss 10.909\n",
      "\r  3%|▎         | 2/60 [22:50<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 2/5\n",
      "\r  3%|▎         | 2/60 [22:50<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.763 Val loss 17.007\n",
      "\r  3%|▎         | 2/60 [22:54<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 11.719 Val loss 11.539\n",
      "\r  3%|▎         | 2/60 [23:42<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 9.747 Val loss 10.655\n",
      "\r  3%|▎         | 2/60 [24:12<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 285 best_val_loss 10.039\n",
      "\r  3%|▎         | 2/60 [24:52<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 3/5\n",
      "\r  3%|▎         | 2/60 [24:52<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.601 Val loss 16.799\n",
      "\r  3%|▎         | 2/60 [24:56<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 11.666 Val loss 12.181\n",
      "\r  3%|▎         | 2/60 [25:44<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 9.614 Val loss 10.994\n",
      "\r  3%|▎         | 2/60 [26:31<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 295 best_val_loss 10.753\n",
      "\r  3%|▎         | 2/60 [27:13<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 4/5\n",
      "\r  3%|▎         | 2/60 [27:13<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.699 Val loss 16.665\n",
      "\r  3%|▎         | 2/60 [27:16<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 10.897 Val loss 11.922\n",
      "\r  3%|▎         | 2/60 [27:46<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 8.837 Val loss 11.015\n",
      "\r  3%|▎         | 2/60 [28:15<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEarly stopped at epoch 204 best_val_loss 10.746\n",
      "\r  3%|▎         | 2/60 [28:28<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rFold: 5/5\n",
      "\r  3%|▎         | 2/60 [28:28<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 0 Train loss 17.614 Val loss 17.175\n",
      "\r  3%|▎         | 2/60 [28:36<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 100 Train loss 11.581 Val loss 12.209\n",
      "\r  3%|▎         | 2/60 [29:19<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rEpoch 200 Train loss 9.850 Val loss 11.591\n",
      "\r  3%|▎         | 2/60 [30:08<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rStopped at epoch 271 best_val_loss 11.040\n",
      "\r  3%|▎         | 2/60 [30:32<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r                                                                                   \rval MSE loss mean: 10.69726\n",
      "\n",
      "\r  3%|▎         | 2/60 [30:32<10:01:32, 622.28s/trial, best loss: 8.273451538085938]\r  5%|▌         | 3/60 [30:32<9:37:00, 607.37s/trial, best loss: 8.273451538085938] \r                                                                                  \r{'batch_size': 128, 'drop_ratio': 0.29212937599269906, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.00020429632563757953, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r  5%|▌         | 3/60 [30:32<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 1/5\n",
      "\r  5%|▌         | 3/60 [30:32<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.518 Val loss 17.541\n",
      "\r  5%|▌         | 3/60 [30:35<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 11.792 Val loss 12.882\n",
      "\r  5%|▌         | 3/60 [31:29<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 193 best_val_loss 12.093\n",
      "\r  5%|▌         | 3/60 [32:21<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 2/5\n",
      "\r  5%|▌         | 3/60 [32:21<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.542 Val loss 16.945\n",
      "\r  5%|▌         | 3/60 [32:28<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 12.189 Val loss 12.098\n",
      "\r  5%|▌         | 3/60 [33:21<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 193 best_val_loss 11.176\n",
      "\r  5%|▌         | 3/60 [34:02<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 3/5\n",
      "\r  5%|▌         | 3/60 [34:02<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.769 Val loss 16.670\n",
      "\r  5%|▌         | 3/60 [34:06<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 12.127 Val loss 12.636\n",
      "\r  5%|▌         | 3/60 [34:54<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 194 best_val_loss 11.719\n",
      "\r  5%|▌         | 3/60 [35:50<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 4/5\n",
      "\r  5%|▌         | 3/60 [35:50<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.750 Val loss 16.655\n",
      "\r  5%|▌         | 3/60 [35:54<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 12.101 Val loss 12.672\n",
      "\r  5%|▌         | 3/60 [36:57<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 183 best_val_loss 12.090\n",
      "\r  5%|▌         | 3/60 [37:45<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 5/5\n",
      "\r  5%|▌         | 3/60 [37:45<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.575 Val loss 17.142\n",
      "\r  5%|▌         | 3/60 [37:49<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 12.375 Val loss 13.359\n",
      "\r  5%|▌         | 3/60 [38:45<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 199 best_val_loss 11.980\n",
      "\r  5%|▌         | 3/60 [39:33<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r                                                                                  \rval MSE loss mean: 11.81172\n",
      "\n",
      "\r  5%|▌         | 3/60 [39:33<9:37:00, 607.37s/trial, best loss: 8.273451538085938]\r  7%|▋         | 4/60 [39:33<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \r{'batch_size': 256, 'drop_ratio': 0.26577433699757924, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0006985664102928056, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r  7%|▋         | 4/60 [39:33<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 1/5\n",
      "\r  7%|▋         | 4/60 [39:33<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.750 Val loss 17.724\n",
      "\r  7%|▋         | 4/60 [39:39<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 11.423 Val loss 12.811\n",
      "\r  7%|▋         | 4/60 [40:25<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 200 Train loss 9.567 Val loss 11.799\n",
      "\r  7%|▋         | 4/60 [41:17<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 255 best_val_loss 11.621\n",
      "\r  7%|▋         | 4/60 [41:54<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 2/5\n",
      "\r  7%|▋         | 4/60 [41:54<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.896 Val loss 17.272\n",
      "\r  7%|▋         | 4/60 [41:59<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 11.016 Val loss 11.523\n",
      "\r  7%|▋         | 4/60 [42:48<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 200 Train loss 9.341 Val loss 10.970\n",
      "\r  7%|▋         | 4/60 [43:17<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 239 best_val_loss 10.454\n",
      "\r  7%|▋         | 4/60 [43:49<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 3/5\n",
      "\r  7%|▋         | 4/60 [43:49<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.879 Val loss 16.787\n",
      "\r  7%|▋         | 4/60 [43:52<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 10.544 Val loss 12.219\n",
      "\r  7%|▋         | 4/60 [44:37<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 200 Train loss 8.902 Val loss 10.568\n",
      "\r  7%|▋         | 4/60 [45:29<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 285 best_val_loss 10.369\n",
      "\r  7%|▋         | 4/60 [46:10<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 4/5\n",
      "\r  7%|▋         | 4/60 [46:10<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.786 Val loss 16.665\n",
      "\r  7%|▋         | 4/60 [46:14<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 11.568 Val loss 12.591\n",
      "\r  7%|▋         | 4/60 [47:04<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 200 Train loss 10.257 Val loss 11.736\n",
      "\r  7%|▋         | 4/60 [47:42<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 233 best_val_loss 11.555\n",
      "\r  7%|▋         | 4/60 [48:09<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 5/5\n",
      "\r  7%|▋         | 4/60 [48:09<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.570 Val loss 16.924\n",
      "\r  7%|▋         | 4/60 [48:12<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 11.026 Val loss 12.377\n",
      "\r  7%|▋         | 4/60 [48:45<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 200 Train loss 9.405 Val loss 11.384\n",
      "\r  7%|▋         | 4/60 [49:34<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 239 best_val_loss 11.019\n",
      "\r  7%|▋         | 4/60 [50:02<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r                                                                                  \rval MSE loss mean: 11.00377\n",
      "\n",
      "\r  7%|▋         | 4/60 [50:02<9:02:36, 581.36s/trial, best loss: 8.273451538085938]\r  8%|▊         | 5/60 [50:02<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \r{'batch_size': 128, 'drop_ratio': 0.2746311876299218, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0008093122688033709, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r  8%|▊         | 5/60 [50:02<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 1/5\n",
      "\r  8%|▊         | 5/60 [50:02<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.159 Val loss 17.542\n",
      "\r  8%|▊         | 5/60 [50:06<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 5.052 Val loss 9.047\n",
      "\r  8%|▊         | 5/60 [51:20<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rStopped at epoch 177 best_val_loss 8.539\n",
      "\r  8%|▊         | 5/60 [52:30<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 2/5\n",
      "\r  8%|▊         | 5/60 [52:30<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.502 Val loss 17.136\n",
      "\r  8%|▊         | 5/60 [52:35<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 5.178 Val loss 8.005\n",
      "\r  8%|▊         | 5/60 [53:43<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 165 best_val_loss 7.807\n",
      "\r  8%|▊         | 5/60 [54:52<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 3/5\n",
      "\r  8%|▊         | 5/60 [54:52<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.447 Val loss 16.555\n",
      "\r  8%|▊         | 5/60 [54:56<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 5.348 Val loss 8.338\n",
      "\r  8%|▊         | 5/60 [55:58<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 166 best_val_loss 8.085\n",
      "\r  8%|▊         | 5/60 [56:55<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 4/5\n",
      "\r  8%|▊         | 5/60 [56:55<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.468 Val loss 16.625\n",
      "\r  8%|▊         | 5/60 [57:01<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 5.526 Val loss 8.592\n",
      "\r  8%|▊         | 5/60 [58:05<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 138 best_val_loss 8.375\n",
      "\r  8%|▊         | 5/60 [58:49<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rFold: 5/5\n",
      "\r  8%|▊         | 5/60 [58:50<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 0 Train loss 17.297 Val loss 17.372\n",
      "\r  8%|▊         | 5/60 [58:54<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEpoch 100 Train loss 5.547 Val loss 8.495\n",
      "\r  8%|▊         | 5/60 [59:59<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                  \rEarly stopped at epoch 165 best_val_loss 8.348\n",
      "\r  8%|▊         | 5/60 [1:01:08<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r                                                                                    \rval MSE loss mean: 8.23063\n",
      "\n",
      "\r  8%|▊         | 5/60 [1:01:08<9:08:37, 598.49s/trial, best loss: 8.273451538085938]\r 10%|█         | 6/60 [1:01:08<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \r{'batch_size': 256, 'drop_ratio': 0.23246570463220426, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0006721512961245496, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 10%|█         | 6/60 [1:01:08<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 1/5\n",
      "\r 10%|█         | 6/60 [1:01:08<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.829 Val loss 17.615\n",
      "\r 10%|█         | 6/60 [1:01:14<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.730 Val loss 12.623\n",
      "\r 10%|█         | 6/60 [1:01:54<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 193 best_val_loss 12.055\n",
      "\r 10%|█         | 6/60 [1:02:42<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 2/5\n",
      "\r 10%|█         | 6/60 [1:02:42<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.821 Val loss 16.750\n",
      "\r 10%|█         | 6/60 [1:02:48<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 12.191 Val loss 12.080\n",
      "\r 10%|█         | 6/60 [1:03:24<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 186 best_val_loss 11.615\n",
      "\r 10%|█         | 6/60 [1:03:58<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 3/5\n",
      "\r 10%|█         | 6/60 [1:03:58<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.814 Val loss 17.565\n",
      "\r 10%|█         | 6/60 [1:04:04<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.388 Val loss 12.520\n",
      "\r 10%|█         | 6/60 [1:04:43<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 179 best_val_loss 11.721\n",
      "\r 10%|█         | 6/60 [1:05:19<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 4/5\n",
      "\r 10%|█         | 6/60 [1:05:19<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.053 Val loss 16.379\n",
      "\r 10%|█         | 6/60 [1:05:23<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.321 Val loss 12.406\n",
      "\r 10%|█         | 6/60 [1:06:02<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 188 best_val_loss 11.544\n",
      "\r 10%|█         | 6/60 [1:06:33<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 5/5\n",
      "\r 10%|█         | 6/60 [1:06:33<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.005 Val loss 16.772\n",
      "\r 10%|█         | 6/60 [1:06:40<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 12.137 Val loss 12.577\n",
      "\r 10%|█         | 6/60 [1:07:19<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 185 best_val_loss 11.835\n",
      "\r 10%|█         | 6/60 [1:07:48<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r                                                                                    \rval MSE loss mean: 11.75400\n",
      "\n",
      "\r 10%|█         | 6/60 [1:07:48<9:19:18, 621.45s/trial, best loss: 8.230630249023438]\r 12%|█▏        | 7/60 [1:07:48<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \r{'batch_size': 128, 'drop_ratio': 0.3130165232945099, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.000572576940776354, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 12%|█▏        | 7/60 [1:07:48<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 1/5\n",
      "\r 12%|█▏        | 7/60 [1:07:48<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.247 Val loss 17.611\n",
      "\r 12%|█▏        | 7/60 [1:07:57<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 5.633 Val loss 9.011\n",
      "\r 12%|█▏        | 7/60 [1:08:52<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 145 best_val_loss 8.565\n",
      "\r 12%|█▏        | 7/60 [1:09:33<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 2/5\n",
      "\r 12%|█▏        | 7/60 [1:09:33<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.491 Val loss 17.261\n",
      "\r 12%|█▏        | 7/60 [1:09:37<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.077 Val loss 8.317\n",
      "\r 12%|█▏        | 7/60 [1:10:51<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 200 Train loss 4.715 Val loss 8.151\n",
      "\r 12%|█▏        | 7/60 [1:11:58<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 195 best_val_loss 8.007\n",
      "\r 12%|█▏        | 7/60 [1:12:17<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 3/5\n",
      "\r 12%|█▏        | 7/60 [1:12:17<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.518 Val loss 16.687\n",
      "\r 12%|█▏        | 7/60 [1:12:23<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 5.797 Val loss 8.687\n",
      "\r 12%|█▏        | 7/60 [1:13:35<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 200 Train loss 4.571 Val loss 8.412\n",
      "\r 12%|█▏        | 7/60 [1:14:44<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 180 best_val_loss 8.209\n",
      "\r 12%|█▏        | 7/60 [1:14:55<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 4/5\n",
      "\r 12%|█▏        | 7/60 [1:14:55<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.518 Val loss 16.702\n",
      "\r 12%|█▏        | 7/60 [1:15:02<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 5.878 Val loss 8.803\n",
      "\r 12%|█▏        | 7/60 [1:16:04<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 200 Train loss 4.708 Val loss 8.473\n",
      "\r 12%|█▏        | 7/60 [1:17:11<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 237 best_val_loss 8.309\n",
      "\r 12%|█▏        | 7/60 [1:17:53<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 5/5\n",
      "\r 12%|█▏        | 7/60 [1:17:53<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.357 Val loss 17.354\n",
      "\r 12%|█▏        | 7/60 [1:17:58<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 5.674 Val loss 8.913\n",
      "\r 12%|█▏        | 7/60 [1:19:05<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 133 best_val_loss 8.420\n",
      "\r 12%|█▏        | 7/60 [1:19:50<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r                                                                                    \rval MSE loss mean: 8.30204\n",
      "\n",
      "\r 12%|█▏        | 7/60 [1:19:50<8:05:02, 549.10s/trial, best loss: 8.230630249023438]\r 13%|█▎        | 8/60 [1:19:50<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \r{'batch_size': 128, 'drop_ratio': 0.43502316031397315, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0009898337105554605, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 13%|█▎        | 8/60 [1:19:50<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 1/5\n",
      "\r 13%|█▎        | 8/60 [1:19:50<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.357 Val loss 17.825\n",
      "\r 13%|█▎        | 8/60 [1:19:54<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.062 Val loss 8.934\n",
      "\r 13%|█▎        | 8/60 [1:21:09<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 145 best_val_loss 8.545\n",
      "\r 13%|█▎        | 8/60 [1:21:57<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 2/5\n",
      "\r 13%|█▎        | 8/60 [1:21:57<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.666 Val loss 17.272\n",
      "\r 13%|█▎        | 8/60 [1:22:02<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.907 Val loss 8.613\n",
      "\r 13%|█▎        | 8/60 [1:23:37<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 148 best_val_loss 8.424\n",
      "\r 13%|█▎        | 8/60 [1:24:30<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 3/5\n",
      "\r 13%|█▎        | 8/60 [1:24:30<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.646 Val loss 16.530\n",
      "\r 13%|█▎        | 8/60 [1:24:36<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.808 Val loss 8.997\n",
      "\r 13%|█▎        | 8/60 [1:25:44<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 125 best_val_loss 8.751\n",
      "\r 13%|█▎        | 8/60 [1:26:28<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 4/5\n",
      "\r 13%|█▎        | 8/60 [1:26:28<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.660 Val loss 16.573\n",
      "\r 13%|█▎        | 8/60 [1:26:35<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.295 Val loss 8.837\n",
      "\r 13%|█▎        | 8/60 [1:28:14<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEarly stopped at epoch 150 best_val_loss 8.528\n",
      "\r 13%|█▎        | 8/60 [1:29:24<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 5/5\n",
      "\r 13%|█▎        | 8/60 [1:29:24<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 17.543 Val loss 17.092\n",
      "\r 13%|█▎        | 8/60 [1:29:37<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 6.657 Val loss 8.851\n",
      "\r 13%|█▎        | 8/60 [1:30:53<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 188 best_val_loss 8.586\n",
      "\r 13%|█▎        | 8/60 [1:32:05<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r                                                                                    \rval MSE loss mean: 8.56681\n",
      "\n",
      "\r 13%|█▎        | 8/60 [1:32:05<8:43:30, 604.05s/trial, best loss: 8.230630249023438]\r 15%|█▌        | 9/60 [1:32:05<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \r{'batch_size': 256, 'drop_ratio': 0.3666718776849015, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0009626130367227975, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 15%|█▌        | 9/60 [1:32:05<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 1/5\n",
      "\r 15%|█▌        | 9/60 [1:32:05<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.586 Val loss 17.571\n",
      "\r 15%|█▌        | 9/60 [1:32:10<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.678 Val loss 12.413\n",
      "\r 15%|█▌        | 9/60 [1:33:09<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 184 best_val_loss 11.674\n",
      "\r 15%|█▌        | 9/60 [1:33:43<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 2/5\n",
      "\r 15%|█▌        | 9/60 [1:33:43<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.458 Val loss 16.863\n",
      "\r 15%|█▌        | 9/60 [1:33:49<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.838 Val loss 11.649\n",
      "\r 15%|█▌        | 9/60 [1:34:26<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 183 best_val_loss 11.126\n",
      "\r 15%|█▌        | 9/60 [1:35:00<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 3/5\n",
      "\r 15%|█▌        | 9/60 [1:35:00<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.419 Val loss 16.929\n",
      "\r 15%|█▌        | 9/60 [1:35:04<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.812 Val loss 12.559\n",
      "\r 15%|█▌        | 9/60 [1:35:36<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 191 best_val_loss 11.589\n",
      "\r 15%|█▌        | 9/60 [1:36:09<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 4/5\n",
      "\r 15%|█▌        | 9/60 [1:36:09<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.777 Val loss 16.610\n",
      "\r 15%|█▌        | 9/60 [1:36:13<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 11.613 Val loss 12.175\n",
      "\r 15%|█▌        | 9/60 [1:36:49<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 194 best_val_loss 11.520\n",
      "\r 15%|█▌        | 9/60 [1:37:37<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rFold: 5/5\n",
      "\r 15%|█▌        | 9/60 [1:37:37<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 0 Train loss 18.700 Val loss 16.819\n",
      "\r 15%|█▌        | 9/60 [1:37:41<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rEpoch 100 Train loss 12.373 Val loss 12.791\n",
      "\r 15%|█▌        | 9/60 [1:38:16<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rStopped at epoch 194 best_val_loss 11.895\n",
      "\r 15%|█▌        | 9/60 [1:38:44<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r                                                                                    \rval MSE loss mean: 11.56059\n",
      "\n",
      "\r 15%|█▌        | 9/60 [1:38:44<9:08:16, 645.03s/trial, best loss: 8.230630249023438]\r 17%|█▋        | 10/60 [1:38:44<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.5994441067338495, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.00015767458983120271, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 17%|█▋        | 10/60 [1:38:44<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 17%|█▋        | 10/60 [1:38:44<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.415 Val loss 18.234\n",
      "\r 17%|█▋        | 10/60 [1:38:48<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.904 Val loss 11.911\n",
      "\r 17%|█▋        | 10/60 [1:39:50<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 9.028 Val loss 10.528\n",
      "\r 17%|█▋        | 10/60 [1:40:51<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 280 best_val_loss 10.235\n",
      "\r 17%|█▋        | 10/60 [1:41:58<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 17%|█▋        | 10/60 [1:41:58<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.539 Val loss 17.313\n",
      "\r 17%|█▋        | 10/60 [1:42:02<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.430 Val loss 11.226\n",
      "\r 17%|█▋        | 10/60 [1:43:06<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 9.547 Val loss 9.911\n",
      "\r 17%|█▋        | 10/60 [1:44:07<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 275 best_val_loss 9.522\n",
      "\r 17%|█▋        | 10/60 [1:45:11<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 17%|█▋        | 10/60 [1:45:11<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.513 Val loss 17.546\n",
      "\r 17%|█▋        | 10/60 [1:45:17<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.172 Val loss 11.529\n",
      "\r 17%|█▋        | 10/60 [1:46:15<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 9.026 Val loss 10.250\n",
      "\r 17%|█▋        | 10/60 [1:47:17<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 291 best_val_loss 9.945\n",
      "\r 17%|█▋        | 10/60 [1:48:14<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 17%|█▋        | 10/60 [1:48:14<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.498 Val loss 16.996\n",
      "\r 17%|█▋        | 10/60 [1:48:20<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.109 Val loss 11.678\n",
      "\r 17%|█▋        | 10/60 [1:49:23<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.938 Val loss 10.474\n",
      "\r 17%|█▋        | 10/60 [1:50:23<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 283 best_val_loss 10.197\n",
      "\r 17%|█▋        | 10/60 [1:51:23<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 17%|█▋        | 10/60 [1:51:23<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.507 Val loss 17.418\n",
      "\r 17%|█▋        | 10/60 [1:51:27<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.558 Val loss 11.760\n",
      "\r 17%|█▋        | 10/60 [1:52:20<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 9.550 Val loss 10.558\n",
      "\r 17%|█▋        | 10/60 [1:53:17<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 282 best_val_loss 10.176\n",
      "\r 17%|█▋        | 10/60 [1:54:19<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 10.01489\n",
      "\n",
      "\r 17%|█▋        | 10/60 [1:54:19<7:54:13, 569.07s/trial, best loss: 8.230630249023438]\r 18%|█▊        | 11/60 [1:54:19<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.10435942003946022, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.00047186076968271594, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 18%|█▊        | 11/60 [1:54:19<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 18%|█▊        | 11/60 [1:54:19<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.487 Val loss 17.513\n",
      "\r 18%|█▊        | 11/60 [1:54:22<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.281 Val loss 11.847\n",
      "\r 18%|█▊        | 11/60 [1:55:01<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 7.996 Val loss 10.417\n",
      "\r 18%|█▊        | 11/60 [1:55:42<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 297 best_val_loss 10.152\n",
      "\r 18%|█▊        | 11/60 [1:56:19<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 18%|█▊        | 11/60 [1:56:19<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.664 Val loss 16.650\n",
      "\r 18%|█▊        | 11/60 [1:56:23<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.621 Val loss 11.161\n",
      "\r 18%|█▊        | 11/60 [1:57:06<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.525 Val loss 9.791\n",
      "\r 18%|█▊        | 11/60 [1:57:44<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 280 best_val_loss 9.550\n",
      "\r 18%|█▊        | 11/60 [1:58:30<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 18%|█▊        | 11/60 [1:58:30<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.505 Val loss 16.795\n",
      "\r 18%|█▊        | 11/60 [1:58:35<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.505 Val loss 11.470\n",
      "\r 18%|█▊        | 11/60 [1:59:17<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.249 Val loss 10.207\n",
      "\r 18%|█▊        | 11/60 [1:59:56<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 286 best_val_loss 9.927\n",
      "\r 18%|█▊        | 11/60 [2:01:02<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 18%|█▊        | 11/60 [2:01:02<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.638 Val loss 16.476\n",
      "\r 18%|█▊        | 11/60 [2:01:07<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.554 Val loss 11.793\n",
      "\r 18%|█▊        | 11/60 [2:02:12<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.481 Val loss 10.800\n",
      "\r 18%|█▊        | 11/60 [2:03:06<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 274 best_val_loss 10.645\n",
      "\r 18%|█▊        | 11/60 [2:03:38<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 18%|█▊        | 11/60 [2:03:38<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.532 Val loss 16.915\n",
      "\r 18%|█▊        | 11/60 [2:03:41<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.211 Val loss 11.410\n",
      "\r 18%|█▊        | 11/60 [2:04:11<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 7.955 Val loss 10.589\n",
      "\r 18%|█▊        | 11/60 [2:04:40<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 237 best_val_loss 10.472\n",
      "\r 18%|█▊        | 11/60 [2:05:00<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 10.14900\n",
      "\n",
      "\r 18%|█▊        | 11/60 [2:05:00<9:16:06, 680.94s/trial, best loss: 8.230630249023438]\r 20%|██        | 12/60 [2:05:00<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.5078100123490756, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 3, 'lr': 0.0009711467495621995, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 20%|██        | 12/60 [2:05:00<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 20%|██        | 12/60 [2:05:00<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.448 Val loss 17.418\n",
      "\r 20%|██        | 12/60 [2:05:04<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 9.750 Val loss 10.830\n",
      "\r 20%|██        | 12/60 [2:05:47<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 95 best_val_loss 10.198\n",
      "\r 20%|██        | 12/60 [2:05:58<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 20%|██        | 12/60 [2:05:58<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.777 Val loss 16.732\n",
      "\r 20%|██        | 12/60 [2:06:01<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.294 Val loss 10.533\n",
      "\r 20%|██        | 12/60 [2:06:44<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 119 best_val_loss 9.643\n",
      "\r 20%|██        | 12/60 [2:07:06<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 20%|██        | 12/60 [2:07:06<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.573 Val loss 16.500\n",
      "\r 20%|██        | 12/60 [2:07:10<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.103 Val loss 10.639\n",
      "\r 20%|██        | 12/60 [2:07:55<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.936 Val loss 10.138\n",
      "\r 20%|██        | 12/60 [2:08:39<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 256 best_val_loss 10.061\n",
      "\r 20%|██        | 12/60 [2:09:17<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 20%|██        | 12/60 [2:09:17<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.764 Val loss 16.592\n",
      "\r 20%|██        | 12/60 [2:09:21<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 9.297 Val loss 10.441\n",
      "\r 20%|██        | 12/60 [2:10:03<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 8.114 Val loss 9.520\n",
      "\r 20%|██        | 12/60 [2:10:47<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 205 best_val_loss 9.395\n",
      "\r 20%|██        | 12/60 [2:11:03<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 20%|██        | 12/60 [2:11:03<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.567 Val loss 16.857\n",
      "\r 20%|██        | 12/60 [2:11:06<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 9.995 Val loss 11.925\n",
      "\r 20%|██        | 12/60 [2:11:51<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 10.913\n",
      "\r 20%|██        | 12/60 [2:11:51<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 10.04175\n",
      "\n",
      "\r 20%|██        | 12/60 [2:11:51<8:55:09, 668.94s/trial, best loss: 8.230630249023438]\r 22%|██▏       | 13/60 [2:11:51<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.14691868752511603, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.00018593669738988238, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 22%|██▏       | 13/60 [2:11:51<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 22%|██▏       | 13/60 [2:11:51<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.385 Val loss 17.594\n",
      "\r 22%|██▏       | 13/60 [2:11:55<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.343 Val loss 12.663\n",
      "\r 22%|██▏       | 13/60 [2:12:18<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 189 best_val_loss 11.817\n",
      "\r 22%|██▏       | 13/60 [2:12:41<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 22%|██▏       | 13/60 [2:12:41<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.593 Val loss 16.919\n",
      "\r 22%|██▏       | 13/60 [2:12:45<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.523 Val loss 11.610\n",
      "\r 22%|██▏       | 13/60 [2:13:08<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 186 best_val_loss 10.832\n",
      "\r 22%|██▏       | 13/60 [2:13:31<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 22%|██▏       | 13/60 [2:13:31<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.454 Val loss 16.735\n",
      "\r 22%|██▏       | 13/60 [2:13:35<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.337 Val loss 11.918\n",
      "\r 22%|██▏       | 13/60 [2:13:59<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 199 best_val_loss 11.230\n",
      "\r 22%|██▏       | 13/60 [2:14:23<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 22%|██▏       | 13/60 [2:14:23<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.525 Val loss 16.643\n",
      "\r 22%|██▏       | 13/60 [2:14:26<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 10.784 Val loss 12.320\n",
      "\r 22%|██▏       | 13/60 [2:14:50<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 182 best_val_loss 11.581\n",
      "\r 22%|██▏       | 13/60 [2:15:13<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 22%|██▏       | 13/60 [2:15:13<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.493 Val loss 17.354\n",
      "\r 22%|██▏       | 13/60 [2:15:17<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 11.761 Val loss 12.347\n",
      "\r 22%|██▏       | 13/60 [2:15:39<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 195 best_val_loss 11.712\n",
      "\r 22%|██▏       | 13/60 [2:16:01<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 11.43428\n",
      "\n",
      "\r 22%|██▏       | 13/60 [2:16:01<7:42:45, 590.76s/trial, best loss: 8.230630249023438]\r 23%|██▎       | 14/60 [2:16:01<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.5250422218315635, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0009490328552573807, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 23%|██▎       | 14/60 [2:16:01<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 23%|██▎       | 14/60 [2:16:01<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.429 Val loss 18.582\n",
      "\r 23%|██▎       | 14/60 [2:16:05<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.608 Val loss 14.542\n",
      "\r 23%|██▎       | 14/60 [2:16:42<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 161 best_val_loss 13.523\n",
      "\r 23%|██▎       | 14/60 [2:17:16<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 23%|██▎       | 14/60 [2:17:16<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.893 Val loss 18.077\n",
      "\r 23%|██▎       | 14/60 [2:17:20<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.504 Val loss 13.614\n",
      "\r 23%|██▎       | 14/60 [2:17:56<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 13.032\n",
      "\r 23%|██▎       | 14/60 [2:18:11<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 23%|██▎       | 14/60 [2:18:11<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.776 Val loss 17.891\n",
      "\r 23%|██▎       | 14/60 [2:18:15<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.404 Val loss 14.118\n",
      "\r 23%|██▎       | 14/60 [2:18:53<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 11.282 Val loss 13.039\n",
      "\r 23%|██▎       | 14/60 [2:19:29<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 208 best_val_loss 12.931\n",
      "\r 23%|██▎       | 14/60 [2:19:42<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 23%|██▎       | 14/60 [2:19:42<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.040 Val loss 17.291\n",
      "\r 23%|██▎       | 14/60 [2:19:46<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.722 Val loss 14.342\n",
      "\r 23%|██▎       | 14/60 [2:20:19<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.832 Val loss 13.626\n",
      "\r 23%|██▎       | 14/60 [2:20:52<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 193 best_val_loss 13.259\n",
      "\r 23%|██▎       | 14/60 [2:20:59<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 23%|██▎       | 14/60 [2:20:59<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.436 Val loss 17.383\n",
      "\r 23%|██▎       | 14/60 [2:21:04<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.521 Val loss 13.991\n",
      "\r 23%|██▎       | 14/60 [2:21:37<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 112 best_val_loss 13.405\n",
      "\r 23%|██▎       | 14/60 [2:21:51<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 13.22997\n",
      "\n",
      "\r 23%|██▎       | 14/60 [2:21:51<6:14:06, 487.96s/trial, best loss: 8.230630249023438]\r 25%|██▌       | 15/60 [2:21:51<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.32138159671268796, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 3, 'lr': 0.0007121816443282798, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 25%|██▌       | 15/60 [2:21:51<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 25%|██▌       | 15/60 [2:21:51<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.517 Val loss 17.364\n",
      "\r 25%|██▌       | 15/60 [2:21:54<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.125 Val loss 13.428\n",
      "\r 25%|██▌       | 15/60 [2:22:23<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 11.927 Val loss 12.436\n",
      "\r 25%|██▌       | 15/60 [2:22:51<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 267 best_val_loss 12.213\n",
      "\r 25%|██▌       | 15/60 [2:23:18<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 25%|██▌       | 15/60 [2:23:18<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.797 Val loss 17.267\n",
      "\r 25%|██▌       | 15/60 [2:23:22<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.392 Val loss 12.001\n",
      "\r 25%|██▌       | 15/60 [2:23:50<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 10.883 Val loss 11.432\n",
      "\r 25%|██▌       | 15/60 [2:24:18<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 262 best_val_loss 10.818\n",
      "\r 25%|██▌       | 15/60 [2:24:45<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 25%|██▌       | 15/60 [2:24:45<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.241 Val loss 16.712\n",
      "\r 25%|██▌       | 15/60 [2:24:49<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.787 Val loss 12.701\n",
      "\r 25%|██▌       | 15/60 [2:25:17<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 11.708 Val loss 11.722\n",
      "\r 25%|██▌       | 15/60 [2:25:46<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 270 best_val_loss 11.439\n",
      "\r 25%|██▌       | 15/60 [2:26:14<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 25%|██▌       | 15/60 [2:26:14<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.355 Val loss 16.599\n",
      "\r 25%|██▌       | 15/60 [2:26:18<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.094 Val loss 12.598\n",
      "\r 25%|██▌       | 15/60 [2:26:48<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 10.141 Val loss 11.412\n",
      "\r 25%|██▌       | 15/60 [2:27:20<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 297 best_val_loss 11.126\n",
      "\r 25%|██▌       | 15/60 [2:27:52<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 25%|██▌       | 15/60 [2:27:52<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.482 Val loss 17.219\n",
      "\r 25%|██▌       | 15/60 [2:27:55<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.925 Val loss 12.963\n",
      "\r 25%|██▌       | 15/60 [2:28:26<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 11.592 Val loss 12.243\n",
      "\r 25%|██▌       | 15/60 [2:28:54<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 296 best_val_loss 12.084\n",
      "\r 25%|██▌       | 15/60 [2:29:23<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 11.53615\n",
      "\n",
      "\r 25%|██▌       | 15/60 [2:29:23<5:34:36, 446.15s/trial, best loss: 8.230630249023438]\r 27%|██▋       | 16/60 [2:29:23<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.49111084019306217, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.00032104330580062806, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 27%|██▋       | 16/60 [2:29:23<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 27%|██▋       | 16/60 [2:29:23<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.077 Val loss 17.661\n",
      "\r 27%|██▋       | 16/60 [2:29:27<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.115 Val loss 13.959\n",
      "\r 27%|██▋       | 16/60 [2:29:49<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.211 Val loss 13.435\n",
      "\r 27%|██▋       | 16/60 [2:30:10<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 263 best_val_loss 12.681\n",
      "\r 27%|██▋       | 16/60 [2:30:31<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 27%|██▋       | 16/60 [2:30:31<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.358 Val loss 16.866\n",
      "\r 27%|██▋       | 16/60 [2:30:34<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.752 Val loss 13.430\n",
      "\r 27%|██▋       | 16/60 [2:30:56<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.598 Val loss 12.276\n",
      "\r 27%|██▋       | 16/60 [2:31:18<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 263 best_val_loss 12.127\n",
      "\r 27%|██▋       | 16/60 [2:31:39<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 27%|██▋       | 16/60 [2:31:39<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.598 Val loss 16.722\n",
      "\r 27%|██▋       | 16/60 [2:31:42<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.451 Val loss 13.107\n",
      "\r 27%|██▋       | 16/60 [2:32:03<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.330 Val loss 12.880\n",
      "\r 27%|██▋       | 16/60 [2:32:25<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 287 best_val_loss 12.423\n",
      "\r 27%|██▋       | 16/60 [2:32:47<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 27%|██▋       | 16/60 [2:32:47<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.545 Val loss 16.797\n",
      "\r 27%|██▋       | 16/60 [2:32:51<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.496 Val loss 13.374\n",
      "\r 27%|██▋       | 16/60 [2:33:12<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.385 Val loss 12.569\n",
      "\r 27%|██▋       | 16/60 [2:33:35<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 294 best_val_loss 12.187\n",
      "\r 27%|██▋       | 16/60 [2:33:56<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 27%|██▋       | 16/60 [2:33:56<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.677 Val loss 17.244\n",
      "\r 27%|██▋       | 16/60 [2:33:59<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.802 Val loss 13.275\n",
      "\r 27%|██▋       | 16/60 [2:34:21<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 12.520 Val loss 12.616\n",
      "\r 27%|██▋       | 16/60 [2:34:43<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 292 best_val_loss 12.364\n",
      "\r 27%|██▋       | 16/60 [2:35:04<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 12.35648\n",
      "\n",
      "\r 27%|██▋       | 16/60 [2:35:04<5:28:34, 448.05s/trial, best loss: 8.230630249023438]\r 28%|██▊       | 17/60 [2:35:04<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.5956216704881602, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0005023852930088836, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 28%|██▊       | 17/60 [2:35:04<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 28%|██▊       | 17/60 [2:35:04<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.776 Val loss 17.864\n",
      "\r 28%|██▊       | 17/60 [2:35:08<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 8.478 Val loss 9.901\n",
      "\r 28%|██▊       | 17/60 [2:36:02<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 7.246 Val loss 9.673\n",
      "\r 28%|██▊       | 17/60 [2:36:58<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 229 best_val_loss 9.322\n",
      "\r 28%|██▊       | 17/60 [2:37:31<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 28%|██▊       | 17/60 [2:37:31<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.938 Val loss 17.332\n",
      "\r 28%|██▊       | 17/60 [2:37:35<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 8.213 Val loss 8.932\n",
      "\r 28%|██▊       | 17/60 [2:38:17<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 6.970 Val loss 8.516\n",
      "\r 28%|██▊       | 17/60 [2:39:08<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 268 best_val_loss 8.403\n",
      "\r 28%|██▊       | 17/60 [2:40:02<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 28%|██▊       | 17/60 [2:40:02<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.027 Val loss 16.910\n",
      "\r 28%|██▊       | 17/60 [2:40:06<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 8.181 Val loss 9.237\n",
      "\r 28%|██▊       | 17/60 [2:41:01<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 6.866 Val loss 8.750\n",
      "\r 28%|██▊       | 17/60 [2:41:55<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 261 best_val_loss 8.609\n",
      "\r 28%|██▊       | 17/60 [2:42:46<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 28%|██▊       | 17/60 [2:42:46<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.979 Val loss 16.721\n",
      "\r 28%|██▊       | 17/60 [2:42:50<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 9.003 Val loss 10.289\n",
      "\r 28%|██▊       | 17/60 [2:43:45<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 129 best_val_loss 10.061\n",
      "\r 28%|██▊       | 17/60 [2:44:19<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 28%|██▊       | 17/60 [2:44:19<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.876 Val loss 17.181\n",
      "\r 28%|██▊       | 17/60 [2:44:22<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 8.934 Val loss 9.767\n",
      "\r 28%|██▊       | 17/60 [2:45:18<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 7.512 Val loss 9.139\n",
      "\r 28%|██▊       | 17/60 [2:46:13<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 225 best_val_loss 8.936\n",
      "\r 28%|██▊       | 17/60 [2:46:44<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 9.06607\n",
      "\n",
      "\r 28%|██▊       | 17/60 [2:46:44<4:58:02, 415.87s/trial, best loss: 8.230630249023438]\r 30%|███       | 18/60 [2:46:44<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.23807005384552435, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0007055226472557689, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 30%|███       | 18/60 [2:46:44<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 30%|███       | 18/60 [2:46:44<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.304 Val loss 17.589\n",
      "\r 30%|███       | 18/60 [2:46:48<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.755 Val loss 9.792\n",
      "\r 30%|███       | 18/60 [2:47:14<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 5.366 Val loss 8.968\n",
      "\r 30%|███       | 18/60 [2:47:43<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 293 best_val_loss 8.885\n",
      "\r 30%|███       | 18/60 [2:48:09<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 30%|███       | 18/60 [2:48:09<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.568 Val loss 16.999\n",
      "\r 30%|███       | 18/60 [2:48:13<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.507 Val loss 8.737\n",
      "\r 30%|███       | 18/60 [2:48:40<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 5.205 Val loss 8.219\n",
      "\r 30%|███       | 18/60 [2:49:07<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 218 best_val_loss 8.074\n",
      "\r 30%|███       | 18/60 [2:49:20<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 30%|███       | 18/60 [2:49:20<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.842 Val loss 16.764\n",
      "\r 30%|███       | 18/60 [2:49:23<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.688 Val loss 9.217\n",
      "\r 30%|███       | 18/60 [2:49:50<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 5.208 Val loss 8.629\n",
      "\r 30%|███       | 18/60 [2:50:18<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 218 best_val_loss 8.433\n",
      "\r 30%|███       | 18/60 [2:50:32<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 30%|███       | 18/60 [2:50:32<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.421 Val loss 16.702\n",
      "\r 30%|███       | 18/60 [2:50:35<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.884 Val loss 9.831\n",
      "\r 30%|███       | 18/60 [2:51:02<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 5.825 Val loss 8.909\n",
      "\r 30%|███       | 18/60 [2:51:27<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 292 best_val_loss 8.746\n",
      "\r 30%|███       | 18/60 [2:51:52<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 30%|███       | 18/60 [2:51:52<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.336 Val loss 17.372\n",
      "\r 30%|███       | 18/60 [2:51:56<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 7.531 Val loss 9.851\n",
      "\r 30%|███       | 18/60 [2:52:22<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 200 Train loss 6.083 Val loss 9.507\n",
      "\r 30%|███       | 18/60 [2:52:46<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 231 best_val_loss 9.130\n",
      "\r 30%|███       | 18/60 [2:53:03<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.65366\n",
      "\n",
      "\r 30%|███       | 18/60 [2:53:03<5:50:52, 501.25s/trial, best loss: 8.230630249023438]\r 32%|███▏      | 19/60 [2:53:03<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.5262486975396965, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0009771330746617952, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 32%|███▏      | 19/60 [2:53:03<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 32%|███▏      | 19/60 [2:53:03<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.222 Val loss 17.652\n",
      "\r 32%|███▏      | 19/60 [2:53:07<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.935 Val loss 13.169\n",
      "\r 32%|███▏      | 19/60 [2:53:26<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 178 best_val_loss 12.780\n",
      "\r 32%|███▏      | 19/60 [2:53:47<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 32%|███▏      | 19/60 [2:53:47<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.022 Val loss 16.866\n",
      "\r 32%|███▏      | 19/60 [2:53:50<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.576 Val loss 11.834\n",
      "\r 32%|███▏      | 19/60 [2:54:12<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 164 best_val_loss 11.154\n",
      "\r 32%|███▏      | 19/60 [2:54:32<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 32%|███▏      | 19/60 [2:54:32<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 18.907 Val loss 17.130\n",
      "\r 32%|███▏      | 19/60 [2:54:36<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.116 Val loss 12.245\n",
      "\r 32%|███▏      | 19/60 [2:54:56<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 187 best_val_loss 11.352\n",
      "\r 32%|███▏      | 19/60 [2:55:15<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 32%|███▏      | 19/60 [2:55:15<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.282 Val loss 16.774\n",
      "\r 32%|███▏      | 19/60 [2:55:19<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 12.388 Val loss 12.503\n",
      "\r 32%|███▏      | 19/60 [2:55:40<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 199 best_val_loss 11.945\n",
      "\r 32%|███▏      | 19/60 [2:56:01<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 32%|███▏      | 19/60 [2:56:01<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 19.261 Val loss 16.865\n",
      "\r 32%|███▏      | 19/60 [2:56:04<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 13.113 Val loss 13.128\n",
      "\r 32%|███▏      | 19/60 [2:56:27<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 197 best_val_loss 12.359\n",
      "\r 32%|███▏      | 19/60 [2:56:47<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 11.91799\n",
      "\n",
      "\r 32%|███▏      | 19/60 [2:56:47<5:17:18, 464.35s/trial, best loss: 8.230630249023438]\r 33%|███▎      | 20/60 [2:56:47<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.16849360776416106, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0008429089383184546, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 33%|███▎      | 20/60 [2:56:48<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 33%|███▎      | 20/60 [2:56:48<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.335 Val loss 17.345\n",
      "\r 33%|███▎      | 20/60 [2:56:51<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.818 Val loss 8.699\n",
      "\r 33%|███▎      | 20/60 [2:57:41<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 149 best_val_loss 8.475\n",
      "\r 33%|███▎      | 20/60 [2:58:22<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 33%|███▎      | 20/60 [2:58:22<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.409 Val loss 16.777\n",
      "\r 33%|███▎      | 20/60 [2:58:26<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.053 Val loss 8.366\n",
      "\r 33%|███▎      | 20/60 [2:59:17<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 170 best_val_loss 8.111\n",
      "\r 33%|███▎      | 20/60 [3:00:06<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 33%|███▎      | 20/60 [3:00:06<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.386 Val loss 16.492\n",
      "\r 33%|███▎      | 20/60 [3:00:10<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.838 Val loss 8.259\n",
      "\r 33%|███▎      | 20/60 [3:01:01<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 97 best_val_loss 8.056\n",
      "\r 33%|███▎      | 20/60 [3:01:15<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 33%|███▎      | 20/60 [3:01:15<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.481 Val loss 16.392\n",
      "\r 33%|███▎      | 20/60 [3:01:19<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.170 Val loss 8.966\n",
      "\r 33%|███▎      | 20/60 [3:02:11<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 191 best_val_loss 8.596\n",
      "\r 33%|███▎      | 20/60 [3:03:05<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 33%|███▎      | 20/60 [3:03:05<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.468 Val loss 16.932\n",
      "\r 33%|███▎      | 20/60 [3:03:09<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.766 Val loss 8.666\n",
      "\r 33%|███▎      | 20/60 [3:04:03<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 105 best_val_loss 8.326\n",
      "\r 33%|███▎      | 20/60 [3:04:22<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.31268\n",
      "\n",
      "\r 33%|███▎      | 20/60 [3:04:22<4:21:38, 392.46s/trial, best loss: 8.230630249023438]\r 35%|███▌      | 21/60 [3:04:22<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.10043661173833665, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0008291802014587426, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 35%|███▌      | 21/60 [3:04:22<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 35%|███▌      | 21/60 [3:04:22<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.254 Val loss 17.303\n",
      "\r 35%|███▌      | 21/60 [3:04:26<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.341 Val loss 8.685\n",
      "\r 35%|███▌      | 21/60 [3:05:19<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 168 best_val_loss 8.389\n",
      "\r 35%|███▌      | 21/60 [3:06:12<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 35%|███▌      | 21/60 [3:06:12<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.303 Val loss 16.665\n",
      "\r 35%|███▌      | 21/60 [3:06:16<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.513 Val loss 8.424\n",
      "\r 35%|███▌      | 21/60 [3:07:09<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 121 best_val_loss 8.119\n",
      "\r 35%|███▌      | 21/60 [3:07:37<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 35%|███▌      | 21/60 [3:07:37<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.321 Val loss 16.446\n",
      "\r 35%|███▌      | 21/60 [3:07:41<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.380 Val loss 8.247\n",
      "\r 35%|███▌      | 21/60 [3:08:34<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 128 best_val_loss 7.999\n",
      "\r 35%|███▌      | 21/60 [3:09:03<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 35%|███▌      | 21/60 [3:09:03<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.382 Val loss 16.456\n",
      "\r 35%|███▌      | 21/60 [3:09:07<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.620 Val loss 8.738\n",
      "\r 35%|███▌      | 21/60 [3:10:01<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 120 best_val_loss 8.468\n",
      "\r 35%|███▌      | 21/60 [3:10:29<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 35%|███▌      | 21/60 [3:10:29<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.350 Val loss 16.940\n",
      "\r 35%|███▌      | 21/60 [3:10:32<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.010 Val loss 9.258\n",
      "\r 35%|███▌      | 21/60 [3:11:22<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 148 best_val_loss 8.420\n",
      "\r 35%|███▌      | 21/60 [3:12:05<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.27897\n",
      "\n",
      "\r 35%|███▌      | 21/60 [3:12:05<4:27:11, 411.07s/trial, best loss: 8.230630249023438]\r 37%|███▋      | 22/60 [3:12:05<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.3915705528078046, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0008569443986699023, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 37%|███▋      | 22/60 [3:12:05<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 37%|███▋      | 22/60 [3:12:05<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.686 Val loss 17.864\n",
      "\r 37%|███▋      | 22/60 [3:12:09<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.675 Val loss 9.472\n",
      "\r 37%|███▋      | 22/60 [3:12:59<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 178 best_val_loss 8.976\n",
      "\r 37%|███▋      | 22/60 [3:13:46<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 37%|███▋      | 22/60 [3:13:46<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.686 Val loss 16.955\n",
      "\r 37%|███▋      | 22/60 [3:13:50<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.163 Val loss 8.602\n",
      "\r 37%|███▋      | 22/60 [3:14:41<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 162 best_val_loss 8.193\n",
      "\r 37%|███▋      | 22/60 [3:15:25<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 37%|███▋      | 22/60 [3:15:25<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.725 Val loss 16.831\n",
      "\r 37%|███▋      | 22/60 [3:15:29<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.636 Val loss 8.950\n",
      "\r 37%|███▋      | 22/60 [3:16:21<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 170 best_val_loss 8.469\n",
      "\r 37%|███▋      | 22/60 [3:17:14<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 37%|███▋      | 22/60 [3:17:14<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.710 Val loss 16.607\n",
      "\r 37%|███▋      | 22/60 [3:17:18<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.839 Val loss 9.189\n",
      "\r 37%|███▋      | 22/60 [3:18:09<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 197 best_val_loss 8.855\n",
      "\r 37%|███▋      | 22/60 [3:18:57<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 37%|███▋      | 22/60 [3:18:57<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.734 Val loss 17.539\n",
      "\r 37%|███▋      | 22/60 [3:19:01<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 6.418 Val loss 8.782\n",
      "\r 37%|███▋      | 22/60 [3:19:48<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 181 best_val_loss 8.466\n",
      "\r 37%|███▋      | 22/60 [3:20:38<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.59180\n",
      "\n",
      "\r 37%|███▋      | 22/60 [3:20:38<4:30:13, 426.67s/trial, best loss: 8.230630249023438]\r 38%|███▊      | 23/60 [3:20:38<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.1718056438631167, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.000787435569304787, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 38%|███▊      | 23/60 [3:20:38<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 38%|███▊      | 23/60 [3:20:38<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.286 Val loss 17.339\n",
      "\r 38%|███▊      | 23/60 [3:20:42<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.873 Val loss 8.929\n",
      "\r 38%|███▊      | 23/60 [3:21:32<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 129 best_val_loss 8.627\n",
      "\r 38%|███▊      | 23/60 [3:22:03<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 38%|███▊      | 23/60 [3:22:03<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.417 Val loss 16.730\n",
      "\r 38%|███▊      | 23/60 [3:22:07<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.351 Val loss 8.346\n",
      "\r 38%|███▊      | 23/60 [3:22:57<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rStopped at epoch 178 best_val_loss 8.004\n",
      "\r 38%|███▊      | 23/60 [3:23:46<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 38%|███▊      | 23/60 [3:23:46<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.443 Val loss 16.530\n",
      "\r 38%|███▊      | 23/60 [3:23:50<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.028 Val loss 8.332\n",
      "\r 38%|███▊      | 23/60 [3:24:38<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 157 best_val_loss 8.045\n",
      "\r 38%|███▊      | 23/60 [3:25:20<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 38%|███▊      | 23/60 [3:25:20<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.445 Val loss 16.425\n",
      "\r 38%|███▊      | 23/60 [3:25:24<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.842 Val loss 8.750\n",
      "\r 38%|███▊      | 23/60 [3:26:08<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 125 best_val_loss 8.465\n",
      "\r 38%|███▊      | 23/60 [3:26:35<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 38%|███▊      | 23/60 [3:26:35<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.423 Val loss 16.915\n",
      "\r 38%|███▊      | 23/60 [3:26:39<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 5.079 Val loss 9.033\n",
      "\r 38%|███▊      | 23/60 [3:27:28<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 123 best_val_loss 8.575\n",
      "\r 38%|███▊      | 23/60 [3:27:56<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.34302\n",
      "\n",
      "\r 38%|███▊      | 23/60 [3:27:56<4:39:09, 452.68s/trial, best loss: 8.230630249023438]\r 40%|████      | 24/60 [3:27:56<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.1289173036136904, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0006209331948157525, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 40%|████      | 24/60 [3:27:56<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 1/5\n",
      "\r 40%|████      | 24/60 [3:27:56<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.052 Val loss 17.588\n",
      "\r 40%|████      | 24/60 [3:28:00<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.382 Val loss 8.514\n",
      "\r 40%|████      | 24/60 [3:28:53<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 8.430\n",
      "\r 40%|████      | 24/60 [3:29:11<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 2/5\n",
      "\r 40%|████      | 24/60 [3:29:11<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.352 Val loss 17.037\n",
      "\r 40%|████      | 24/60 [3:29:15<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.487 Val loss 8.107\n",
      "\r 40%|████      | 24/60 [3:30:05<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 7.839\n",
      "\r 40%|████      | 24/60 [3:30:41<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 3/5\n",
      "\r 40%|████      | 24/60 [3:30:41<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.317 Val loss 16.554\n",
      "\r 40%|████      | 24/60 [3:30:44<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.419 Val loss 8.128\n",
      "\r 40%|████      | 24/60 [3:31:33<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 122 best_val_loss 7.987\n",
      "\r 40%|████      | 24/60 [3:31:57<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 4/5\n",
      "\r 40%|████      | 24/60 [3:31:57<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.381 Val loss 16.704\n",
      "\r 40%|████      | 24/60 [3:32:01<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.348 Val loss 8.541\n",
      "\r 40%|████      | 24/60 [3:32:52<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 143 best_val_loss 8.205\n",
      "\r 40%|████      | 24/60 [3:33:20<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rFold: 5/5\n",
      "\r 40%|████      | 24/60 [3:33:20<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 0 Train loss 17.206 Val loss 17.482\n",
      "\r 40%|████      | 24/60 [3:33:24<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEpoch 100 Train loss 4.495 Val loss 8.519\n",
      "\r 40%|████      | 24/60 [3:34:16<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rEarly stopped at epoch 138 best_val_loss 8.374\n",
      "\r 40%|████      | 24/60 [3:34:54<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r                                                                                     \rval MSE loss mean: 8.16700\n",
      "\n",
      "\r 40%|████      | 24/60 [3:34:54<4:28:56, 448.24s/trial, best loss: 8.230630249023438]\r 42%|████▏     | 25/60 [3:34:55<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.18245507207738149, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.00039171052620225687, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 42%|████▏     | 25/60 [3:34:55<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 1/5\n",
      "\r 42%|████▏     | 25/60 [3:34:55<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.165 Val loss 17.581\n",
      "\r 42%|████▏     | 25/60 [3:34:58<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.384 Val loss 8.960\n",
      "\r 42%|████▏     | 25/60 [3:35:51<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 162 best_val_loss 8.619\n",
      "\r 42%|████▏     | 25/60 [3:36:41<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 2/5\n",
      "\r 42%|████▏     | 25/60 [3:36:41<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.355 Val loss 17.185\n",
      "\r 42%|████▏     | 25/60 [3:36:45<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.689 Val loss 8.513\n",
      "\r 42%|████▏     | 25/60 [3:37:41<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 159 best_val_loss 8.063\n",
      "\r 42%|████▏     | 25/60 [3:38:30<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 3/5\n",
      "\r 42%|████▏     | 25/60 [3:38:30<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.382 Val loss 16.665\n",
      "\r 42%|████▏     | 25/60 [3:38:34<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.246 Val loss 8.281\n",
      "\r 42%|████▏     | 25/60 [3:39:29<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 182 best_val_loss 8.054\n",
      "\r 42%|████▏     | 25/60 [3:40:23<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 4/5\n",
      "\r 42%|████▏     | 25/60 [3:40:23<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.419 Val loss 16.714\n",
      "\r 42%|████▏     | 25/60 [3:40:27<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.270 Val loss 9.028\n",
      "\r 42%|████▏     | 25/60 [3:41:22<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 137 best_val_loss 8.599\n",
      "\r 42%|████▏     | 25/60 [3:41:57<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 5/5\n",
      "\r 42%|████▏     | 25/60 [3:41:57<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.211 Val loss 17.640\n",
      "\r 42%|████▏     | 25/60 [3:42:01<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.464 Val loss 8.832\n",
      "\r 42%|████▏     | 25/60 [3:42:56<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 133 best_val_loss 8.406\n",
      "\r 42%|████▏     | 25/60 [3:43:32<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r                                                                                     \rval MSE loss mean: 8.34807\n",
      "\n",
      "\r 42%|████▏     | 25/60 [3:43:32<4:16:13, 439.25s/trial, best loss: 8.167001831054687]\r 43%|████▎     | 26/60 [3:43:32<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.4074986592979066, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0006028437925509073, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 43%|████▎     | 26/60 [3:43:32<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 1/5\n",
      "\r 43%|████▎     | 26/60 [3:43:32<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.401 Val loss 17.682\n",
      "\r 43%|████▎     | 26/60 [3:43:35<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 6.650 Val loss 9.321\n",
      "\r 43%|████▎     | 26/60 [3:44:31<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 192 best_val_loss 8.984\n",
      "\r 43%|████▎     | 26/60 [3:45:24<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 2/5\n",
      "\r 43%|████▎     | 26/60 [3:45:24<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.623 Val loss 17.417\n",
      "\r 43%|████▎     | 26/60 [3:45:28<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 6.798 Val loss 8.659\n",
      "\r 43%|████▎     | 26/60 [3:46:20<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 196 best_val_loss 8.160\n",
      "\r 43%|████▎     | 26/60 [3:47:06<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 3/5\n",
      "\r 43%|████▎     | 26/60 [3:47:06<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.650 Val loss 16.724\n",
      "\r 43%|████▎     | 26/60 [3:47:10<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 6.582 Val loss 8.972\n",
      "\r 43%|████▎     | 26/60 [3:47:56<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 138 best_val_loss 8.542\n",
      "\r 43%|████▎     | 26/60 [3:48:30<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 4/5\n",
      "\r 43%|████▎     | 26/60 [3:48:30<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.605 Val loss 16.646\n",
      "\r 43%|████▎     | 26/60 [3:48:34<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 6.301 Val loss 8.828\n",
      "\r 43%|████▎     | 26/60 [3:49:19<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 195 best_val_loss 8.572\n",
      "\r 43%|████▎     | 26/60 [3:50:10<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 5/5\n",
      "\r 43%|████▎     | 26/60 [3:50:10<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.480 Val loss 17.271\n",
      "\r 43%|████▎     | 26/60 [3:50:14<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 6.633 Val loss 8.902\n",
      "\r 43%|████▎     | 26/60 [3:51:07<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 133 best_val_loss 8.584\n",
      "\r 43%|████▎     | 26/60 [3:51:42<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r                                                                                     \rval MSE loss mean: 8.56836\n",
      "\n",
      "\r 43%|████▎     | 26/60 [3:51:42<4:22:08, 462.60s/trial, best loss: 8.167001831054687]\r 45%|████▌     | 27/60 [3:51:42<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.2678750189797493, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0006119129872434677, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 45%|████▌     | 27/60 [3:51:42<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 1/5\n",
      "\r 45%|████▌     | 27/60 [3:51:42<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.181 Val loss 17.590\n",
      "\r 45%|████▌     | 27/60 [3:51:46<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.220 Val loss 8.793\n",
      "\r 45%|████▌     | 27/60 [3:52:34<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 145 best_val_loss 8.504\n",
      "\r 45%|████▌     | 27/60 [3:53:09<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 2/5\n",
      "\r 45%|████▌     | 27/60 [3:53:09<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.464 Val loss 17.178\n",
      "\r 45%|████▌     | 27/60 [3:53:13<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.996 Val loss 7.994\n",
      "\r 45%|████▌     | 27/60 [3:54:05<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 178 best_val_loss 7.813\n",
      "\r 45%|████▌     | 27/60 [3:54:52<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 3/5\n",
      "\r 45%|████▌     | 27/60 [3:54:52<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.441 Val loss 16.661\n",
      "\r 45%|████▌     | 27/60 [3:54:56<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.485 Val loss 8.734\n",
      "\r 45%|████▌     | 27/60 [3:55:31<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 173 best_val_loss 8.321\n",
      "\r 45%|████▌     | 27/60 [3:56:24<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 4/5\n",
      "\r 45%|████▌     | 27/60 [3:56:24<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.456 Val loss 16.750\n",
      "\r 45%|████▌     | 27/60 [3:56:27<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.281 Val loss 8.650\n",
      "\r 45%|████▌     | 27/60 [3:57:21<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rStopped at epoch 196 best_val_loss 8.288\n",
      "\r 45%|████▌     | 27/60 [3:58:12<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 5/5\n",
      "\r 45%|████▌     | 27/60 [3:58:12<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.301 Val loss 17.548\n",
      "\r 45%|████▌     | 27/60 [3:58:15<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 5.455 Val loss 8.973\n",
      "\r 45%|████▌     | 27/60 [3:59:01<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 157 best_val_loss 8.589\n",
      "\r 45%|████▌     | 27/60 [3:59:51<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r                                                                                     \rval MSE loss mean: 8.30289\n",
      "\n",
      "\r 45%|████▌     | 27/60 [3:59:51<4:18:59, 470.91s/trial, best loss: 8.167001831054687]\r 47%|████▋     | 28/60 [3:59:51<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.14234196621060002, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0007661165222865405, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 47%|████▋     | 28/60 [3:59:51<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 1/5\n",
      "\r 47%|████▋     | 28/60 [3:59:51<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.071 Val loss 17.489\n",
      "\r 47%|████▋     | 28/60 [3:59:55<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.413 Val loss 8.704\n",
      "\r 47%|████▋     | 28/60 [4:00:48<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 148 best_val_loss 8.277\n",
      "\r 47%|████▋     | 28/60 [4:01:31<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 2/5\n",
      "\r 47%|████▋     | 28/60 [4:01:31<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.385 Val loss 16.898\n",
      "\r 47%|████▋     | 28/60 [4:01:34<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.552 Val loss 8.174\n",
      "\r 47%|████▋     | 28/60 [4:02:29<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 112 best_val_loss 7.880\n",
      "\r 47%|████▋     | 28/60 [4:02:53<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 3/5\n",
      "\r 47%|████▋     | 28/60 [4:02:53<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.300 Val loss 16.513\n",
      "\r 47%|████▋     | 28/60 [4:02:58<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.244 Val loss 8.236\n",
      "\r 47%|████▋     | 28/60 [4:03:52<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 149 best_val_loss 8.008\n",
      "\r 47%|████▋     | 28/60 [4:04:36<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 4/5\n",
      "\r 47%|████▋     | 28/60 [4:04:36<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.405 Val loss 16.626\n",
      "\r 47%|████▋     | 28/60 [4:04:39<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.363 Val loss 8.366\n",
      "\r 47%|████▋     | 28/60 [4:05:33<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 126 best_val_loss 8.112\n",
      "\r 47%|████▋     | 28/60 [4:06:00<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rFold: 5/5\n",
      "\r 47%|████▋     | 28/60 [4:06:00<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 0 Train loss 17.214 Val loss 17.424\n",
      "\r 47%|████▋     | 28/60 [4:06:04<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEpoch 100 Train loss 4.471 Val loss 8.735\n",
      "\r 47%|████▋     | 28/60 [4:06:53<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rEarly stopped at epoch 125 best_val_loss 8.385\n",
      "\r 47%|████▋     | 28/60 [4:07:23<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r                                                                                     \rval MSE loss mean: 8.13224\n",
      "\n",
      "\r 47%|████▋     | 28/60 [4:07:23<4:14:00, 476.26s/trial, best loss: 8.167001831054687]\r 48%|████▊     | 29/60 [4:07:23<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.13391957521560804, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0005063940801076119, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 48%|████▊     | 29/60 [4:07:23<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 48%|████▊     | 29/60 [4:07:23<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.087 Val loss 17.600\n",
      "\r 48%|████▊     | 29/60 [4:07:27<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.591 Val loss 8.841\n",
      "\r 48%|████▊     | 29/60 [4:08:21<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 123 best_val_loss 8.531\n",
      "\r 48%|████▊     | 29/60 [4:08:50<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 48%|████▊     | 29/60 [4:08:50<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.332 Val loss 17.134\n",
      "\r 48%|████▊     | 29/60 [4:08:54<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.903 Val loss 8.261\n",
      "\r 48%|████▊     | 29/60 [4:09:47<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 170 best_val_loss 8.109\n",
      "\r 48%|████▊     | 29/60 [4:10:41<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 48%|████▊     | 29/60 [4:10:41<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.331 Val loss 16.608\n",
      "\r 48%|████▊     | 29/60 [4:10:45<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.937 Val loss 8.316\n",
      "\r 48%|████▊     | 29/60 [4:11:39<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 171 best_val_loss 8.133\n",
      "\r 48%|████▊     | 29/60 [4:12:32<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 48%|████▊     | 29/60 [4:12:32<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.386 Val loss 16.769\n",
      "\r 48%|████▊     | 29/60 [4:12:36<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.758 Val loss 8.728\n",
      "\r 48%|████▊     | 29/60 [4:13:30<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 137 best_val_loss 8.372\n",
      "\r 48%|████▊     | 29/60 [4:14:07<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 48%|████▊     | 29/60 [4:14:07<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.197 Val loss 17.513\n",
      "\r 48%|████▊     | 29/60 [4:14:11<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.825 Val loss 8.754\n",
      "\r 48%|████▊     | 29/60 [4:14:57<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 8.579\n",
      "\r 48%|████▊     | 29/60 [4:15:13<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.34506\n",
      "\n",
      "\r 48%|████▊     | 29/60 [4:15:13<4:02:23, 469.14s/trial, best loss: 8.132235107421875]\r 50%|█████     | 30/60 [4:15:13<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.2018376785158165, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0009025401056505385, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 50%|█████     | 30/60 [4:15:13<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 50%|█████     | 30/60 [4:15:13<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.118 Val loss 17.462\n",
      "\r 50%|█████     | 30/60 [4:15:16<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.735 Val loss 8.831\n",
      "\r 50%|█████     | 30/60 [4:15:57<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 181 best_val_loss 8.589\n",
      "\r 50%|█████     | 30/60 [4:16:35<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 50%|█████     | 30/60 [4:16:35<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.399 Val loss 16.951\n",
      "\r 50%|█████     | 30/60 [4:16:39<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.705 Val loss 8.250\n",
      "\r 50%|█████     | 30/60 [4:17:23<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 143 best_val_loss 7.893\n",
      "\r 50%|█████     | 30/60 [4:18:04<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 50%|█████     | 30/60 [4:18:04<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.307 Val loss 16.512\n",
      "\r 50%|█████     | 30/60 [4:18:08<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.321 Val loss 8.044\n",
      "\r 50%|█████     | 30/60 [4:19:01<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 7.886\n",
      "\r 50%|█████     | 30/60 [4:19:25<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 50%|█████     | 30/60 [4:19:25<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.459 Val loss 16.622\n",
      "\r 50%|█████     | 30/60 [4:19:28<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.934 Val loss 8.472\n",
      "\r 50%|█████     | 30/60 [4:20:24<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 126 best_val_loss 8.374\n",
      "\r 50%|█████     | 30/60 [4:20:55<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 50%|█████     | 30/60 [4:20:55<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.262 Val loss 17.312\n",
      "\r 50%|█████     | 30/60 [4:20:59<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.914 Val loss 8.642\n",
      "\r 50%|█████     | 30/60 [4:21:54<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 112 best_val_loss 8.428\n",
      "\r 50%|█████     | 30/60 [4:22:12<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.23407\n",
      "\n",
      "\r 50%|█████     | 30/60 [4:22:12<3:54:36, 469.23s/trial, best loss: 8.132235107421875]\r 52%|█████▏    | 31/60 [4:22:12<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.12000470636421887, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0004066957692649266, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 52%|█████▏    | 31/60 [4:22:12<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 52%|█████▏    | 31/60 [4:22:12<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.125 Val loss 17.598\n",
      "\r 52%|█████▏    | 31/60 [4:22:16<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.840 Val loss 8.973\n",
      "\r 52%|█████▏    | 31/60 [4:23:09<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 123 best_val_loss 8.665\n",
      "\r 52%|█████▏    | 31/60 [4:23:38<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 52%|█████▏    | 31/60 [4:23:38<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.329 Val loss 17.245\n",
      "\r 52%|█████▏    | 31/60 [4:23:42<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.052 Val loss 8.485\n",
      "\r 52%|█████▏    | 31/60 [4:24:33<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 164 best_val_loss 8.238\n",
      "\r 52%|█████▏    | 31/60 [4:25:20<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 52%|█████▏    | 31/60 [4:25:20<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.334 Val loss 16.636\n",
      "\r 52%|█████▏    | 31/60 [4:25:24<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.893 Val loss 8.448\n",
      "\r 52%|█████▏    | 31/60 [4:26:05<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 174 best_val_loss 8.179\n",
      "\r 52%|█████▏    | 31/60 [4:26:53<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 52%|█████▏    | 31/60 [4:26:53<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.360 Val loss 16.741\n",
      "\r 52%|█████▏    | 31/60 [4:26:57<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.098 Val loss 9.199\n",
      "\r 52%|█████▏    | 31/60 [4:27:52<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 166 best_val_loss 8.584\n",
      "\r 52%|█████▏    | 31/60 [4:28:36<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 52%|█████▏    | 31/60 [4:28:36<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.174 Val loss 17.541\n",
      "\r 52%|█████▏    | 31/60 [4:28:40<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.043 Val loss 8.795\n",
      "\r 52%|█████▏    | 31/60 [4:29:35<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 165 best_val_loss 8.494\n",
      "\r 52%|█████▏    | 31/60 [4:30:24<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.43213\n",
      "\n",
      "\r 52%|█████▏    | 31/60 [4:30:24<3:39:31, 454.17s/trial, best loss: 8.132235107421875]\r 53%|█████▎    | 32/60 [4:30:24<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.15266715538257847, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0007722679723078079, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 53%|█████▎    | 32/60 [4:30:24<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 53%|█████▎    | 32/60 [4:30:24<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.389 Val loss 17.947\n",
      "\r 53%|█████▎    | 32/60 [4:30:28<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.996 Val loss 10.538\n",
      "\r 53%|█████▎    | 32/60 [4:31:00<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 178 best_val_loss 9.976\n",
      "\r 53%|█████▎    | 32/60 [4:31:33<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 53%|█████▎    | 32/60 [4:31:33<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.616 Val loss 17.351\n",
      "\r 53%|█████▎    | 32/60 [4:31:37<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.773 Val loss 9.387\n",
      "\r 53%|█████▎    | 32/60 [4:32:09<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 174 best_val_loss 9.080\n",
      "\r 53%|█████▎    | 32/60 [4:32:42<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 53%|█████▎    | 32/60 [4:32:42<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.475 Val loss 16.633\n",
      "\r 53%|█████▎    | 32/60 [4:32:45<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.040 Val loss 10.656\n",
      "\r 53%|█████▎    | 32/60 [4:33:18<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 181 best_val_loss 9.985\n",
      "\r 53%|█████▎    | 32/60 [4:33:50<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 53%|█████▎    | 32/60 [4:33:50<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.574 Val loss 16.548\n",
      "\r 53%|█████▎    | 32/60 [4:33:53<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.541 Val loss 10.334\n",
      "\r 53%|█████▎    | 32/60 [4:34:28<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 176 best_val_loss 9.856\n",
      "\r 53%|█████▎    | 32/60 [4:35:04<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 53%|█████▎    | 32/60 [4:35:04<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.661 Val loss 17.117\n",
      "\r 53%|█████▎    | 32/60 [4:35:08<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.467 Val loss 10.403\n",
      "\r 53%|█████▎    | 32/60 [4:35:45<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 177 best_val_loss 9.693\n",
      "\r 53%|█████▎    | 32/60 [4:36:22<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 9.71788\n",
      "\n",
      "\r 53%|█████▎    | 32/60 [4:36:22<3:37:18, 465.67s/trial, best loss: 8.132235107421875]\r 55%|█████▌    | 33/60 [4:36:22<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.20461860614655536, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0006335804255095832, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 55%|█████▌    | 33/60 [4:36:22<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 55%|█████▌    | 33/60 [4:36:22<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.150 Val loss 17.556\n",
      "\r 55%|█████▌    | 33/60 [4:36:25<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.951 Val loss 9.034\n",
      "\r 55%|█████▌    | 33/60 [4:37:17<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 155 best_val_loss 8.458\n",
      "\r 55%|█████▌    | 33/60 [4:38:01<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 55%|█████▌    | 33/60 [4:38:01<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.408 Val loss 17.171\n",
      "\r 55%|█████▌    | 33/60 [4:38:04<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.781 Val loss 8.103\n",
      "\r 55%|█████▌    | 33/60 [4:38:46<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 128 best_val_loss 7.908\n",
      "\r 55%|█████▌    | 33/60 [4:39:17<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 55%|█████▌    | 33/60 [4:39:17<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.327 Val loss 16.587\n",
      "\r 55%|█████▌    | 33/60 [4:39:21<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.815 Val loss 8.159\n",
      "\r 55%|█████▌    | 33/60 [4:40:16<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 135 best_val_loss 8.012\n",
      "\r 55%|█████▌    | 33/60 [4:40:52<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 55%|█████▌    | 33/60 [4:40:52<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.450 Val loss 16.711\n",
      "\r 55%|█████▌    | 33/60 [4:40:55<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.886 Val loss 8.604\n",
      "\r 55%|█████▌    | 33/60 [4:41:47<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 143 best_val_loss 8.326\n",
      "\r 55%|█████▌    | 33/60 [4:42:28<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 55%|█████▌    | 33/60 [4:42:28<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.271 Val loss 17.532\n",
      "\r 55%|█████▌    | 33/60 [4:42:32<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.993 Val loss 8.530\n",
      "\r 55%|█████▌    | 33/60 [4:43:26<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 133 best_val_loss 8.346\n",
      "\r 55%|█████▌    | 33/60 [4:43:58<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.20994\n",
      "\n",
      "\r 55%|█████▌    | 33/60 [4:43:58<3:14:56, 433.21s/trial, best loss: 8.132235107421875]\r 57%|█████▋    | 34/60 [4:43:58<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.23767061808507256, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0005482071400192308, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 57%|█████▋    | 34/60 [4:43:58<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 57%|█████▋    | 34/60 [4:43:58<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.481 Val loss 17.524\n",
      "\r 57%|█████▋    | 34/60 [4:44:02<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.635 Val loss 12.640\n",
      "\r 57%|█████▋    | 34/60 [4:44:44<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 180 best_val_loss 11.900\n",
      "\r 57%|█████▋    | 34/60 [4:45:26<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 57%|█████▋    | 34/60 [4:45:26<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.747 Val loss 16.928\n",
      "\r 57%|█████▋    | 34/60 [4:45:30<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.115 Val loss 11.123\n",
      "\r 57%|█████▋    | 34/60 [4:46:09<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 159 best_val_loss 10.211\n",
      "\r 57%|█████▋    | 34/60 [4:46:46<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 57%|█████▋    | 34/60 [4:46:46<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.565 Val loss 16.630\n",
      "\r 57%|█████▋    | 34/60 [4:46:50<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.761 Val loss 11.722\n",
      "\r 57%|█████▋    | 34/60 [4:47:30<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 170 best_val_loss 11.239\n",
      "\r 57%|█████▋    | 34/60 [4:48:08<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 57%|█████▋    | 34/60 [4:48:08<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.708 Val loss 16.719\n",
      "\r 57%|█████▋    | 34/60 [4:48:12<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.944 Val loss 11.664\n",
      "\r 57%|█████▋    | 34/60 [4:48:48<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 157 best_val_loss 11.036\n",
      "\r 57%|█████▋    | 34/60 [4:49:24<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 57%|█████▋    | 34/60 [4:49:24<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.642 Val loss 16.979\n",
      "\r 57%|█████▋    | 34/60 [4:49:27<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.381 Val loss 12.019\n",
      "\r 57%|█████▋    | 34/60 [4:50:10<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 191 best_val_loss 11.322\n",
      "\r 57%|█████▋    | 34/60 [4:50:51<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 11.14142\n",
      "\n",
      "\r 57%|█████▋    | 34/60 [4:50:51<3:10:45, 440.21s/trial, best loss: 8.132235107421875]\r 58%|█████▊    | 35/60 [4:50:51<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.3391812445042908, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0007513473440852823, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 58%|█████▊    | 35/60 [4:50:51<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 58%|█████▊    | 35/60 [4:50:51<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.240 Val loss 17.580\n",
      "\r 58%|█████▊    | 35/60 [4:50:55<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.474 Val loss 8.764\n",
      "\r 58%|█████▊    | 35/60 [4:51:40<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 169 best_val_loss 8.455\n",
      "\r 58%|█████▊    | 35/60 [4:52:31<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 58%|█████▊    | 35/60 [4:52:31<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.544 Val loss 17.346\n",
      "\r 58%|█████▊    | 35/60 [4:52:34<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.906 Val loss 8.378\n",
      "\r 58%|█████▊    | 35/60 [4:53:29<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 183 best_val_loss 8.154\n",
      "\r 58%|█████▊    | 35/60 [4:54:25<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 58%|█████▊    | 35/60 [4:54:25<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.530 Val loss 16.581\n",
      "\r 58%|█████▊    | 35/60 [4:54:28<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.581 Val loss 8.506\n",
      "\r 58%|█████▊    | 35/60 [4:55:23<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 146 best_val_loss 8.219\n",
      "\r 58%|█████▊    | 35/60 [4:56:05<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 58%|█████▊    | 35/60 [4:56:05<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.561 Val loss 16.645\n",
      "\r 58%|█████▊    | 35/60 [4:56:09<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.721 Val loss 8.815\n",
      "\r 58%|█████▊    | 35/60 [4:57:01<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 140 best_val_loss 8.436\n",
      "\r 58%|█████▊    | 35/60 [4:57:38<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 58%|█████▊    | 35/60 [4:57:38<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.376 Val loss 17.303\n",
      "\r 58%|█████▊    | 35/60 [4:57:42<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.391 Val loss 9.071\n",
      "\r 58%|█████▊    | 35/60 [4:58:37<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 126 best_val_loss 8.668\n",
      "\r 58%|█████▊    | 35/60 [4:59:09<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.38617\n",
      "\n",
      "\r 58%|█████▊    | 35/60 [4:59:09<2:59:57, 431.91s/trial, best loss: 8.132235107421875]\r 60%|██████    | 36/60 [4:59:09<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.29588894163181745, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0008897757389224345, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 60%|██████    | 36/60 [4:59:09<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 60%|██████    | 36/60 [4:59:09<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.641 Val loss 18.185\n",
      "\r 60%|██████    | 36/60 [4:59:13<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.517 Val loss 11.710\n",
      "\r 60%|██████    | 36/60 [4:59:37<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 164 best_val_loss 11.215\n",
      "\r 60%|██████    | 36/60 [5:00:00<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 60%|██████    | 36/60 [5:00:00<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.781 Val loss 17.197\n",
      "\r 60%|██████    | 36/60 [5:00:03<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.686 Val loss 11.374\n",
      "\r 60%|██████    | 36/60 [5:00:27<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 155 best_val_loss 10.783\n",
      "\r 60%|██████    | 36/60 [5:00:48<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 60%|██████    | 36/60 [5:00:48<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.848 Val loss 16.782\n",
      "\r 60%|██████    | 36/60 [5:00:51<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.734 Val loss 10.210\n",
      "\r 60%|██████    | 36/60 [5:01:15<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 179 best_val_loss 9.617\n",
      "\r 60%|██████    | 36/60 [5:01:38<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 60%|██████    | 36/60 [5:01:38<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.928 Val loss 16.669\n",
      "\r 60%|██████    | 36/60 [5:01:42<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.832 Val loss 10.899\n",
      "\r 60%|██████    | 36/60 [5:02:04<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 191 best_val_loss 10.414\n",
      "\r 60%|██████    | 36/60 [5:02:28<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 60%|██████    | 36/60 [5:02:28<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.005 Val loss 16.945\n",
      "\r 60%|██████    | 36/60 [5:02:31<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.162 Val loss 11.680\n",
      "\r 60%|██████    | 36/60 [5:02:55<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 177 best_val_loss 10.844\n",
      "\r 60%|██████    | 36/60 [5:03:20<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 10.57491\n",
      "\n",
      "\r 60%|██████    | 36/60 [5:03:20<3:00:43, 451.81s/trial, best loss: 8.132235107421875]\r 62%|██████▏   | 37/60 [5:03:20<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.11861546083948717, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.00026384403555821046, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 62%|██████▏   | 37/60 [5:03:20<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 62%|██████▏   | 37/60 [5:03:20<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.133 Val loss 17.600\n",
      "\r 62%|██████▏   | 37/60 [5:03:23<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.200 Val loss 9.533\n",
      "\r 62%|██████▏   | 37/60 [5:04:18<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 188 best_val_loss 9.066\n",
      "\r 62%|██████▏   | 37/60 [5:05:02<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 62%|██████▏   | 37/60 [5:05:02<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.333 Val loss 17.121\n",
      "\r 62%|██████▏   | 37/60 [5:05:07<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.275 Val loss 8.699\n",
      "\r 62%|██████▏   | 37/60 [5:05:49<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 159 best_val_loss 8.212\n",
      "\r 62%|██████▏   | 37/60 [5:06:33<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 62%|██████▏   | 37/60 [5:06:33<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.389 Val loss 16.700\n",
      "\r 62%|██████▏   | 37/60 [5:06:37<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.292 Val loss 9.047\n",
      "\r 62%|██████▏   | 37/60 [5:07:29<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 171 best_val_loss 8.577\n",
      "\r 62%|██████▏   | 37/60 [5:08:22<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 62%|██████▏   | 37/60 [5:08:22<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.398 Val loss 16.728\n",
      "\r 62%|██████▏   | 37/60 [5:08:26<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.113 Val loss 9.560\n",
      "\r 62%|██████▏   | 37/60 [5:09:20<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 156 best_val_loss 8.945\n",
      "\r 62%|██████▏   | 37/60 [5:10:08<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 62%|██████▏   | 37/60 [5:10:08<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.207 Val loss 17.309\n",
      "\r 62%|██████▏   | 37/60 [5:10:11<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.484 Val loss 9.812\n",
      "\r 62%|██████▏   | 37/60 [5:11:07<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 155 best_val_loss 9.211\n",
      "\r 62%|██████▏   | 37/60 [5:11:47<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.80220\n",
      "\n",
      "\r 62%|██████▏   | 37/60 [5:11:47<2:30:03, 391.46s/trial, best loss: 8.132235107421875]\r 63%|██████▎   | 38/60 [5:11:47<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.4455344192080101, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0006664013454527335, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 63%|██████▎   | 38/60 [5:11:48<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 63%|██████▎   | 38/60 [5:11:48<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.457 Val loss 17.738\n",
      "\r 63%|██████▎   | 38/60 [5:11:51<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.547 Val loss 9.289\n",
      "\r 63%|██████▎   | 38/60 [5:12:36<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 193 best_val_loss 8.717\n",
      "\r 63%|██████▎   | 38/60 [5:13:28<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 63%|██████▎   | 38/60 [5:13:28<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.696 Val loss 17.436\n",
      "\r 63%|██████▎   | 38/60 [5:13:32<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.567 Val loss 8.964\n",
      "\r 63%|██████▎   | 38/60 [5:14:23<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 8.643\n",
      "\r 63%|██████▎   | 38/60 [5:15:00<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 63%|██████▎   | 38/60 [5:15:00<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.675 Val loss 16.871\n",
      "\r 63%|██████▎   | 38/60 [5:15:04<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.657 Val loss 8.544\n",
      "\r 63%|██████▎   | 38/60 [5:15:57<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 181 best_val_loss 8.294\n",
      "\r 63%|██████▎   | 38/60 [5:16:47<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 63%|██████▎   | 38/60 [5:16:47<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.672 Val loss 16.651\n",
      "\r 63%|██████▎   | 38/60 [5:16:51<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.808 Val loss 9.421\n",
      "\r 63%|██████▎   | 38/60 [5:17:38<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 184 best_val_loss 8.963\n",
      "\r 63%|██████▎   | 38/60 [5:18:32<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 63%|██████▎   | 38/60 [5:18:32<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.538 Val loss 17.127\n",
      "\r 63%|██████▎   | 38/60 [5:18:35<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.478 Val loss 9.518\n",
      "\r 63%|██████▎   | 38/60 [5:19:12<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 143 best_val_loss 9.092\n",
      "\r 63%|██████▎   | 38/60 [5:19:41<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.74172\n",
      "\n",
      "\r 63%|██████▎   | 38/60 [5:19:41<2:36:20, 426.40s/trial, best loss: 8.132235107421875]\r 65%|██████▌   | 39/60 [5:19:41<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.22114756118102152, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.00010436007440118211, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 65%|██████▌   | 39/60 [5:19:41<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 65%|██████▌   | 39/60 [5:19:41<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.607 Val loss 17.669\n",
      "\r 65%|██████▌   | 39/60 [5:19:45<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.846 Val loss 13.804\n",
      "\r 65%|██████▌   | 39/60 [5:20:07<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 197 best_val_loss 13.219\n",
      "\r 65%|██████▌   | 39/60 [5:20:30<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 65%|██████▌   | 39/60 [5:20:30<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.798 Val loss 16.933\n",
      "\r 65%|██████▌   | 39/60 [5:20:34<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 13.001 Val loss 12.831\n",
      "\r 65%|██████▌   | 39/60 [5:20:56<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 189 best_val_loss 12.192\n",
      "\r 65%|██████▌   | 39/60 [5:21:17<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 65%|██████▌   | 39/60 [5:21:17<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.770 Val loss 16.866\n",
      "\r 65%|██████▌   | 39/60 [5:21:21<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 13.178 Val loss 13.469\n",
      "\r 65%|██████▌   | 39/60 [5:21:44<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 199 best_val_loss 12.716\n",
      "\r 65%|██████▌   | 39/60 [5:22:09<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 65%|██████▌   | 39/60 [5:22:09<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.957 Val loss 16.622\n",
      "\r 65%|██████▌   | 39/60 [5:22:12<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.855 Val loss 13.604\n",
      "\r 65%|██████▌   | 39/60 [5:22:38<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 197 best_val_loss 12.944\n",
      "\r 65%|██████▌   | 39/60 [5:23:02<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 65%|██████▌   | 39/60 [5:23:02<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.877 Val loss 16.970\n",
      "\r 65%|██████▌   | 39/60 [5:23:05<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.870 Val loss 13.233\n",
      "\r 65%|██████▌   | 39/60 [5:23:31<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 170 best_val_loss 12.755\n",
      "\r 65%|██████▌   | 39/60 [5:23:55<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 12.76526\n",
      "\n",
      "\r 65%|██████▌   | 39/60 [5:23:55<2:34:13, 440.65s/trial, best loss: 8.132235107421875]\r 67%|██████▋   | 40/60 [5:23:55<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.25154183702129596, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0004354495952130996, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 67%|██████▋   | 40/60 [5:23:55<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 67%|██████▋   | 40/60 [5:23:55<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.055 Val loss 17.845\n",
      "\r 67%|██████▋   | 40/60 [5:23:59<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.676 Val loss 12.688\n",
      "\r 67%|██████▋   | 40/60 [5:24:29<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 190 best_val_loss 11.584\n",
      "\r 67%|██████▋   | 40/60 [5:24:54<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 67%|██████▋   | 40/60 [5:24:54<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.631 Val loss 16.760\n",
      "\r 67%|██████▋   | 40/60 [5:24:58<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.820 Val loss 12.140\n",
      "\r 67%|██████▋   | 40/60 [5:25:26<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 194 best_val_loss 11.347\n",
      "\r 67%|██████▋   | 40/60 [5:25:56<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 67%|██████▋   | 40/60 [5:25:56<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.862 Val loss 16.650\n",
      "\r 67%|██████▋   | 40/60 [5:26:00<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.810 Val loss 12.272\n",
      "\r 67%|██████▋   | 40/60 [5:26:29<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 11.730\n",
      "\r 67%|██████▋   | 40/60 [5:26:59<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 67%|██████▋   | 40/60 [5:26:59<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.297 Val loss 16.740\n",
      "\r 67%|██████▋   | 40/60 [5:27:03<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.090 Val loss 12.413\n",
      "\r 67%|██████▋   | 40/60 [5:27:33<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 199 best_val_loss 11.756\n",
      "\r 67%|██████▋   | 40/60 [5:28:02<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 67%|██████▋   | 40/60 [5:28:02<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.824 Val loss 16.901\n",
      "\r 67%|██████▋   | 40/60 [5:28:06<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.694 Val loss 12.053\n",
      "\r 67%|██████▋   | 40/60 [5:28:35<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 191 best_val_loss 11.456\n",
      "\r 67%|██████▋   | 40/60 [5:29:03<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 11.57471\n",
      "\n",
      "\r 67%|██████▋   | 40/60 [5:29:03<2:08:12, 384.63s/trial, best loss: 8.132235107421875]\r 68%|██████▊   | 41/60 [5:29:03<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.19916371016729362, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0005736058303926634, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 68%|██████▊   | 41/60 [5:29:03<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 68%|██████▊   | 41/60 [5:29:03<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.141 Val loss 17.574\n",
      "\r 68%|██████▊   | 41/60 [5:29:07<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.844 Val loss 8.828\n",
      "\r 68%|██████▊   | 41/60 [5:30:01<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 147 best_val_loss 8.463\n",
      "\r 68%|██████▊   | 41/60 [5:30:42<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 68%|██████▊   | 41/60 [5:30:42<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.387 Val loss 17.076\n",
      "\r 68%|██████▊   | 41/60 [5:30:46<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.803 Val loss 8.092\n",
      "\r 68%|██████▊   | 41/60 [5:31:40<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 129 best_val_loss 7.849\n",
      "\r 68%|██████▊   | 41/60 [5:32:02<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 68%|██████▊   | 41/60 [5:32:02<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.341 Val loss 16.592\n",
      "\r 68%|██████▊   | 41/60 [5:32:06<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.927 Val loss 8.402\n",
      "\r 68%|██████▊   | 41/60 [5:32:54<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 146 best_val_loss 8.185\n",
      "\r 68%|██████▊   | 41/60 [5:33:37<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 68%|██████▊   | 41/60 [5:33:37<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.436 Val loss 16.717\n",
      "\r 68%|██████▊   | 41/60 [5:33:41<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.904 Val loss 8.995\n",
      "\r 68%|██████▊   | 41/60 [5:34:35<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 166 best_val_loss 8.399\n",
      "\r 68%|██████▊   | 41/60 [5:35:30<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 68%|██████▊   | 41/60 [5:35:30<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.262 Val loss 17.581\n",
      "\r 68%|██████▊   | 41/60 [5:35:33<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.206 Val loss 8.753\n",
      "\r 68%|██████▊   | 41/60 [5:36:28<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 8.420\n",
      "\r 68%|██████▊   | 41/60 [5:36:45<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.26314\n",
      "\n",
      "\r 68%|██████▊   | 41/60 [5:36:45<1:54:29, 361.54s/trial, best loss: 8.132235107421875]\r 70%|███████   | 42/60 [5:36:45<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.2815919385572302, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0007274475587463011, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 70%|███████   | 42/60 [5:36:45<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 70%|███████   | 42/60 [5:36:45<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.306 Val loss 17.665\n",
      "\r 70%|███████   | 42/60 [5:36:48<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.140 Val loss 9.094\n",
      "\r 70%|███████   | 42/60 [5:37:13<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 177 best_val_loss 8.690\n",
      "\r 70%|███████   | 42/60 [5:37:38<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 70%|███████   | 42/60 [5:37:38<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.504 Val loss 16.958\n",
      "\r 70%|███████   | 42/60 [5:37:41<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.404 Val loss 8.224\n",
      "\r 70%|███████   | 42/60 [5:38:10<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 155 best_val_loss 7.813\n",
      "\r 70%|███████   | 42/60 [5:38:35<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 70%|███████   | 42/60 [5:38:35<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.661 Val loss 16.778\n",
      "\r 70%|███████   | 42/60 [5:38:39<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.831 Val loss 8.729\n",
      "\r 70%|███████   | 42/60 [5:39:07<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 8.363\n",
      "\r 70%|███████   | 42/60 [5:39:36<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 70%|███████   | 42/60 [5:39:36<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.574 Val loss 16.647\n",
      "\r 70%|███████   | 42/60 [5:39:40<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.443 Val loss 8.924\n",
      "\r 70%|███████   | 42/60 [5:40:08<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 167 best_val_loss 8.429\n",
      "\r 70%|███████   | 42/60 [5:40:36<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 70%|███████   | 42/60 [5:40:36<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.363 Val loss 17.035\n",
      "\r 70%|███████   | 42/60 [5:40:40<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.321 Val loss 9.052\n",
      "\r 70%|███████   | 42/60 [5:41:09<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 152 best_val_loss 8.703\n",
      "\r 70%|███████   | 42/60 [5:41:29<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.39943\n",
      "\n",
      "\r 70%|███████   | 42/60 [5:41:29<1:57:29, 391.61s/trial, best loss: 8.132235107421875]\r 72%|███████▏  | 43/60 [5:41:29<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.3595119187123371, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.00035688533290772513, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 72%|███████▏  | 43/60 [5:41:29<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 72%|███████▏  | 43/60 [5:41:29<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.835 Val loss 17.531\n",
      "\r 72%|███████▏  | 43/60 [5:41:33<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.226 Val loss 12.963\n",
      "\r 72%|███████▏  | 43/60 [5:41:59<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 12.439\n",
      "\r 72%|███████▏  | 43/60 [5:42:27<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 72%|███████▏  | 43/60 [5:42:27<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.677 Val loss 16.806\n",
      "\r 72%|███████▏  | 43/60 [5:42:30<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.333 Val loss 12.377\n",
      "\r 72%|███████▏  | 43/60 [5:42:57<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 195 best_val_loss 11.680\n",
      "\r 72%|███████▏  | 43/60 [5:43:25<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 72%|███████▏  | 43/60 [5:43:25<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.996 Val loss 16.697\n",
      "\r 72%|███████▏  | 43/60 [5:43:28<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.442 Val loss 12.755\n",
      "\r 72%|███████▏  | 43/60 [5:43:56<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 12.269\n",
      "\r 72%|███████▏  | 43/60 [5:44:24<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 72%|███████▏  | 43/60 [5:44:24<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.931 Val loss 16.500\n",
      "\r 72%|███████▏  | 43/60 [5:44:28<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.230 Val loss 12.909\n",
      "\r 72%|███████▏  | 43/60 [5:44:56<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 183 best_val_loss 12.205\n",
      "\r 72%|███████▏  | 43/60 [5:45:23<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 72%|███████▏  | 43/60 [5:45:23<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.679 Val loss 17.623\n",
      "\r 72%|███████▏  | 43/60 [5:45:26<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.536 Val loss 12.922\n",
      "\r 72%|███████▏  | 43/60 [5:45:52<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 188 best_val_loss 12.314\n",
      "\r 72%|███████▏  | 43/60 [5:46:18<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 12.18115\n",
      "\n",
      "\r 72%|███████▏  | 43/60 [5:46:18<1:41:51, 359.52s/trial, best loss: 8.132235107421875]\r 73%|███████▎  | 44/60 [5:46:18<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.14821336094114268, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0006646382257632098, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 73%|███████▎  | 44/60 [5:46:18<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 73%|███████▎  | 44/60 [5:46:18<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.554 Val loss 17.660\n",
      "\r 73%|███████▎  | 44/60 [5:46:22<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.587 Val loss 10.733\n",
      "\r 73%|███████▎  | 44/60 [5:46:54<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 7.131 Val loss 10.113\n",
      "\r 73%|███████▎  | 44/60 [5:47:28<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 272 best_val_loss 9.766\n",
      "\r 73%|███████▎  | 44/60 [5:48:00<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 73%|███████▎  | 44/60 [5:48:00<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.476 Val loss 16.801\n",
      "\r 73%|███████▎  | 44/60 [5:48:04<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.518 Val loss 10.716\n",
      "\r 73%|███████▎  | 44/60 [5:48:42<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 8.081 Val loss 10.398\n",
      "\r 73%|███████▎  | 44/60 [5:49:17<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 250 best_val_loss 9.798\n",
      "\r 73%|███████▎  | 44/60 [5:49:48<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 73%|███████▎  | 44/60 [5:49:48<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.602 Val loss 16.762\n",
      "\r 73%|███████▎  | 44/60 [5:49:51<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.131 Val loss 11.588\n",
      "\r 73%|███████▎  | 44/60 [5:50:24<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 8.652 Val loss 10.637\n",
      "\r 73%|███████▎  | 44/60 [5:50:56<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 218 best_val_loss 10.473\n",
      "\r 73%|███████▎  | 44/60 [5:51:10<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 73%|███████▎  | 44/60 [5:51:10<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.485 Val loss 16.399\n",
      "\r 73%|███████▎  | 44/60 [5:51:14<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.585 Val loss 11.621\n",
      "\r 73%|███████▎  | 44/60 [5:51:42<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 7.722 Val loss 10.421\n",
      "\r 73%|███████▎  | 44/60 [5:52:16<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 201 best_val_loss 10.220\n",
      "\r 73%|███████▎  | 44/60 [5:52:28<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 73%|███████▎  | 44/60 [5:52:28<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.483 Val loss 17.364\n",
      "\r 73%|███████▎  | 44/60 [5:52:32<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.886 Val loss 10.687\n",
      "\r 73%|███████▎  | 44/60 [5:53:08<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 6.964 Val loss 9.825\n",
      "\r 73%|███████▎  | 44/60 [5:53:41<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 291 best_val_loss 9.538\n",
      "\r 73%|███████▎  | 44/60 [5:54:11<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 9.95906\n",
      "\n",
      "\r 73%|███████▎  | 44/60 [5:54:11<1:30:13, 338.35s/trial, best loss: 8.132235107421875]\r 75%|███████▌  | 45/60 [5:54:11<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.10182698250062744, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0009009753018835119, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 75%|███████▌  | 45/60 [5:54:11<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 75%|███████▌  | 45/60 [5:54:11<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.035 Val loss 17.425\n",
      "\r 75%|███████▌  | 45/60 [5:54:15<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 3.999 Val loss 8.864\n",
      "\r 75%|███████▌  | 45/60 [5:55:11<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 122 best_val_loss 8.517\n",
      "\r 75%|███████▌  | 45/60 [5:55:32<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 75%|███████▌  | 45/60 [5:55:32<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.364 Val loss 16.899\n",
      "\r 75%|███████▌  | 45/60 [5:55:36<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.336 Val loss 8.528\n",
      "\r 75%|███████▌  | 45/60 [5:56:28<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 143 best_val_loss 8.229\n",
      "\r 75%|███████▌  | 45/60 [5:57:09<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 75%|███████▌  | 45/60 [5:57:09<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.270 Val loss 16.414\n",
      "\r 75%|███████▌  | 45/60 [5:57:13<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.147 Val loss 8.254\n",
      "\r 75%|███████▌  | 45/60 [5:58:07<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 132 best_val_loss 8.128\n",
      "\r 75%|███████▌  | 45/60 [5:58:40<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 75%|███████▌  | 45/60 [5:58:40<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.374 Val loss 16.610\n",
      "\r 75%|███████▌  | 45/60 [5:58:43<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 4.192 Val loss 8.646\n",
      "\r 75%|███████▌  | 45/60 [5:59:36<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 131 best_val_loss 8.299\n",
      "\r 75%|███████▌  | 45/60 [6:00:10<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 75%|███████▌  | 45/60 [6:00:10<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.174 Val loss 17.077\n",
      "\r 75%|███████▌  | 45/60 [6:00:14<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 3.948 Val loss 8.415\n",
      "\r 75%|███████▌  | 45/60 [6:01:08<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 94 best_val_loss 8.154\n",
      "\r 75%|███████▌  | 45/60 [6:01:21<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.26541\n",
      "\n",
      "\r 75%|███████▌  | 45/60 [6:01:21<1:34:41, 378.76s/trial, best loss: 8.132235107421875]\r 77%|███████▋  | 46/60 [6:01:21<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.5626856022498319, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0005328622257249861, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 77%|███████▋  | 46/60 [6:01:22<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 77%|███████▋  | 46/60 [6:01:22<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.636 Val loss 17.805\n",
      "\r 77%|███████▋  | 46/60 [6:01:25<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.638 Val loss 11.077\n",
      "\r 77%|███████▋  | 46/60 [6:01:50<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 188 best_val_loss 10.557\n",
      "\r 77%|███████▋  | 46/60 [6:02:16<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 77%|███████▋  | 46/60 [6:02:16<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.786 Val loss 16.893\n",
      "\r 77%|███████▋  | 46/60 [6:02:19<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.028 Val loss 10.304\n",
      "\r 77%|███████▋  | 46/60 [6:02:45<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 9.747\n",
      "\r 77%|███████▋  | 46/60 [6:03:10<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 77%|███████▋  | 46/60 [6:03:10<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.995 Val loss 16.792\n",
      "\r 77%|███████▋  | 46/60 [6:03:14<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 9.730 Val loss 10.684\n",
      "\r 77%|███████▋  | 46/60 [6:03:40<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 199 best_val_loss 10.198\n",
      "\r 77%|███████▋  | 46/60 [6:04:05<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 77%|███████▋  | 46/60 [6:04:05<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.694 Val loss 16.630\n",
      "\r 77%|███████▋  | 46/60 [6:04:09<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 8.932 Val loss 10.230\n",
      "\r 77%|███████▋  | 46/60 [6:04:32<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 194 best_val_loss 9.717\n",
      "\r 77%|███████▋  | 46/60 [6:04:57<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 77%|███████▋  | 46/60 [6:04:57<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.657 Val loss 17.227\n",
      "\r 77%|███████▋  | 46/60 [6:05:01<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 10.093 Val loss 11.140\n",
      "\r 77%|███████▋  | 46/60 [6:05:27<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 199 best_val_loss 10.685\n",
      "\r 77%|███████▋  | 46/60 [6:05:53<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 10.18080\n",
      "\n",
      "\r 77%|███████▋  | 46/60 [6:05:53<1:31:58, 394.15s/trial, best loss: 8.132235107421875]\r 78%|███████▊  | 47/60 [6:05:53<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.3228605068593864, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.00046590746358343075, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 78%|███████▊  | 47/60 [6:05:53<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 78%|███████▊  | 47/60 [6:05:53<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.689 Val loss 17.889\n",
      "\r 78%|███████▊  | 47/60 [6:05:56<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.417 Val loss 13.283\n",
      "\r 78%|███████▊  | 47/60 [6:06:29<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 10.135 Val loss 12.246\n",
      "\r 78%|███████▊  | 47/60 [6:07:05<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 231 best_val_loss 11.959\n",
      "\r 78%|███████▊  | 47/60 [6:07:28<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 78%|███████▊  | 47/60 [6:07:28<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.791 Val loss 17.216\n",
      "\r 78%|███████▊  | 47/60 [6:07:32<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.792 Val loss 13.166\n",
      "\r 78%|███████▊  | 47/60 [6:08:09<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 10.437 Val loss 11.937\n",
      "\r 78%|███████▊  | 47/60 [6:08:44<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 236 best_val_loss 11.373\n",
      "\r 78%|███████▊  | 47/60 [6:09:06<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 78%|███████▊  | 47/60 [6:09:06<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.782 Val loss 16.828\n",
      "\r 78%|███████▊  | 47/60 [6:09:10<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.219 Val loss 13.032\n",
      "\r 78%|███████▊  | 47/60 [6:09:42<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 106 best_val_loss 12.065\n",
      "\r 78%|███████▊  | 47/60 [6:09:53<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 78%|███████▊  | 47/60 [6:09:53<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.824 Val loss 16.636\n",
      "\r 78%|███████▊  | 47/60 [6:09:57<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.514 Val loss 12.874\n",
      "\r 78%|███████▊  | 47/60 [6:10:29<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 10.067 Val loss 12.184\n",
      "\r 78%|███████▊  | 47/60 [6:11:02<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 277 best_val_loss 11.750\n",
      "\r 78%|███████▊  | 47/60 [6:11:34<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 78%|███████▊  | 47/60 [6:11:34<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.647 Val loss 17.060\n",
      "\r 78%|███████▊  | 47/60 [6:11:38<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.563 Val loss 12.873\n",
      "\r 78%|███████▊  | 47/60 [6:12:10<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 9.839 Val loss 11.769\n",
      "\r 78%|███████▊  | 47/60 [6:12:43<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 247 best_val_loss 11.286\n",
      "\r 78%|███████▊  | 47/60 [6:13:08<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 11.68647\n",
      "\n",
      "\r 78%|███████▊  | 47/60 [6:13:08<1:17:24, 357.27s/trial, best loss: 8.132235107421875]\r 80%|████████  | 48/60 [6:13:08<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.4646151322179383, 'epochs': 200, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0008007303855946623, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 80%|████████  | 48/60 [6:13:08<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 80%|████████  | 48/60 [6:13:09<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.946 Val loss 17.546\n",
      "\r 80%|████████  | 48/60 [6:13:13<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 11.113 Val loss 11.792\n",
      "\r 80%|████████  | 48/60 [6:13:41<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 194 best_val_loss 11.137\n",
      "\r 80%|████████  | 48/60 [6:14:09<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 80%|████████  | 48/60 [6:14:09<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.242 Val loss 16.748\n",
      "\r 80%|████████  | 48/60 [6:14:12<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.079 Val loss 12.019\n",
      "\r 80%|████████  | 48/60 [6:14:41<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 177 best_val_loss 11.178\n",
      "\r 80%|████████  | 48/60 [6:15:09<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 80%|████████  | 48/60 [6:15:09<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.147 Val loss 16.688\n",
      "\r 80%|████████  | 48/60 [6:15:13<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.416 Val loss 12.339\n",
      "\r 80%|████████  | 48/60 [6:15:40<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 198 best_val_loss 11.821\n",
      "\r 80%|████████  | 48/60 [6:16:05<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 80%|████████  | 48/60 [6:16:05<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.531 Val loss 16.900\n",
      "\r 80%|████████  | 48/60 [6:16:08<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.464 Val loss 12.479\n",
      "\r 80%|████████  | 48/60 [6:16:35<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 199 best_val_loss 11.904\n",
      "\r 80%|████████  | 48/60 [6:17:02<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 80%|████████  | 48/60 [6:17:02<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 18.016 Val loss 17.096\n",
      "\r 80%|████████  | 48/60 [6:17:06<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 12.320 Val loss 12.444\n",
      "\r 80%|████████  | 48/60 [6:17:34<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 174 best_val_loss 11.911\n",
      "\r 80%|████████  | 48/60 [6:18:02<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 11.59011\n",
      "\n",
      "\r 80%|████████  | 48/60 [6:18:02<1:16:09, 380.82s/trial, best loss: 8.132235107421875]\r 82%|████████▏ | 49/60 [6:18:02<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 256, 'drop_ratio': 0.3888728572388678, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0009443364310387527, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 82%|████████▏ | 49/60 [6:18:02<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 82%|████████▏ | 49/60 [6:18:02<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.363 Val loss 17.773\n",
      "\r 82%|████████▏ | 49/60 [6:18:06<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.682 Val loss 9.183\n",
      "\r 82%|████████▏ | 49/60 [6:18:35<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 5.342 Val loss 8.848\n",
      "\r 82%|████████▏ | 49/60 [6:19:08<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 232 best_val_loss 8.733\n",
      "\r 82%|████████▏ | 49/60 [6:19:30<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 82%|████████▏ | 49/60 [6:19:30<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.636 Val loss 17.083\n",
      "\r 82%|████████▏ | 49/60 [6:19:33<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.136 Val loss 8.169\n",
      "\r 82%|████████▏ | 49/60 [6:20:07<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 7.818\n",
      "\r 82%|████████▏ | 49/60 [6:20:33<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 82%|████████▏ | 49/60 [6:20:33<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.759 Val loss 16.802\n",
      "\r 82%|████████▏ | 49/60 [6:20:36<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.422 Val loss 8.617\n",
      "\r 82%|████████▏ | 49/60 [6:21:11<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 5.129 Val loss 8.398\n",
      "\r 82%|████████▏ | 49/60 [6:21:43<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 259 best_val_loss 8.231\n",
      "\r 82%|████████▏ | 49/60 [6:22:13<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 82%|████████▏ | 49/60 [6:22:13<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.820 Val loss 16.602\n",
      "\r 82%|████████▏ | 49/60 [6:22:17<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.416 Val loss 8.970\n",
      "\r 82%|████████▏ | 49/60 [6:22:49<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 5.244 Val loss 8.435\n",
      "\r 82%|████████▏ | 49/60 [6:23:22<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 200 best_val_loss 8.435\n",
      "\r 82%|████████▏ | 49/60 [6:23:32<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 82%|████████▏ | 49/60 [6:23:33<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.538 Val loss 16.971\n",
      "\r 82%|████████▏ | 49/60 [6:23:36<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.821 Val loss 8.788\n",
      "\r 82%|████████▏ | 49/60 [6:24:08<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 200 Train loss 5.405 Val loss 8.844\n",
      "\r 82%|████████▏ | 49/60 [6:24:42<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 218 best_val_loss 8.510\n",
      "\r 82%|████████▏ | 49/60 [6:24:58<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.34522\n",
      "\n",
      "\r 82%|████████▏ | 49/60 [6:24:58<1:05:02, 354.74s/trial, best loss: 8.132235107421875]\r 83%|████████▎ | 50/60 [6:24:58<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \r{'batch_size': 128, 'drop_ratio': 0.3026600517599539, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0006415261676290615, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 83%|████████▎ | 50/60 [6:24:58<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 1/5\n",
      "\r 83%|████████▎ | 50/60 [6:24:58<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.446 Val loss 17.716\n",
      "\r 83%|████████▎ | 50/60 [6:25:02<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.225 Val loss 9.206\n",
      "\r 83%|████████▎ | 50/60 [6:25:53<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rStopped at epoch 196 best_val_loss 8.845\n",
      "\r 83%|████████▎ | 50/60 [6:26:44<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 2/5\n",
      "\r 83%|████████▎ | 50/60 [6:26:44<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.552 Val loss 17.029\n",
      "\r 83%|████████▎ | 50/60 [6:26:47<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.804 Val loss 8.258\n",
      "\r 83%|████████▎ | 50/60 [6:27:37<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 84 best_val_loss 8.127\n",
      "\r 83%|████████▎ | 50/60 [6:27:45<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 3/5\n",
      "\r 83%|████████▎ | 50/60 [6:27:45<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.630 Val loss 16.876\n",
      "\r 83%|████████▎ | 50/60 [6:27:49<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 6.293 Val loss 8.967\n",
      "\r 83%|████████▎ | 50/60 [6:28:38<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 153 best_val_loss 8.483\n",
      "\r 83%|████████▎ | 50/60 [6:29:21<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 4/5\n",
      "\r 83%|████████▎ | 50/60 [6:29:21<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.563 Val loss 16.628\n",
      "\r 83%|████████▎ | 50/60 [6:29:24<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 5.649 Val loss 8.990\n",
      "\r 83%|████████▎ | 50/60 [6:30:15<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 148 best_val_loss 8.663\n",
      "\r 83%|████████▎ | 50/60 [6:30:55<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rFold: 5/5\n",
      "\r 83%|████████▎ | 50/60 [6:30:55<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 0 Train loss 17.570 Val loss 17.596\n",
      "\r 83%|████████▎ | 50/60 [6:30:58<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEpoch 100 Train loss 7.057 Val loss 9.733\n",
      "\r 83%|████████▎ | 50/60 [6:31:48<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rEarly stopped at epoch 165 best_val_loss 9.208\n",
      "\r 83%|████████▎ | 50/60 [6:32:36<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r                                                                                     \rval MSE loss mean: 8.66535\n",
      "\n",
      "\r 83%|████████▎ | 50/60 [6:32:36<1:02:11, 373.15s/trial, best loss: 8.132235107421875]\r 85%|████████▌ | 51/60 [6:32:36<59:45, 398.36s/trial, best loss: 8.132235107421875]  \r                                                                                   \r{'batch_size': 128, 'drop_ratio': 0.13856204327949043, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0007286602452095279, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 85%|████████▌ | 51/60 [6:32:36<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 85%|████████▌ | 51/60 [6:32:36<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 19.067 Val loss 17.650\n",
      "\r 85%|████████▌ | 51/60 [6:32:40<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.405 Val loss 12.497\n",
      "\r 85%|████████▌ | 51/60 [6:33:11<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 10.126 Val loss 11.682\n",
      "\r 85%|████████▌ | 51/60 [6:33:42<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 276 best_val_loss 11.327\n",
      "\r 85%|████████▌ | 51/60 [6:34:10<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 85%|████████▌ | 51/60 [6:34:10<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 19.439 Val loss 16.938\n",
      "\r 85%|████████▌ | 51/60 [6:34:14<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.917 Val loss 11.717\n",
      "\r 85%|████████▌ | 51/60 [6:34:45<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 10.375 Val loss 11.099\n",
      "\r 85%|████████▌ | 51/60 [6:35:13<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 287 best_val_loss 10.703\n",
      "\r 85%|████████▌ | 51/60 [6:35:44<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 85%|████████▌ | 51/60 [6:35:44<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 19.476 Val loss 16.694\n",
      "\r 85%|████████▌ | 51/60 [6:35:47<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.156 Val loss 11.858\n",
      "\r 85%|████████▌ | 51/60 [6:36:15<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 9.762 Val loss 11.325\n",
      "\r 85%|████████▌ | 51/60 [6:36:42<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 294 best_val_loss 11.093\n",
      "\r 85%|████████▌ | 51/60 [6:37:10<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 85%|████████▌ | 51/60 [6:37:10<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 19.081 Val loss 16.663\n",
      "\r 85%|████████▌ | 51/60 [6:37:14<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.176 Val loss 12.350\n",
      "\r 85%|████████▌ | 51/60 [6:37:44<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 9.544 Val loss 11.360\n",
      "\r 85%|████████▌ | 51/60 [6:38:12<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 293 best_val_loss 11.014\n",
      "\r 85%|████████▌ | 51/60 [6:38:42<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 85%|████████▌ | 51/60 [6:38:42<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 18.831 Val loss 17.013\n",
      "\r 85%|████████▌ | 51/60 [6:38:45<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.000 Val loss 12.450\n",
      "\r 85%|████████▌ | 51/60 [6:39:15<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 9.645 Val loss 11.180\n",
      "\r 85%|████████▌ | 51/60 [6:39:45<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 272 best_val_loss 10.615\n",
      "\r 85%|████████▌ | 51/60 [6:40:16<59:45, 398.36s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 10.95049\n",
      "\n",
      "\r 85%|████████▌ | 51/60 [6:40:16<59:45, 398.36s/trial, best loss: 8.132235107421875]\r 87%|████████▋ | 52/60 [6:40:16<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 256, 'drop_ratio': 0.2581533305378223, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0005798193022482118, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 87%|████████▋ | 52/60 [6:40:16<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 87%|████████▋ | 52/60 [6:40:16<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.321 Val loss 17.651\n",
      "\r 87%|████████▋ | 52/60 [6:40:19<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.467 Val loss 9.111\n",
      "\r 87%|████████▋ | 52/60 [6:40:48<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 181 best_val_loss 8.667\n",
      "\r 87%|████████▋ | 52/60 [6:41:19<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 87%|████████▋ | 52/60 [6:41:19<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.475 Val loss 17.001\n",
      "\r 87%|████████▋ | 52/60 [6:41:23<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.758 Val loss 8.390\n",
      "\r 87%|████████▋ | 52/60 [6:41:51<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 180 best_val_loss 8.018\n",
      "\r 87%|████████▋ | 52/60 [6:42:23<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 87%|████████▋ | 52/60 [6:42:23<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.702 Val loss 16.843\n",
      "\r 87%|████████▋ | 52/60 [6:42:26<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.903 Val loss 8.797\n",
      "\r 87%|████████▋ | 52/60 [6:42:56<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 158 best_val_loss 8.310\n",
      "\r 87%|████████▋ | 52/60 [6:43:23<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 87%|████████▋ | 52/60 [6:43:23<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.525 Val loss 16.674\n",
      "\r 87%|████████▋ | 52/60 [6:43:26<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.810 Val loss 9.026\n",
      "\r 87%|████████▋ | 52/60 [6:43:56<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 167 best_val_loss 8.524\n",
      "\r 87%|████████▋ | 52/60 [6:44:27<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 87%|████████▋ | 52/60 [6:44:27<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.379 Val loss 17.006\n",
      "\r 87%|████████▋ | 52/60 [6:44:31<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 6.610 Val loss 9.307\n",
      "\r 87%|████████▋ | 52/60 [6:45:04<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 174 best_val_loss 8.789\n",
      "\r 87%|████████▋ | 52/60 [6:45:39<55:35, 416.90s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 8.46185\n",
      "\n",
      "\r 87%|████████▋ | 52/60 [6:45:39<55:35, 416.90s/trial, best loss: 8.132235107421875]\r 88%|████████▊ | 53/60 [6:45:39<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 128, 'drop_ratio': 0.1753856014498851, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0002669680607814525, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 88%|████████▊ | 53/60 [6:45:39<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 88%|████████▊ | 53/60 [6:45:39<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.352 Val loss 17.572\n",
      "\r 88%|████████▊ | 53/60 [6:45:43<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.924 Val loss 12.231\n",
      "\r 88%|████████▊ | 53/60 [6:46:19<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 199 best_val_loss 11.557\n",
      "\r 88%|████████▊ | 53/60 [6:46:56<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 88%|████████▊ | 53/60 [6:46:56<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.421 Val loss 16.808\n",
      "\r 88%|████████▊ | 53/60 [6:47:00<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.037 Val loss 11.159\n",
      "\r 88%|████████▊ | 53/60 [6:47:37<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 192 best_val_loss 10.392\n",
      "\r 88%|████████▊ | 53/60 [6:48:11<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 88%|████████▊ | 53/60 [6:48:11<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.591 Val loss 16.610\n",
      "\r 88%|████████▊ | 53/60 [6:48:15<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.925 Val loss 11.582\n",
      "\r 88%|████████▊ | 53/60 [6:48:50<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 193 best_val_loss 10.851\n",
      "\r 88%|████████▊ | 53/60 [6:49:22<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 88%|████████▊ | 53/60 [6:49:22<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.548 Val loss 16.552\n",
      "\r 88%|████████▊ | 53/60 [6:49:25<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.863 Val loss 12.226\n",
      "\r 88%|████████▊ | 53/60 [6:49:58<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 196 best_val_loss 11.351\n",
      "\r 88%|████████▊ | 53/60 [6:50:27<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 88%|████████▊ | 53/60 [6:50:27<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.435 Val loss 17.247\n",
      "\r 88%|████████▊ | 53/60 [6:50:31<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.834 Val loss 12.583\n",
      "\r 88%|████████▊ | 53/60 [6:51:07<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 169 best_val_loss 11.169\n",
      "\r 88%|████████▊ | 53/60 [6:51:41<45:21, 388.73s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 11.06402\n",
      "\n",
      "\r 88%|████████▊ | 53/60 [6:51:41<45:21, 388.73s/trial, best loss: 8.132235107421875]\r 90%|█████████ | 54/60 [6:51:41<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 128, 'drop_ratio': 0.12262554335209144, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0006955557000923638, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 90%|█████████ | 54/60 [6:51:41<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 90%|█████████ | 54/60 [6:51:41<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.156 Val loss 17.767\n",
      "\r 90%|█████████ | 54/60 [6:51:45<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.225 Val loss 9.377\n",
      "\r 90%|█████████ | 54/60 [6:52:31<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 4.070 Val loss 9.060\n",
      "\r 90%|█████████ | 54/60 [6:53:16<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 204 best_val_loss 8.870\n",
      "\r 90%|█████████ | 54/60 [6:53:32<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 90%|█████████ | 54/60 [6:53:32<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.446 Val loss 16.852\n",
      "\r 90%|█████████ | 54/60 [6:53:36<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.133 Val loss 8.569\n",
      "\r 90%|█████████ | 54/60 [6:54:20<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 3.958 Val loss 8.229\n",
      "\r 90%|█████████ | 54/60 [6:55:05<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 180 best_val_loss 8.090\n",
      "\r 90%|█████████ | 54/60 [6:55:10<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 90%|█████████ | 54/60 [6:55:10<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.279 Val loss 16.368\n",
      "\r 90%|█████████ | 54/60 [6:55:14<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.403 Val loss 8.877\n",
      "\r 90%|█████████ | 54/60 [6:56:00<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 147 best_val_loss 8.120\n",
      "\r 90%|█████████ | 54/60 [6:56:34<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 90%|█████████ | 54/60 [6:56:34<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.257 Val loss 16.447\n",
      "\r 90%|█████████ | 54/60 [6:56:38<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.151 Val loss 8.835\n",
      "\r 90%|█████████ | 54/60 [6:57:21<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 200 Train loss 4.018 Val loss 8.357\n",
      "\r 90%|█████████ | 54/60 [6:58:06<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 170 best_val_loss 8.356\n",
      "\r 90%|█████████ | 54/60 [6:58:06<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 90%|█████████ | 54/60 [6:58:06<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.172 Val loss 17.968\n",
      "\r 90%|█████████ | 54/60 [6:58:10<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 5.346 Val loss 9.635\n",
      "\r 90%|█████████ | 54/60 [6:58:55<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 113 best_val_loss 8.851\n",
      "\r 90%|█████████ | 54/60 [6:59:15<38:03, 380.64s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 8.45737\n",
      "\n",
      "\r 90%|█████████ | 54/60 [6:59:15<38:03, 380.64s/trial, best loss: 8.132235107421875]\r 92%|█████████▏| 55/60 [6:59:15<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 128, 'drop_ratio': 0.18643873637713154, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0008251567894570764, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 92%|█████████▏| 55/60 [6:59:15<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 92%|█████████▏| 55/60 [6:59:15<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.114 Val loss 17.531\n",
      "\r 92%|█████████▏| 55/60 [6:59:19<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.893 Val loss 8.646\n",
      "\r 92%|█████████▏| 55/60 [7:00:11<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 149 best_val_loss 8.459\n",
      "\r 92%|█████████▏| 55/60 [7:00:54<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 92%|█████████▏| 55/60 [7:00:54<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.440 Val loss 16.972\n",
      "\r 92%|█████████▏| 55/60 [7:00:58<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.738 Val loss 8.171\n",
      "\r 92%|█████████▏| 55/60 [7:01:51<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 142 best_val_loss 7.786\n",
      "\r 92%|█████████▏| 55/60 [7:02:32<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 92%|█████████▏| 55/60 [7:02:32<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.299 Val loss 16.493\n",
      "\r 92%|█████████▏| 55/60 [7:02:36<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.427 Val loss 8.220\n",
      "\r 92%|█████████▏| 55/60 [7:03:28<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 132 best_val_loss 8.014\n",
      "\r 92%|█████████▏| 55/60 [7:03:54<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 92%|█████████▏| 55/60 [7:03:54<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.427 Val loss 16.715\n",
      "\r 92%|█████████▏| 55/60 [7:03:58<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.959 Val loss 8.716\n",
      "\r 92%|█████████▏| 55/60 [7:04:50<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 130 best_val_loss 8.282\n",
      "\r 92%|█████████▏| 55/60 [7:05:22<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 92%|█████████▏| 55/60 [7:05:22<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.225 Val loss 17.321\n",
      "\r 92%|█████████▏| 55/60 [7:05:25<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.662 Val loss 8.545\n",
      "\r 92%|█████████▏| 55/60 [7:06:18<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 112 best_val_loss 8.134\n",
      "\r 92%|█████████▏| 55/60 [7:06:41<33:34, 402.81s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 8.13503\n",
      "\n",
      "\r 92%|█████████▏| 55/60 [7:06:41<33:34, 402.81s/trial, best loss: 8.132235107421875]\r 93%|█████████▎| 56/60 [7:06:41<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 256, 'drop_ratio': 0.18980864153593657, 'epochs': 200, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.000998808363662253, 'lrf': 0.01, 'num_filters': (32,)}\n",
      "\r 93%|█████████▎| 56/60 [7:06:41<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 93%|█████████▎| 56/60 [7:06:41<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.919 Val loss 17.610\n",
      "\r 93%|█████████▎| 56/60 [7:06:45<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 11.086 Val loss 12.577\n",
      "\r 93%|█████████▎| 56/60 [7:07:08<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 165 best_val_loss 11.685\n",
      "\r 93%|█████████▎| 56/60 [7:07:30<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 93%|█████████▎| 56/60 [7:07:30<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.819 Val loss 16.891\n",
      "\r 93%|█████████▎| 56/60 [7:07:34<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.061 Val loss 11.415\n",
      "\r 93%|█████████▎| 56/60 [7:07:55<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 174 best_val_loss 10.433\n",
      "\r 93%|█████████▎| 56/60 [7:08:18<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 93%|█████████▎| 56/60 [7:08:18<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 18.039 Val loss 16.778\n",
      "\r 93%|█████████▎| 56/60 [7:08:21<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.552 Val loss 11.891\n",
      "\r 93%|█████████▎| 56/60 [7:08:44<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 175 best_val_loss 11.151\n",
      "\r 93%|█████████▎| 56/60 [7:09:06<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 93%|█████████▎| 56/60 [7:09:06<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.843 Val loss 16.468\n",
      "\r 93%|█████████▎| 56/60 [7:09:10<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 10.089 Val loss 12.042\n",
      "\r 93%|█████████▎| 56/60 [7:09:32<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 172 best_val_loss 10.969\n",
      "\r 93%|█████████▎| 56/60 [7:09:54<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 93%|█████████▎| 56/60 [7:09:54<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.761 Val loss 17.107\n",
      "\r 93%|█████████▎| 56/60 [7:09:58<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 8.994 Val loss 10.848\n",
      "\r 93%|█████████▎| 56/60 [7:10:19<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rStopped at epoch 173 best_val_loss 10.380\n",
      "\r 93%|█████████▎| 56/60 [7:10:42<27:43, 415.77s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 10.92371\n",
      "\n",
      "\r 93%|█████████▎| 56/60 [7:10:42<27:43, 415.77s/trial, best loss: 8.132235107421875]\r 95%|█████████▌| 57/60 [7:10:42<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \r{'batch_size': 128, 'drop_ratio': 0.15885304762193142, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0008241914200557523, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 95%|█████████▌| 57/60 [7:10:42<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 1/5\n",
      "\r 95%|█████████▌| 57/60 [7:10:42<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.087 Val loss 17.483\n",
      "\r 95%|█████████▌| 57/60 [7:10:46<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.446 Val loss 8.922\n",
      "\r 95%|█████████▌| 57/60 [7:11:39<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 123 best_val_loss 8.376\n",
      "\r 95%|█████████▌| 57/60 [7:12:07<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 2/5\n",
      "\r 95%|█████████▌| 57/60 [7:12:07<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.422 Val loss 16.905\n",
      "\r 95%|█████████▌| 57/60 [7:12:11<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.709 Val loss 8.135\n",
      "\r 95%|█████████▌| 57/60 [7:13:05<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 80 best_val_loss 8.049\n",
      "\r 95%|█████████▌| 57/60 [7:13:11<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 3/5\n",
      "\r 95%|█████████▌| 57/60 [7:13:11<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.295 Val loss 16.492\n",
      "\r 95%|█████████▌| 57/60 [7:13:15<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.470 Val loss 8.260\n",
      "\r 95%|█████████▌| 57/60 [7:14:03<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 140 best_val_loss 7.965\n",
      "\r 95%|█████████▌| 57/60 [7:14:29<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 4/5\n",
      "\r 95%|█████████▌| 57/60 [7:14:29<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.399 Val loss 16.678\n",
      "\r 95%|█████████▌| 57/60 [7:14:33<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.352 Val loss 8.552\n",
      "\r 95%|█████████▌| 57/60 [7:15:21<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 140 best_val_loss 8.157\n",
      "\r 95%|█████████▌| 57/60 [7:16:01<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rFold: 5/5\n",
      "\r 95%|█████████▌| 57/60 [7:16:01<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 0 Train loss 17.243 Val loss 17.359\n",
      "\r 95%|█████████▌| 57/60 [7:16:05<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEpoch 100 Train loss 4.378 Val loss 8.389\n",
      "\r 95%|█████████▌| 57/60 [7:16:59<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rEarly stopped at epoch 138 best_val_loss 8.092\n",
      "\r 95%|█████████▌| 57/60 [7:17:37<18:09, 363.31s/trial, best loss: 8.132235107421875]\r                                                                                   \rval MSE loss mean: 8.12765\n",
      "\n",
      "\r 95%|█████████▌| 57/60 [7:17:37<18:09, 363.31s/trial, best loss: 8.132235107421875]\r 97%|█████████▋| 58/60 [7:17:37<12:37, 378.96s/trial, best loss: 8.12765087890625] \r                                                                                  \r{'batch_size': 128, 'drop_ratio': 0.22496847881870113, 'epochs': 300, 'fc_unit': (64,), 'kernel_size': 5, 'lr': 0.0009225730341536689, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\r 97%|█████████▋| 58/60 [7:17:38<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 1/5\n",
      "\r 97%|█████████▋| 58/60 [7:17:38<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.156 Val loss 17.845\n",
      "\r 97%|█████████▋| 58/60 [7:17:41<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 5.752 Val loss 9.474\n",
      "\r 97%|█████████▋| 58/60 [7:18:26<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 119 best_val_loss 8.978\n",
      "\r 97%|█████████▋| 58/60 [7:18:49<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 2/5\n",
      "\r 97%|█████████▋| 58/60 [7:18:49<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.406 Val loss 16.889\n",
      "\r 97%|█████████▋| 58/60 [7:18:52<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 5.730 Val loss 8.476\n",
      "\r 97%|█████████▋| 58/60 [7:19:30<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 106 best_val_loss 8.158\n",
      "\r 97%|█████████▋| 58/60 [7:19:46<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 3/5\n",
      "\r 97%|█████████▋| 58/60 [7:19:46<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.329 Val loss 16.354\n",
      "\r 97%|█████████▋| 58/60 [7:19:50<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 6.027 Val loss 8.770\n",
      "\r 97%|█████████▋| 58/60 [7:20:36<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 137 best_val_loss 8.612\n",
      "\r 97%|█████████▋| 58/60 [7:21:06<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 4/5\n",
      "\r 97%|█████████▋| 58/60 [7:21:06<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.328 Val loss 16.378\n",
      "\r 97%|█████████▋| 58/60 [7:21:10<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 5.344 Val loss 8.558\n",
      "\r 97%|█████████▋| 58/60 [7:21:55<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 4.399 Val loss 8.141\n",
      "\r 97%|█████████▋| 58/60 [7:22:40<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 232 best_val_loss 8.010\n",
      "\r 97%|█████████▋| 58/60 [7:23:10<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 5/5\n",
      "\r 97%|█████████▋| 58/60 [7:23:10<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.240 Val loss 17.777\n",
      "\r 97%|█████████▋| 58/60 [7:23:13<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 6.372 Val loss 9.219\n",
      "\r 97%|█████████▋| 58/60 [7:23:58<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 153 best_val_loss 8.541\n",
      "\r 97%|█████████▋| 58/60 [7:24:37<12:37, 378.96s/trial, best loss: 8.12765087890625]\r                                                                                  \rval MSE loss mean: 8.45959\n",
      "\n",
      "\r 97%|█████████▋| 58/60 [7:24:37<12:37, 378.96s/trial, best loss: 8.12765087890625]\r 98%|█████████▊| 59/60 [7:24:37<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \r{'batch_size': 128, 'drop_ratio': 0.16627586303850542, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 3, 'lr': 0.0008771451902190724, 'lrf': 0.01, 'num_filters': (16,)}\n",
      "\r 98%|█████████▊| 59/60 [7:24:37<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 1/5\n",
      "\r 98%|█████████▊| 59/60 [7:24:37<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.298 Val loss 17.412\n",
      "\r 98%|█████████▊| 59/60 [7:24:40<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 8.945 Val loss 11.229\n",
      "\r 98%|█████████▊| 59/60 [7:25:16<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 7.438 Val loss 10.055\n",
      "\r 98%|█████████▊| 59/60 [7:25:48<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rStopped at epoch 271 best_val_loss 9.790\n",
      "\r 98%|█████████▊| 59/60 [7:26:19<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 2/5\n",
      "\r 98%|█████████▊| 59/60 [7:26:19<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.537 Val loss 16.943\n",
      "\r 98%|█████████▊| 59/60 [7:26:22<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 9.658 Val loss 10.819\n",
      "\r 98%|█████████▊| 59/60 [7:26:55<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 8.115 Val loss 9.988\n",
      "\r 98%|█████████▊| 59/60 [7:27:29<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rStopped at epoch 275 best_val_loss 9.779\n",
      "\r 98%|█████████▊| 59/60 [7:28:03<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 3/5\n",
      "\r 98%|█████████▊| 59/60 [7:28:03<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.561 Val loss 16.567\n",
      "\r 98%|█████████▊| 59/60 [7:28:07<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 8.576 Val loss 10.018\n",
      "\r 98%|█████████▊| 59/60 [7:28:39<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 6.646 Val loss 9.228\n",
      "\r 98%|█████████▊| 59/60 [7:29:12<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEarly stopped at epoch 258 best_val_loss 8.974\n",
      "\r 98%|█████████▊| 59/60 [7:29:46<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 4/5\n",
      "\r 98%|█████████▊| 59/60 [7:29:46<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.591 Val loss 16.519\n",
      "\r 98%|█████████▊| 59/60 [7:29:49<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 9.904 Val loss 11.302\n",
      "\r 98%|█████████▊| 59/60 [7:30:22<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 7.769 Val loss 10.177\n",
      "\r 98%|█████████▊| 59/60 [7:30:54<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rStopped at epoch 290 best_val_loss 9.992\n",
      "\r 98%|█████████▊| 59/60 [7:31:28<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rFold: 5/5\n",
      "\r 98%|█████████▊| 59/60 [7:31:28<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 0 Train loss 17.354 Val loss 17.086\n",
      "\r 98%|█████████▊| 59/60 [7:31:31<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 100 Train loss 10.579 Val loss 11.748\n",
      "\r 98%|█████████▊| 59/60 [7:32:04<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rEpoch 200 Train loss 8.684 Val loss 10.462\n",
      "\r 98%|█████████▊| 59/60 [7:32:42<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rStopped at epoch 297 best_val_loss 10.180\n",
      "\r 98%|█████████▊| 59/60 [7:33:16<06:31, 391.08s/trial, best loss: 8.12765087890625]\r                                                                                  \rval MSE loss mean: 9.74308\n",
      "\n",
      "\r 98%|█████████▊| 59/60 [7:33:16<06:31, 391.08s/trial, best loss: 8.12765087890625]\r100%|██████████| 60/60 [7:33:16<00:00, 429.52s/trial, best loss: 8.12765087890625]\r100%|██████████| 60/60 [7:33:16<00:00, 453.28s/trial, best loss: 8.12765087890625]\n",
      "Best params:{'batch_size': 128, 'drop_ratio': 0.15885304762193142, 'epochs': 300, 'fc_unit': (128, 64), 'kernel_size': 5, 'lr': 0.0008241914200557523, 'lrf': 0.01, 'num_filters': (16, 32)}\n",
      "\n",
      "Fold: 1/5\n",
      "[Epoch 0 fold 1 logkcatkm] Train loss 17.083 Val loss 17.501\n",
      "[Epoch 50 fold 1 logkcatkm] Train loss 5.638 Val loss 9.566\n",
      "[Epoch 100 fold 1 logkcatkm] Train loss 4.234 Val loss 8.681\n",
      "Early stopped at epoch 117 best_val_loss 8.387\n",
      "Fold: 2/5\n",
      "[Epoch 0 fold 2 logkcatkm] Train loss 17.424 Val loss 16.903\n",
      "[Epoch 50 fold 2 logkcatkm] Train loss 6.309 Val loss 8.483\n",
      "[Epoch 100 fold 2 logkcatkm] Train loss 4.836 Val loss 8.056\n",
      "Early stopped at epoch 92 best_val_loss 7.915\n",
      "Fold: 3/5\n",
      "[Epoch 0 fold 3 logkcatkm] Train loss 17.296 Val loss 16.497\n",
      "[Epoch 50 fold 3 logkcatkm] Train loss 5.566 Val loss 8.563\n",
      "[Epoch 100 fold 3 logkcatkm] Train loss 4.265 Val loss 8.199\n",
      "Early stopped at epoch 102 best_val_loss 7.957\n",
      "Fold: 4/5\n",
      "[Epoch 0 fold 4 logkcatkm] Train loss 17.409 Val loss 16.687\n",
      "[Epoch 50 fold 4 logkcatkm] Train loss 5.766 Val loss 9.198\n",
      "[Epoch 100 fold 4 logkcatkm] Train loss 4.415 Val loss 8.454\n",
      "[Epoch 150 fold 4 logkcatkm] Train loss 3.950 Val loss 8.287\n",
      "Early stopped at epoch 126 best_val_loss 8.232\n",
      "Fold: 5/5\n",
      "[Epoch 0 fold 5 logkcatkm] Train loss 17.243 Val loss 17.393\n",
      "[Epoch 50 fold 5 logkcatkm] Train loss 6.218 Val loss 9.001\n",
      "[Epoch 100 fold 5 logkcatkm] Train loss 4.702 Val loss 8.469\n",
      "[Epoch 150 fold 5 logkcatkm] Train loss 4.119 Val loss 8.175\n",
      "Early stopped at epoch 129 best_val_loss 8.113\n",
      "Dimension of x: 1328\n",
      "[Val] rmse 2.8746 mae 2.0876 r2 0.5212 pcc 0.7282 [Test] rmse 2.9381 mae 2.1166 r2 0.4930 pcc 0.7097\n",
      "\n",
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval  # 超参数搜索\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchsummary import summary\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension=1, kernel_size_list=[3, 3], filters_list=[16, 32], fc_unit=[128], drop_ratio=0.5, activation=nn.ReLU):\n",
    "        super(CNN1d, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 1  # Since input_dimension is (batch_size, input_dimension), we treat it as a single channel sequence\n",
    "        for i, filters in enumerate(filters_list):\n",
    "            kernel_size = kernel_size_list[i]\n",
    "            padding = (kernel_size - 1) // 2  # Calculate padding to maintain the same size\n",
    "            out_channels = filters\n",
    "            self.conv_layers.append(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.relu = activation()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Compute the dimension of the feature map after the convolutional layers and pooling\n",
    "        feature_map_dimension = input_dimension // (2 ** len(filters_list))\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.drop = nn.Dropout(p=drop_ratio)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        in_features = filters_list[-1] * feature_map_dimension\n",
    "        for units in fc_unit:\n",
    "            self.fc_layers.append(nn.Linear(in_features, units))\n",
    "            self.fc_layers.append(self.relu)\n",
    "            self.fc_layers.append(self.drop)  # Add Dropout after each fully connected layer\n",
    "            in_features = units\n",
    "\n",
    "        self.fc_layers.append(nn.Linear(in_features, output_dimension))\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            x = x.unsqueeze(1)  # Add a channel dimension: (batch_size, 1, input_dimension)\n",
    "\n",
    "            for conv in self.conv_layers:\n",
    "                x = self.pool(self.relu(conv(x)))\n",
    "\n",
    "            x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "\n",
    "            for layer in self.fc_layers:\n",
    "                x = layer(x)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    y_true = np.array(y_true).ravel()\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "\n",
    "def return_data_loader(x, y, batch_size, shuffle=True, seed=66):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    x = torch.FloatTensor(x)\n",
    "    y = torch.FloatTensor(y)\n",
    "    label_loader = Data.DataLoader(Data.TensorDataset(x, y), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return label_loader\n",
    "\n",
    "def return_x_y(df_filtered):\n",
    "    y = df_filtered[label_name].values\n",
    "    mask = ~np.isnan(y)\n",
    "\n",
    "    # factors\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_filtered['ph'].values.reshape(-1, 1)\n",
    "        t = df_filtered['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_filtered['mw'].values.reshape(-1, 1)\n",
    "        logp = df_filtered['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_filtered[protein_column].tolist())\n",
    "    substrate_data = np.array(df_filtered[substrate_column].tolist())\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    accu_loss_train = torch.zeros(1).to(device)  # 累计损失\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        data, label_value = data[0].to(device), data[1].to(device)\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = loss_function(pred.float().squeeze(), label_value.float())\n",
    "        loss.backward()\n",
    "        accu_loss_train += loss.detach()\n",
    "\n",
    "        # 在更新权重之前，对梯度进行裁剪，使其不超过clip_value\n",
    "        torch.nn.utils.clip_grad_value_([p for p in model.parameters() if p.requires_grad], clip_value=clip_value)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return accu_loss_train.item() / (step + 1), model\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, mode='search'):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_function = torch.nn.MSELoss()\n",
    "        accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "\n",
    "        for step, data in enumerate(data_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_function(outputs.float().squeeze(), labels.float())\n",
    "            accu_loss += loss.detach()\n",
    "\n",
    "            if mode != 'search':\n",
    "                all_pred.extend(outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    torch.cuda.empty_cache()  # 清理未使用的缓存\n",
    "\n",
    "    if mode == 'search':\n",
    "        return accu_loss.item() / len(data_loader)  # 返回平均损失\n",
    "\n",
    "    else:\n",
    "        return all_pred, all_labels\n",
    "\n",
    "\n",
    "def search_model(params, train_x, train_y, val_x, val_y):\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = CNN1d(\n",
    "        input_dimension=len(train_x[0]),\n",
    "        output_dimension=1,\n",
    "        kernel_size_list=[params['kernel_size'] for i in range(len(params['num_filters']))],  # [3, 3]\n",
    "        filters_list=params['num_filters'],  # [16, 32]\n",
    "        fc_unit=params['fc_unit'],  # [128]\n",
    "        drop_ratio=params['drop_ratio']\n",
    "        ).to(device)\n",
    "\n",
    "    # # 打印模型结构\n",
    "    # summary(model, input_size=(len(train_x[0]),))  # input_size 是输入数据的形状\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums = 0, 0\n",
    "\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        # train\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "        if epoch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch_idx} Train loss {train_loss:.3f} Val loss {val_loss:.3f}')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            break\n",
    "\n",
    "    # print Log\n",
    "    if patience_nums > patience:\n",
    "        print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "    else:\n",
    "        print(f'Stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "\n",
    "def _search_params(params):\n",
    "    print(params)\n",
    "    val_loss_list = []\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "        print(f\"Fold: {fold_idx}/5\")\n",
    "        df_train = df_train_val.iloc[train_index]\n",
    "        df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "        train_x, train_y = return_x_y(df_train)\n",
    "        val_x, val_y = return_x_y(df_val)\n",
    "\n",
    "        val_loss = search_model(params, train_x, train_y, val_x, val_y)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    val_loss_mean = np.mean(val_loss_list, axis=0)\n",
    "    print(f\"val MSE loss mean: {val_loss_mean:.5f}\\n\")\n",
    "\n",
    "    return val_loss_mean\n",
    "\n",
    "\n",
    "def search_best_param(max_evals):\n",
    "    space = {\n",
    "        'lr': hp.uniform('lr', 1e-4, 1e-3),\n",
    "        'lrf': hp.choice('lrf', [0.01]),\n",
    "        'drop_ratio': hp.uniform('drop_ratio', 0.1, 0.6),\n",
    "        'kernel_size': hp.choice('kernel_size', [3, 5]),\n",
    "        'fc_unit': hp.choice('fc_unit', [(64,), (128, 64)]),\n",
    "        'num_filters': hp.choice('num_filters', [(16, 32), (16,), (32,)]),\n",
    "        'batch_size': hp.choice('batch_size', [128, 256]),\n",
    "        'epochs': hp.choice('epochs', [200, 300]),\n",
    "    }\n",
    "\n",
    "    trials = Trials()\n",
    "    print(f'[Info] Starting parameter search with MSE_Loss...')\n",
    "    best_params = fmin(fn=_search_params, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "    best_params = space_eval(space, best_params)\n",
    "\n",
    "    # Save the best params to JSON\n",
    "    with open(params_json_path, 'w') as json_file:\n",
    "        json.dump(best_params, json_file)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device: {device}\")\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "search_max_evals = 60\n",
    "patience = 30\n",
    "clip_value = 0.8\n",
    "\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'cnn1d'\n",
    "label_name = 'logkcatkm'\n",
    "\n",
    "df_input = pd.read_pickle(f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl')\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "params_json_path = f'{current_dir}/model_dict/{input_model}_params.json'\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path) as json_file:\n",
    "        params = json.load(json_file)\n",
    "else:\n",
    "    params = search_best_param(search_max_evals)\n",
    "\n",
    "print(f'Best params:{params}\\n')\n",
    "\n",
    "# Train\n",
    "val_scores_list, test_scores_list = [], []\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "    print(f\"Fold: {fold_idx}/5\")\n",
    "    df_train = df_train_val.iloc[train_index]\n",
    "    df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "    train_x, train_y = return_x_y(df_train)\n",
    "    val_x, val_y = return_x_y(df_val)\n",
    "    test_x, test_y = return_x_y(df_test)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "    test_loader = return_data_loader(test_x, test_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = CNN1d(\n",
    "        input_dimension=len(train_x[0]),\n",
    "        output_dimension=1,\n",
    "        kernel_size_list=[params['kernel_size'] for i in range(len(params['num_filters']))],  # [3, 3]\n",
    "        filters_list=params['num_filters'],  # [16, 32]\n",
    "        fc_unit=params['fc_unit'],  # [128]\n",
    "        drop_ratio=params['drop_ratio']\n",
    "    ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums, best_model = 0, 0, None\n",
    "\n",
    "    # train\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_model = model\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "            break\n",
    "        if epoch_idx % 50 == 0:\n",
    "            print(f\"[Epoch {epoch_idx} fold {fold_idx} {label_name}] Train loss {train_loss:.3f} Val loss {val_loss:.3f}\")\n",
    "\n",
    "    val_pred, val_labels = evaluate_model(best_model, val_loader, mode='val')\n",
    "    test_pred, test_labels = evaluate_model(best_model, test_loader, mode='test')\n",
    "\n",
    "    # scores\n",
    "    val_scores = return_scores(val_labels, val_pred)\n",
    "    test_scores = return_scores(test_labels, test_pred)\n",
    "    val_scores_list.append(val_scores)\n",
    "    test_scores_list.append(test_scores)\n",
    "\n",
    "    # fold\n",
    "    fold_results.append([\n",
    "        fold_idx,\n",
    "        val_scores[0], val_scores[1], val_scores[2], val_scores[3],\n",
    "        test_scores[0], test_scores[1], test_scores[2], test_scores[3]\n",
    "    ])\n",
    "\n",
    "# mean\n",
    "val_scores_mean = np.mean(val_scores_list, axis=0)\n",
    "test_scores_mean = np.mean(test_scores_list, axis=0)\n",
    "\n",
    "print(f\"Dimension of x: {train_x.shape[1]}\")\n",
    "print(f\"[Val] rmse {val_scores_mean[0]:.4f} mae {val_scores_mean[1]:.4f} r2 {val_scores_mean[2]:.4f} pcc {val_scores_mean[3]:.4f} \"\n",
    "      f\"[Test] rmse {test_scores_mean[0]:.4f} mae {test_scores_mean[1]:.4f} r2 {test_scores_mean[2]:.4f} pcc {test_scores_mean[3]:.4f}\\n\")\n",
    "\n",
    "# save cvs\n",
    "df_cv_results = pd.DataFrame(fold_results, columns=[\n",
    "    \"Fold\",\n",
    "    \"Val_RMSE\", \"Val_MAE\", \"Val_R2\", \"Val_PCC\",\n",
    "    \"Test_RMSE\", \"Test_MAE\", \"Test_R2\", \"Test_PCC\"])\n",
    "df_cv_results.to_excel(f\"{current_dir}/results/{input_model}_cv_results.xlsx\", index=False)\n",
    "print(\"Results saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynoMTGBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db0e6cebfd42dbe7de32cf1b0daf517db5c30eda4a99fad3eb7c5d8b4a7bde0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
