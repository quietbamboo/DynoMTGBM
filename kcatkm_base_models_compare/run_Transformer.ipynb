{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2486c8e-efe9-4aa5-b0ec-19c5108d472d",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c4d3ad-4417-4186-a7c6-783cc5ecfb27",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e37d13a-853b-46a5-bbfd-72d9e062aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda/envs/DynoMTGBM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math, os\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "class TransformerKP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list=[1024, 256], encoder_dim_list=[(8, 32), (1, 64)],\n",
    "                 drop_ratio=0.12, norm_fun='batch_norm',\n",
    "                 act_fun='gelu', encoder_with_res=False, encoder_norm=None,\n",
    "                 encoder_drop_ratio=0.0, num_heads=1, residual_coef=1.0, device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")):\n",
    "        super(TransformerKP, self).__init__()\n",
    "\n",
    "        # fc blocks\n",
    "        self.fc_layers = FCBlock(input_dim, hidden_dim_list, norm_fun, act_fun, drop_ratio)\n",
    "\n",
    "        # encoder layers\n",
    "        self.encoder_layers = TransformerBlock(hidden_dim_list, encoder_dim_list, drop_ratio, norm_fun,\n",
    "                 act_fun, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef)\n",
    "\n",
    "        self.output_layer = nn.Linear(encoder_dim_list[-1][0] * encoder_dim_list[-1][1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list, norm_fun, act_fun, drop_ratio):\n",
    "        super(FCBlock, self).__init__()\n",
    "\n",
    "        self.act = nn.GELU() if act_fun == 'gelu' else nn.ReLU()\n",
    "\n",
    "        if norm_fun == 'batch_norm':\n",
    "            self.norm_fc = nn.ModuleList(nn.BatchNorm1d(dim) for dim in hidden_dim_list[1:])\n",
    "        elif norm_fun == 'layer_norm':\n",
    "            self.norm_fc = nn.ModuleList(nn.LayerNorm(dim) for dim in hidden_dim_list[1:])\n",
    "        else:\n",
    "            self.norm_fc = nn.ModuleList(nn.Identity() for dim in hidden_dim_list[1:])\n",
    "\n",
    "        # self.norm_fc = nn.ModuleList([nn.BatchNorm1d(dim) if norm_fun == 'batch_norm' else nn.LayerNorm(dim) for dim in hidden_dim_list[1:]])\n",
    "        self.drop = nn.Dropout(p=drop_ratio)\n",
    "\n",
    "        # fc blocks\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_layers.append(nn.Linear(input_dim, hidden_dim_list[0]))\n",
    "\n",
    "        self.norm_fcs = nn.ModuleList()\n",
    "\n",
    "        for idx in range(len(hidden_dim_list) - 1):\n",
    "            self.fc_layers.append(nn.Linear(hidden_dim_list[idx], hidden_dim_list[idx + 1]))\n",
    "            self.norm_fcs.append(self.norm_fc[idx])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.act(self.fc_layers[0](x)))\n",
    "\n",
    "        for fc_layer, norm in zip(self.fc_layers[1:], self.norm_fcs):\n",
    "            x = self.drop(norm(self.act(fc_layer(x))))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim_list, encoder_dim_list, drop_ratio, norm_fun,\n",
    "                 act_fun, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.act = return_act_fun(act_fun)\n",
    "\n",
    "\n",
    "        self.drop = nn.Dropout(p=drop_ratio)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "        encoder_dim = hidden_dim_list[-1]  # 256\n",
    "        for _num, _encoder_dim in encoder_dim_list:  # [(8, 32), (1, 64)]\n",
    "            if norm_fun == 'batch_norm':\n",
    "                self.norm_fun = nn.BatchNorm1d(_num * _encoder_dim)\n",
    "            elif norm_fun == 'layer_norm':\n",
    "                self.norm_fun = nn.LayerNorm(_num * _encoder_dim)\n",
    "            else:\n",
    "                self.norm_fun = nn.Identity()\n",
    "\n",
    "            linear_ = nn.Sequential(\n",
    "                nn.Linear(encoder_dim, _num * _encoder_dim),  # (8, 32)\n",
    "                self.act,\n",
    "                self.norm_fun,\n",
    "                self.drop,\n",
    "            )\n",
    "            encoder_dim = _num * _encoder_dim\n",
    "            reshape_layer = ReshapeLayer(_num, _encoder_dim)\n",
    "            attention_ = SelfAttention(_encoder_dim, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef)\n",
    "            flatten1_ = nn.Flatten()\n",
    "\n",
    "            self.encoder_layers.append(linear_)\n",
    "            self.encoder_layers.append(reshape_layer)\n",
    "            self.encoder_layers.append(attention_)\n",
    "            self.encoder_layers.append(flatten1_)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def return_act_fun(name):\n",
    "    if name == 'silu':\n",
    "        return nn.SiLU()\n",
    "    elif name == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'gelu':\n",
    "        return nn.GELU()\n",
    "    elif name == 'lrelu':\n",
    "        return nn.LeakyReLU(negative_slope=0.01)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation function: {name}\")\n",
    "\n",
    "\n",
    "class ReshapeLayer(nn.Module):\n",
    "    def __init__(self, num, dim):\n",
    "        super(ReshapeLayer, self).__init__()\n",
    "        self.num = num\n",
    "        self.dim = dim\n",
    "\n",
    "    # @autocast(True)\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), self.num, self.dim)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, output_dim, encoder_with_res=False, encoder_norm=None, encoder_drop_ratio=0.0, num_heads=1, residual_coef=1.0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.encoder_with_res = encoder_with_res\n",
    "        self.residual_coef = residual_coef\n",
    "        self.num_heads = num_heads\n",
    "        self.encoder_norm = nn.LayerNorm(output_dim) if encoder_norm else None\n",
    "        self.dropout = nn.Dropout(p=encoder_drop_ratio) if encoder_drop_ratio > 0 else None\n",
    "\n",
    "        head_dim = output_dim // num_heads\n",
    "        assert head_dim * num_heads == output_dim, \"output_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Define the weights\n",
    "        self.WQ = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.WK = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.WV = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.WQ)\n",
    "        nn.init.xavier_uniform_(self.WK)\n",
    "        nn.init.xavier_uniform_(self.WV)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "\n",
    "        # Linear projections\n",
    "        Q = torch.matmul(x, self.WQ).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "        K = torch.matmul(x, self.WK).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "        V = torch.matmul(x, self.WV).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        QK = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.output_dim // self.num_heads)\n",
    "        QK = F.softmax(QK, dim=-1)\n",
    "\n",
    "        output = torch.matmul(QK, V).permute(0, 2, 1, 3).contiguous().view(batch_size, seq_length, self.output_dim)\n",
    "\n",
    "        # Apply dropout if specified\n",
    "        if self.dropout:\n",
    "            output = self.dropout(output)\n",
    "\n",
    "        # Apply normalization if specified\n",
    "        if self.encoder_norm:\n",
    "            output = self.encoder_norm(output)\n",
    "\n",
    "        # Add residual connection if specified\n",
    "        if self.encoder_with_res:\n",
    "            output = output + self.residual_coef * x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e75a0c-f3cc-4d84-bc09-b5715d797a54",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8060bcc0-4ea0-4475-a2e6-450b257c112b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Starting parameter search with MSE_Loss...\n",
      "  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.17175376482442656, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.4277067000542414, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0008343603673047218, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.7753877506491463}\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rFold: 1/5\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 21.174 Val loss 21.857\n",
      "\r  0%|          | 0/60 [00:07<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 8.718 Val loss 10.694\n",
      "\r  0%|          | 0/60 [01:22<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 6.777 Val loss 9.765\n",
      "\r  0%|          | 0/60 [02:35<?, ?trial/s, best loss=?]\r                                                      \rStopped at epoch 294 best_val_loss 9.293\n",
      "\r  0%|          | 0/60 [03:30<?, ?trial/s, best loss=?]\r                                                      \rFold: 2/5\n",
      "\r  0%|          | 0/60 [03:30<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 21.369 Val loss 21.137\n",
      "\r  0%|          | 0/60 [03:34<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 9.172 Val loss 9.783\n",
      "\r  0%|          | 0/60 [04:47<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 6.953 Val loss 8.757\n",
      "\r  0%|          | 0/60 [06:02<?, ?trial/s, best loss=?]\r                                                      \rStopped at epoch 274 best_val_loss 8.466\n",
      "\r  0%|          | 0/60 [07:12<?, ?trial/s, best loss=?]\r                                                      \rFold: 3/5\n",
      "\r  0%|          | 0/60 [07:12<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 21.515 Val loss 20.908\n",
      "\r  0%|          | 0/60 [07:16<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 8.804 Val loss 9.748\n",
      "\r  0%|          | 0/60 [08:19<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 6.841 Val loss 9.101\n",
      "\r  0%|          | 0/60 [09:34<?, ?trial/s, best loss=?]\r                                                      \rStopped at epoch 293 best_val_loss 8.662\n",
      "\r  0%|          | 0/60 [10:34<?, ?trial/s, best loss=?]\r                                                      \rFold: 4/5\n",
      "\r  0%|          | 0/60 [10:34<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 21.457 Val loss 20.180\n",
      "\r  0%|          | 0/60 [10:38<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 8.563 Val loss 10.963\n",
      "\r  0%|          | 0/60 [11:48<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 6.662 Val loss 9.455\n",
      "\r  0%|          | 0/60 [13:02<?, ?trial/s, best loss=?]\r                                                      \rStopped at epoch 270 best_val_loss 9.191\n",
      "\r  0%|          | 0/60 [14:14<?, ?trial/s, best loss=?]\r                                                      \rFold: 5/5\n",
      "\r  0%|          | 0/60 [14:14<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 21.475 Val loss 20.097\n",
      "\r  0%|          | 0/60 [14:17<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 9.241 Val loss 10.657\n",
      "\r  0%|          | 0/60 [15:28<?, ?trial/s, best loss=?]\r                                                      \rEpoch 200 Train loss 7.088 Val loss 9.379\n",
      "\r  0%|          | 0/60 [16:42<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 259 best_val_loss 9.078\n",
      "\r  0%|          | 0/60 [17:48<?, ?trial/s, best loss=?]\r                                                      \rval MSE loss mean: 8.93785\n",
      "\n",
      "\r  0%|          | 0/60 [17:48<?, ?trial/s, best loss=?]\r  2%|▏         | 1/60 [17:48<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.25218163927221005, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.48766363219712927, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0002776241648145162, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.35621180164324084}\n",
      "\r  2%|▏         | 1/60 [17:48<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 1/5\n",
      "\r  2%|▏         | 1/60 [17:48<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 19.652 Val loss 17.691\n",
      "\r  2%|▏         | 1/60 [17:52<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 13.087 Val loss 15.369\n",
      "\r  2%|▏         | 1/60 [18:21<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 133 best_val_loss 14.164\n",
      "\r  2%|▏         | 1/60 [18:41<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 2/5\n",
      "\r  2%|▏         | 1/60 [18:41<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 19.425 Val loss 17.355\n",
      "\r  2%|▏         | 1/60 [18:44<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 0 best_val_loss 17.355\n",
      "\r  2%|▏         | 1/60 [18:53<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 3/5\n",
      "\r  2%|▏         | 1/60 [18:53<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 19.688 Val loss 16.994\n",
      "\r  2%|▏         | 1/60 [18:56<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 13.038 Val loss 14.679\n",
      "\r  2%|▏         | 1/60 [19:26<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 130 best_val_loss 13.376\n",
      "\r  2%|▏         | 1/60 [19:44<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 4/5\n",
      "\r  2%|▏         | 1/60 [19:44<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 19.578 Val loss 17.062\n",
      "\r  2%|▏         | 1/60 [19:47<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 13.507 Val loss 15.942\n",
      "\r  2%|▏         | 1/60 [20:20<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 129 best_val_loss 13.820\n",
      "\r  2%|▏         | 1/60 [20:40<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 5/5\n",
      "\r  2%|▏         | 1/60 [20:40<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 19.437 Val loss 17.528\n",
      "\r  2%|▏         | 1/60 [20:43<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 0 best_val_loss 17.528\n",
      "\r  2%|▏         | 1/60 [20:53<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r                                                                                   \rval MSE loss mean: 15.24867\n",
      "\n",
      "\r  2%|▏         | 1/60 [20:53<17:30:40, 1068.49s/trial, best loss: 8.93785142164964]\r  3%|▎         | 2/60 [20:53<8:50:19, 548.61s/trial, best loss: 8.93785142164964]  \r                                                                                 \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.04260169497731103, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.178496802762467, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0003144991589096469, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.9313777770912892}\n",
      "\r  3%|▎         | 2/60 [20:53<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 1/5\n",
      "\r  3%|▎         | 2/60 [20:53<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.596 Val loss 17.774\n",
      "\r  3%|▎         | 2/60 [20:57<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.182 Val loss 10.388\n",
      "\r  3%|▎         | 2/60 [21:43<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 171 best_val_loss 9.970\n",
      "\r  3%|▎         | 2/60 [22:29<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 2/5\n",
      "\r  3%|▎         | 2/60 [22:29<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.594 Val loss 17.269\n",
      "\r  3%|▎         | 2/60 [22:32<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.054 Val loss 9.477\n",
      "\r  3%|▎         | 2/60 [23:08<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 122 best_val_loss 8.872\n",
      "\r  3%|▎         | 2/60 [23:26<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 3/5\n",
      "\r  3%|▎         | 2/60 [23:26<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.713 Val loss 17.322\n",
      "\r  3%|▎         | 2/60 [23:30<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.140 Val loss 10.403\n",
      "\r  3%|▎         | 2/60 [24:16<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 153 best_val_loss 9.668\n",
      "\r  3%|▎         | 2/60 [24:55<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 4/5\n",
      "\r  3%|▎         | 2/60 [24:55<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.576 Val loss 16.697\n",
      "\r  3%|▎         | 2/60 [24:59<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.133 Val loss 10.917\n",
      "\r  3%|▎         | 2/60 [25:45<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 114 best_val_loss 10.129\n",
      "\r  3%|▎         | 2/60 [26:06<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 5/5\n",
      "\r  3%|▎         | 2/60 [26:06<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.570 Val loss 17.370\n",
      "\r  3%|▎         | 2/60 [26:09<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 6.924 Val loss 10.900\n",
      "\r  3%|▎         | 2/60 [26:54<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 131 best_val_loss 10.202\n",
      "\r  3%|▎         | 2/60 [27:22<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r                                                                                 \rval MSE loss mean: 9.76830\n",
      "\n",
      "\r  3%|▎         | 2/60 [27:22<8:50:19, 548.61s/trial, best loss: 8.93785142164964]\r  5%|▌         | 3/60 [27:22<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.31349040317038435, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.14633736782376516, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0007634846170989097, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.784864865209818}\n",
      "\r  5%|▌         | 3/60 [27:22<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 1/5\n",
      "\r  5%|▌         | 3/60 [27:22<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 20.742 Val loss 21.444\n",
      "\r  5%|▌         | 3/60 [27:26<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.186 Val loss 10.609\n",
      "\r  5%|▌         | 3/60 [28:35<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 196 best_val_loss 9.570\n",
      "\r  5%|▌         | 3/60 [29:51<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 2/5\n",
      "\r  5%|▌         | 3/60 [29:51<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 20.976 Val loss 20.237\n",
      "\r  5%|▌         | 3/60 [29:55<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.406 Val loss 9.796\n",
      "\r  5%|▌         | 3/60 [31:14<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 193 best_val_loss 8.547\n",
      "\r  5%|▌         | 3/60 [32:19<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 3/5\n",
      "\r  5%|▌         | 3/60 [32:19<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.000 Val loss 20.725\n",
      "\r  5%|▌         | 3/60 [32:23<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.399 Val loss 9.816\n",
      "\r  5%|▌         | 3/60 [33:37<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 199 best_val_loss 9.043\n",
      "\r  5%|▌         | 3/60 [34:56<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 4/5\n",
      "\r  5%|▌         | 3/60 [34:56<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.202 Val loss 20.110\n",
      "\r  5%|▌         | 3/60 [35:00<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.955 Val loss 10.255\n",
      "\r  5%|▌         | 3/60 [35:59<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 183 best_val_loss 9.688\n",
      "\r  5%|▌         | 3/60 [37:14<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 5/5\n",
      "\r  5%|▌         | 3/60 [37:14<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.149 Val loss 19.947\n",
      "\r  5%|▌         | 3/60 [37:18<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.307 Val loss 10.138\n",
      "\r  5%|▌         | 3/60 [38:36<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 181 best_val_loss 9.517\n",
      "\r  5%|▌         | 3/60 [39:42<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r                                                                                 \rval MSE loss mean: 9.27289\n",
      "\n",
      "\r  5%|▌         | 3/60 [39:42<7:32:11, 475.99s/trial, best loss: 8.93785142164964]\r  7%|▋         | 4/60 [39:42<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.05135549892854152, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.1290837354587625, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.000613805137148198, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.34342051718267275}\n",
      "\r  7%|▋         | 4/60 [39:42<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 1/5\n",
      "\r  7%|▋         | 4/60 [39:42<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.052 Val loss 20.786\n",
      "\r  7%|▋         | 4/60 [39:45<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.827 Val loss 11.518\n",
      "\r  7%|▋         | 4/60 [40:14<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 5.338 Val loss 9.612\n",
      "\r  7%|▋         | 4/60 [40:44<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 217 best_val_loss 9.498\n",
      "\r  7%|▋         | 4/60 [40:57<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 2/5\n",
      "\r  7%|▋         | 4/60 [40:57<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.109 Val loss 19.631\n",
      "\r  7%|▋         | 4/60 [41:01<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.001 Val loss 10.240\n",
      "\r  7%|▋         | 4/60 [41:31<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 5.482 Val loss 9.983\n",
      "\r  7%|▋         | 4/60 [41:59<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 188 best_val_loss 9.153\n",
      "\r  7%|▋         | 4/60 [42:05<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 3/5\n",
      "\r  7%|▋         | 4/60 [42:05<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.666 Val loss 19.631\n",
      "\r  7%|▋         | 4/60 [42:08<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.927 Val loss 10.535\n",
      "\r  7%|▋         | 4/60 [42:38<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 5.426 Val loss 9.562\n",
      "\r  7%|▋         | 4/60 [43:07<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 188 best_val_loss 9.199\n",
      "\r  7%|▋         | 4/60 [43:12<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 4/5\n",
      "\r  7%|▋         | 4/60 [43:12<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.332 Val loss 20.207\n",
      "\r  7%|▋         | 4/60 [43:15<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 7.807 Val loss 13.595\n",
      "\r  7%|▋         | 4/60 [43:47<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 5.279 Val loss 10.089\n",
      "\r  7%|▋         | 4/60 [44:16<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 198 best_val_loss 9.816\n",
      "\r  7%|▋         | 4/60 [44:26<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 5/5\n",
      "\r  7%|▋         | 4/60 [44:26<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 21.493 Val loss 19.674\n",
      "\r  7%|▋         | 4/60 [44:29<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.334 Val loss 11.825\n",
      "\r  7%|▋         | 4/60 [44:58<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 164 best_val_loss 10.131\n",
      "\r  7%|▋         | 4/60 [45:25<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r                                                                                 \rval MSE loss mean: 9.55941\n",
      "\n",
      "\r  7%|▋         | 4/60 [45:25<9:01:18, 579.97s/trial, best loss: 8.93785142164964]\r  8%|▊         | 5/60 [45:25<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.4562223758346601, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.3431449441322162, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0008938500004956679, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.051566722565177026}\n",
      "\r  8%|▊         | 5/60 [45:25<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 1/5\n",
      "\r  8%|▊         | 5/60 [45:25<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 18.286 Val loss 18.158\n",
      "\r  8%|▊         | 5/60 [45:29<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 10.890 Val loss 12.097\n",
      "\r  8%|▊         | 5/60 [46:11<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 8.883 Val loss 11.137\n",
      "\r  8%|▊         | 5/60 [46:55<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 270 best_val_loss 10.683\n",
      "\r  8%|▊         | 5/60 [47:35<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 2/5\n",
      "\r  8%|▊         | 5/60 [47:35<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 18.590 Val loss 17.594\n",
      "\r  8%|▊         | 5/60 [47:38<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 11.205 Val loss 10.962\n",
      "\r  8%|▊         | 5/60 [48:20<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 9.333 Val loss 9.822\n",
      "\r  8%|▊         | 5/60 [48:55<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 296 best_val_loss 9.473\n",
      "\r  8%|▊         | 5/60 [49:36<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 3/5\n",
      "\r  8%|▊         | 5/60 [49:36<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 18.528 Val loss 17.404\n",
      "\r  8%|▊         | 5/60 [49:40<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 10.912 Val loss 11.281\n",
      "\r  8%|▊         | 5/60 [50:20<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 9.024 Val loss 10.216\n",
      "\r  8%|▊         | 5/60 [51:00<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 284 best_val_loss 9.810\n",
      "\r  8%|▊         | 5/60 [51:43<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 4/5\n",
      "\r  8%|▊         | 5/60 [51:43<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 18.661 Val loss 17.159\n",
      "\r  8%|▊         | 5/60 [51:47<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 10.886 Val loss 11.618\n",
      "\r  8%|▊         | 5/60 [52:27<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 9.081 Val loss 10.767\n",
      "\r  8%|▊         | 5/60 [53:10<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 251 best_val_loss 10.575\n",
      "\r  8%|▊         | 5/60 [53:45<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 5/5\n",
      "\r  8%|▊         | 5/60 [53:45<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 18.651 Val loss 17.495\n",
      "\r  8%|▊         | 5/60 [53:48<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 10.901 Val loss 11.860\n",
      "\r  8%|▊         | 5/60 [54:31<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 9.146 Val loss 10.774\n",
      "\r  8%|▊         | 5/60 [55:07<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rStopped at epoch 273 best_val_loss 10.357\n",
      "\r  8%|▊         | 5/60 [55:49<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r                                                                                 \rval MSE loss mean: 10.17956\n",
      "\n",
      "\r  8%|▊         | 5/60 [55:49<7:33:26, 494.67s/trial, best loss: 8.93785142164964]\r 10%|█         | 6/60 [55:49<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.13311052337591772, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.25853040377866204, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.0008861396175986121, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.10647373236379765}\n",
      "\r 10%|█         | 6/60 [55:49<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 1/5\n",
      "\r 10%|█         | 6/60 [55:49<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.495 Val loss 17.970\n",
      "\r 10%|█         | 6/60 [55:53<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.373 Val loss 11.441\n",
      "\r 10%|█         | 6/60 [56:40<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 200 Train loss 6.462 Val loss 10.599\n",
      "\r 10%|█         | 6/60 [57:25<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 186 best_val_loss 10.269\n",
      "\r 10%|█         | 6/60 [57:33<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 2/5\n",
      "\r 10%|█         | 6/60 [57:34<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.708 Val loss 17.594\n",
      "\r 10%|█         | 6/60 [57:37<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.194 Val loss 9.908\n",
      "\r 10%|█         | 6/60 [58:24<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 166 best_val_loss 9.010\n",
      "\r 10%|█         | 6/60 [59:08<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rFold: 3/5\n",
      "\r 10%|█         | 6/60 [59:08<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 0 Train loss 17.825 Val loss 17.379\n",
      "\r 10%|█         | 6/60 [59:12<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEpoch 100 Train loss 8.718 Val loss 11.206\n",
      "\r 10%|█         | 6/60 [59:57<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                 \rEarly stopped at epoch 151 best_val_loss 9.804\n",
      "\r 10%|█         | 6/60 [1:00:35<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 4/5\n",
      "\r 10%|█         | 6/60 [1:00:35<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 17.751 Val loss 17.143\n",
      "\r 10%|█         | 6/60 [1:00:38<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 8.205 Val loss 11.381\n",
      "\r 10%|█         | 6/60 [1:01:23<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 118 best_val_loss 10.605\n",
      "\r 10%|█         | 6/60 [1:01:46<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 5/5\n",
      "\r 10%|█         | 6/60 [1:01:46<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 17.507 Val loss 17.203\n",
      "\r 10%|█         | 6/60 [1:01:50<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 8.604 Val loss 11.327\n",
      "\r 10%|█         | 6/60 [1:02:35<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 125 best_val_loss 10.452\n",
      "\r 10%|█         | 6/60 [1:02:59<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r                                                                                   \rval MSE loss mean: 10.02802\n",
      "\n",
      "\r 10%|█         | 6/60 [1:02:59<8:04:54, 538.78s/trial, best loss: 8.93785142164964]\r 12%|█▏        | 7/60 [1:02:59<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.36819373901113683, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.04754227823182405, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0006074687338073932, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.4149774378234763}\n",
      "\r 12%|█▏        | 7/60 [1:02:59<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 1/5\n",
      "\r 12%|█▏        | 7/60 [1:02:59<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 17.749 Val loss 17.818\n",
      "\r 12%|█▏        | 7/60 [1:03:03<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.757 Val loss 11.624\n",
      "\r 12%|█▏        | 7/60 [1:04:04<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.615 Val loss 10.368\n",
      "\r 12%|█▏        | 7/60 [1:05:00<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 300 Train loss 6.620 Val loss 9.836\n",
      "\r 12%|█▏        | 7/60 [1:06:18<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 297 best_val_loss 9.749\n",
      "\r 12%|█▏        | 7/60 [1:06:39<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 2/5\n",
      "\r 12%|█▏        | 7/60 [1:06:39<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 17.822 Val loss 17.291\n",
      "\r 12%|█▏        | 7/60 [1:06:43<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.939 Val loss 10.296\n",
      "\r 12%|█▏        | 7/60 [1:07:46<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.930 Val loss 9.363\n",
      "\r 12%|█▏        | 7/60 [1:09:01<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 300 Train loss 6.682 Val loss 8.964\n",
      "\r 12%|█▏        | 7/60 [1:10:13<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 306 best_val_loss 8.817\n",
      "\r 12%|█▏        | 7/60 [1:10:42<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 3/5\n",
      "\r 12%|█▏        | 7/60 [1:10:42<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 18.060 Val loss 17.088\n",
      "\r 12%|█▏        | 7/60 [1:10:46<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.893 Val loss 10.698\n",
      "\r 12%|█▏        | 7/60 [1:11:54<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.935 Val loss 9.589\n",
      "\r 12%|█▏        | 7/60 [1:12:58<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 300 Train loss 6.597 Val loss 9.247\n",
      "\r 12%|█▏        | 7/60 [1:13:58<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 315 best_val_loss 9.016\n",
      "\r 12%|█▏        | 7/60 [1:14:23<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 4/5\n",
      "\r 12%|█▏        | 7/60 [1:14:23<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 18.139 Val loss 16.851\n",
      "\r 12%|█▏        | 7/60 [1:14:27<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.718 Val loss 11.576\n",
      "\r 12%|█▏        | 7/60 [1:15:36<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.588 Val loss 10.256\n",
      "\r 12%|█▏        | 7/60 [1:16:52<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 300 Train loss 6.343 Val loss 9.893\n",
      "\r 12%|█▏        | 7/60 [1:18:00<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 358 best_val_loss 9.631\n",
      "\r 12%|█▏        | 7/60 [1:19:00<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 5/5\n",
      "\r 12%|█▏        | 7/60 [1:19:00<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 17.754 Val loss 17.258\n",
      "\r 12%|█▏        | 7/60 [1:19:04<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.807 Val loss 11.145\n",
      "\r 12%|█▏        | 7/60 [1:20:14<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.871 Val loss 9.990\n",
      "\r 12%|█▏        | 7/60 [1:21:16<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 254 best_val_loss 9.714\n",
      "\r 12%|█▏        | 7/60 [1:22:08<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r                                                                                   \rval MSE loss mean: 9.38544\n",
      "\n",
      "\r 12%|█▏        | 7/60 [1:22:08<7:24:18, 503.00s/trial, best loss: 8.93785142164964]\r 13%|█▎        | 8/60 [1:22:08<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.14702409781060138, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.09138600852407641, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.0007646793528219444, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.02315986185667951}\n",
      "\r 13%|█▎        | 8/60 [1:22:08<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 13%|█▎        | 8/60 [1:22:08<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.488 Val loss 22.305\n",
      "\r 13%|█▎        | 8/60 [1:22:12<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.097 Val loss 9.813\n",
      "\r 13%|█▎        | 8/60 [1:22:45<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 170 best_val_loss 9.117\n",
      "\r 13%|█▎        | 8/60 [1:23:17<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 13%|█▎        | 8/60 [1:23:17<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.769 Val loss 21.947\n",
      "\r 13%|█▎        | 8/60 [1:23:20<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.232 Val loss 9.129\n",
      "\r 13%|█▎        | 8/60 [1:23:52<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 199 best_val_loss 8.217\n",
      "\r 13%|█▎        | 8/60 [1:24:21<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 13%|█▎        | 8/60 [1:24:21<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.592 Val loss 21.636\n",
      "\r 13%|█▎        | 8/60 [1:24:24<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.347 Val loss 10.314\n",
      "\r 13%|█▎        | 8/60 [1:24:54<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 192 best_val_loss 8.888\n",
      "\r 13%|█▎        | 8/60 [1:25:23<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 13%|█▎        | 8/60 [1:25:23<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.765 Val loss 20.289\n",
      "\r 13%|█▎        | 8/60 [1:25:26<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.230 Val loss 9.998\n",
      "\r 13%|█▎        | 8/60 [1:25:55<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 186 best_val_loss 9.353\n",
      "\r 13%|█▎        | 8/60 [1:26:25<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 13%|█▎        | 8/60 [1:26:25<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.829 Val loss 20.066\n",
      "\r 13%|█▎        | 8/60 [1:26:29<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.256 Val loss 10.124\n",
      "\r 13%|█▎        | 8/60 [1:27:02<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 154 best_val_loss 9.659\n",
      "\r 13%|█▎        | 8/60 [1:27:29<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.04669\n",
      "\n",
      "\r 13%|█▎        | 8/60 [1:27:29<10:14:16, 708.79s/trial, best loss: 8.93785142164964]\r 15%|█▌        | 9/60 [1:27:29<8:19:26, 587.57s/trial, best loss: 8.93785142164964] \r                                                                                   \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.08834810444144442, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.4792701343844903, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0009123263972570749, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.5331232699693049}\n",
      "\r 15%|█▌        | 9/60 [1:27:29<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 1/5\n",
      "\r 15%|█▌        | 9/60 [1:27:29<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 21.382 Val loss 21.534\n",
      "\r 15%|█▌        | 9/60 [1:27:33<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.794 Val loss 12.212\n",
      "\r 15%|█▌        | 9/60 [1:28:01<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 6.709 Val loss 10.266\n",
      "\r 15%|█▌        | 9/60 [1:28:29<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rStopped at epoch 284 best_val_loss 9.343\n",
      "\r 15%|█▌        | 9/60 [1:28:56<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 2/5\n",
      "\r 15%|█▌        | 9/60 [1:28:56<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 21.920 Val loss 21.021\n",
      "\r 15%|█▌        | 9/60 [1:28:59<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.597 Val loss 11.239\n",
      "\r 15%|█▌        | 9/60 [1:29:28<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 6.947 Val loss 9.352\n",
      "\r 15%|█▌        | 9/60 [1:29:57<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 242 best_val_loss 8.775\n",
      "\r 15%|█▌        | 9/60 [1:30:19<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 3/5\n",
      "\r 15%|█▌        | 9/60 [1:30:19<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 21.993 Val loss 20.810\n",
      "\r 15%|█▌        | 9/60 [1:30:23<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.482 Val loss 10.966\n",
      "\r 15%|█▌        | 9/60 [1:30:52<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 7.024 Val loss 9.947\n",
      "\r 15%|█▌        | 9/60 [1:31:20<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rStopped at epoch 286 best_val_loss 9.058\n",
      "\r 15%|█▌        | 9/60 [1:31:48<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 4/5\n",
      "\r 15%|█▌        | 9/60 [1:31:48<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 21.989 Val loss 20.755\n",
      "\r 15%|█▌        | 9/60 [1:31:51<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.387 Val loss 11.447\n",
      "\r 15%|█▌        | 9/60 [1:32:21<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 6.760 Val loss 10.097\n",
      "\r 15%|█▌        | 9/60 [1:32:53<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 250 best_val_loss 9.626\n",
      "\r 15%|█▌        | 9/60 [1:33:16<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rFold: 5/5\n",
      "\r 15%|█▌        | 9/60 [1:33:16<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 0 Train loss 21.595 Val loss 20.247\n",
      "\r 15%|█▌        | 9/60 [1:33:20<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 100 Train loss 9.950 Val loss 11.601\n",
      "\r 15%|█▌        | 9/60 [1:33:48<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEpoch 200 Train loss 6.956 Val loss 9.998\n",
      "\r 15%|█▌        | 9/60 [1:34:15<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rEarly stopped at epoch 265 best_val_loss 9.452\n",
      "\r 15%|█▌        | 9/60 [1:34:44<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r                                                                                   \rval MSE loss mean: 9.25060\n",
      "\n",
      "\r 15%|█▌        | 9/60 [1:34:44<8:19:26, 587.57s/trial, best loss: 8.93785142164964]\r 17%|█▋        | 10/60 [1:34:44<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.05466575060932993, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.03376903509002782, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0005137947246183402, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.037837361610403075}\n",
      "\r 17%|█▋        | 10/60 [1:34:44<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 17%|█▋        | 10/60 [1:34:44<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.463 Val loss 17.753\n",
      "\r 17%|█▋        | 10/60 [1:34:47<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 6.856 Val loss 10.139\n",
      "\r 17%|█▋        | 10/60 [1:35:27<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 169 best_val_loss 9.668\n",
      "\r 17%|█▋        | 10/60 [1:36:05<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 17%|█▋        | 10/60 [1:36:05<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.661 Val loss 17.239\n",
      "\r 17%|█▋        | 10/60 [1:36:08<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.072 Val loss 9.045\n",
      "\r 17%|█▋        | 10/60 [1:36:52<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 182 best_val_loss 8.570\n",
      "\r 17%|█▋        | 10/60 [1:37:36<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 17%|█▋        | 10/60 [1:37:36<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.716 Val loss 17.100\n",
      "\r 17%|█▋        | 10/60 [1:37:40<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.396 Val loss 10.147\n",
      "\r 17%|█▋        | 10/60 [1:38:26<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 185 best_val_loss 9.213\n",
      "\r 17%|█▋        | 10/60 [1:39:10<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 17%|█▋        | 10/60 [1:39:10<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.612 Val loss 17.023\n",
      "\r 17%|█▋        | 10/60 [1:39:14<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 6.786 Val loss 10.283\n",
      "\r 17%|█▋        | 10/60 [1:39:57<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 185 best_val_loss 9.608\n",
      "\r 17%|█▋        | 10/60 [1:40:34<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 17%|█▋        | 10/60 [1:40:34<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.671 Val loss 16.936\n",
      "\r 17%|█▋        | 10/60 [1:40:37<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 6.949 Val loss 10.372\n",
      "\r 17%|█▋        | 10/60 [1:41:21<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 173 best_val_loss 9.640\n",
      "\r 17%|█▋        | 10/60 [1:42:00<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.33967\n",
      "\n",
      "\r 17%|█▋        | 10/60 [1:42:00<7:30:16, 540.34s/trial, best loss: 8.93785142164964]\r 18%|█▊        | 11/60 [1:42:00<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.14097992902924295, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.25503523846121723, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0006317825466599971, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.5835501030036162}\n",
      "\r 18%|█▊        | 11/60 [1:42:00<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 18%|█▊        | 11/60 [1:42:00<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.760 Val loss 17.796\n",
      "\r 18%|█▊        | 11/60 [1:42:04<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.683 Val loss 10.858\n",
      "\r 18%|█▊        | 11/60 [1:42:33<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.199 Val loss 10.057\n",
      "\r 18%|█▊        | 11/60 [1:43:02<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 185 best_val_loss 9.903\n",
      "\r 18%|█▊        | 11/60 [1:43:07<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 18%|█▊        | 11/60 [1:43:07<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.135 Val loss 17.188\n",
      "\r 18%|█▊        | 11/60 [1:43:10<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.521 Val loss 10.263\n",
      "\r 18%|█▊        | 11/60 [1:43:39<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.372 Val loss 8.640\n",
      "\r 18%|█▊        | 11/60 [1:44:07<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 211 best_val_loss 8.436\n",
      "\r 18%|█▊        | 11/60 [1:44:18<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 18%|█▊        | 11/60 [1:44:18<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.411 Val loss 17.244\n",
      "\r 18%|█▊        | 11/60 [1:44:22<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.638 Val loss 10.692\n",
      "\r 18%|█▊        | 11/60 [1:44:52<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.504 Val loss 9.869\n",
      "\r 18%|█▊        | 11/60 [1:45:21<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 221 best_val_loss 9.550\n",
      "\r 18%|█▊        | 11/60 [1:45:35<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 18%|█▊        | 11/60 [1:45:35<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.182 Val loss 16.723\n",
      "\r 18%|█▊        | 11/60 [1:45:38<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.113 Val loss 11.178\n",
      "\r 18%|█▊        | 11/60 [1:46:08<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.089 Val loss 9.694\n",
      "\r 18%|█▊        | 11/60 [1:46:37<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 200 best_val_loss 9.694\n",
      "\r 18%|█▊        | 11/60 [1:46:45<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 18%|█▊        | 11/60 [1:46:45<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.812 Val loss 16.421\n",
      "\r 18%|█▊        | 11/60 [1:46:49<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.451 Val loss 11.933\n",
      "\r 18%|█▊        | 11/60 [1:47:19<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 161 best_val_loss 10.020\n",
      "\r 18%|█▊        | 11/60 [1:47:46<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.52061\n",
      "\n",
      "\r 18%|█▊        | 11/60 [1:47:46<6:55:19, 508.55s/trial, best loss: 8.93785142164964]\r 20%|██        | 12/60 [1:47:46<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.09208969743342105, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.3491972109390805, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0001411805091693317, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.02987623799755912}\n",
      "\r 20%|██        | 12/60 [1:47:46<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 20%|██        | 12/60 [1:47:46<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.336 Val loss 20.104\n",
      "\r 20%|██        | 12/60 [1:47:50<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.146 Val loss 15.977\n",
      "\r 20%|██        | 12/60 [1:48:19<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 176 best_val_loss 14.743\n",
      "\r 20%|██        | 12/60 [1:48:48<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 20%|██        | 12/60 [1:48:48<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.529 Val loss 19.420\n",
      "\r 20%|██        | 12/60 [1:48:51<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.605 Val loss 14.810\n",
      "\r 20%|██        | 12/60 [1:49:28<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 171 best_val_loss 13.917\n",
      "\r 20%|██        | 12/60 [1:50:00<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 20%|██        | 12/60 [1:50:00<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.859 Val loss 20.321\n",
      "\r 20%|██        | 12/60 [1:50:05<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.407 Val loss 15.721\n",
      "\r 20%|██        | 12/60 [1:50:37<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 151 best_val_loss 14.461\n",
      "\r 20%|██        | 12/60 [1:51:03<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 20%|██        | 12/60 [1:51:03<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.926 Val loss 18.782\n",
      "\r 20%|██        | 12/60 [1:51:07<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.407 Val loss 15.637\n",
      "\r 20%|██        | 12/60 [1:51:42<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 177 best_val_loss 15.298\n",
      "\r 20%|██        | 12/60 [1:52:15<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 20%|██        | 12/60 [1:52:15<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.696 Val loss 18.764\n",
      "\r 20%|██        | 12/60 [1:52:18<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.693 Val loss 15.232\n",
      "\r 20%|██        | 12/60 [1:52:49<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 145 best_val_loss 14.712\n",
      "\r 20%|██        | 12/60 [1:53:14<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 14.62605\n",
      "\n",
      "\r 20%|██        | 12/60 [1:53:14<6:07:12, 459.00s/trial, best loss: 8.93785142164964]\r 22%|██▏       | 13/60 [1:53:14<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.017951642779981403, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.4850809047175302, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0009610074060083547, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.9653293527453086}\n",
      "\r 22%|██▏       | 13/60 [1:53:14<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 22%|██▏       | 13/60 [1:53:14<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.374 Val loss 17.738\n",
      "\r 22%|██▏       | 13/60 [1:53:18<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.052 Val loss 11.605\n",
      "\r 22%|██▏       | 13/60 [1:53:51<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.214 Val loss 10.598\n",
      "\r 22%|██▏       | 13/60 [1:54:23<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 251 best_val_loss 10.066\n",
      "\r 22%|██▏       | 13/60 [1:54:48<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 22%|██▏       | 13/60 [1:54:48<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.703 Val loss 17.404\n",
      "\r 22%|██▏       | 13/60 [1:54:52<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.768 Val loss 11.016\n",
      "\r 22%|██▏       | 13/60 [1:55:25<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.799 Val loss 10.000\n",
      "\r 22%|██▏       | 13/60 [1:55:58<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 220 best_val_loss 9.523\n",
      "\r 22%|██▏       | 13/60 [1:56:16<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 22%|██▏       | 13/60 [1:56:16<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.625 Val loss 16.936\n",
      "\r 22%|██▏       | 13/60 [1:56:20<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.275 Val loss 11.009\n",
      "\r 22%|██▏       | 13/60 [1:56:52<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 158 best_val_loss 10.137\n",
      "\r 22%|██▏       | 13/60 [1:57:22<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 22%|██▏       | 13/60 [1:57:22<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.486 Val loss 17.023\n",
      "\r 22%|██▏       | 13/60 [1:57:26<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.125 Val loss 12.134\n",
      "\r 22%|██▏       | 13/60 [1:58:00<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.316 Val loss 11.138\n",
      "\r 22%|██▏       | 13/60 [1:58:35<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 209 best_val_loss 10.438\n",
      "\r 22%|██▏       | 13/60 [1:58:49<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 22%|██▏       | 13/60 [1:58:49<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.452 Val loss 17.417\n",
      "\r 22%|██▏       | 13/60 [1:58:53<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.924 Val loss 12.687\n",
      "\r 22%|██▏       | 13/60 [1:59:26<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.648 Val loss 10.606\n",
      "\r 22%|██▏       | 13/60 [2:00:00<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 191 best_val_loss 10.374\n",
      "\r 22%|██▏       | 13/60 [2:00:08<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 10.10775\n",
      "\n",
      "\r 22%|██▏       | 13/60 [2:00:08<5:28:23, 419.23s/trial, best loss: 8.93785142164964]\r 23%|██▎       | 14/60 [2:00:08<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.30013780362085224, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.3547494057061172, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0007938691091424689, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.421356760271009}\n",
      "\r 23%|██▎       | 14/60 [2:00:08<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 23%|██▎       | 14/60 [2:00:08<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.127 Val loss 17.946\n",
      "\r 23%|██▎       | 14/60 [2:00:12<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.187 Val loss 11.273\n",
      "\r 23%|██▎       | 14/60 [2:01:01<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.898 Val loss 10.112\n",
      "\r 23%|██▎       | 14/60 [2:01:49<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 237 best_val_loss 9.681\n",
      "\r 23%|██▎       | 14/60 [2:02:23<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 23%|██▎       | 14/60 [2:02:23<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.223 Val loss 17.253\n",
      "\r 23%|██▎       | 14/60 [2:02:27<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.227 Val loss 9.956\n",
      "\r 23%|██▎       | 14/60 [2:03:16<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.991 Val loss 8.983\n",
      "\r 23%|██▎       | 14/60 [2:04:06<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 235 best_val_loss 8.855\n",
      "\r 23%|██▎       | 14/60 [2:04:38<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 23%|██▎       | 14/60 [2:04:38<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.267 Val loss 17.112\n",
      "\r 23%|██▎       | 14/60 [2:04:41<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.221 Val loss 10.800\n",
      "\r 23%|██▎       | 14/60 [2:05:29<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.974 Val loss 9.509\n",
      "\r 23%|██▎       | 14/60 [2:06:12<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 244 best_val_loss 9.254\n",
      "\r 23%|██▎       | 14/60 [2:06:48<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 23%|██▎       | 14/60 [2:06:48<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.264 Val loss 16.803\n",
      "\r 23%|██▎       | 14/60 [2:06:51<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.171 Val loss 11.126\n",
      "\r 23%|██▎       | 14/60 [2:07:34<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 7.000 Val loss 10.213\n",
      "\r 23%|██▎       | 14/60 [2:08:20<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 249 best_val_loss 9.848\n",
      "\r 23%|██▎       | 14/60 [2:08:57<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 23%|██▎       | 14/60 [2:08:57<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.120 Val loss 17.004\n",
      "\r 23%|██▎       | 14/60 [2:09:00<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.603 Val loss 11.025\n",
      "\r 23%|██▎       | 14/60 [2:09:48<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.926 Val loss 9.985\n",
      "\r 23%|██▎       | 14/60 [2:10:27<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 265 best_val_loss 9.843\n",
      "\r 23%|██▎       | 14/60 [2:11:08<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.49610\n",
      "\n",
      "\r 23%|██▎       | 14/60 [2:11:08<5:20:18, 417.80s/trial, best loss: 8.93785142164964]\r 25%|██▌       | 15/60 [2:11:08<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.2978283613370758, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.48643941088396386, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.00038065872416690724, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.46038621426822346}\n",
      "\r 25%|██▌       | 15/60 [2:11:08<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 25%|██▌       | 15/60 [2:11:08<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.103 Val loss 22.577\n",
      "\r 25%|██▌       | 15/60 [2:11:12<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.817 Val loss 15.088\n",
      "\r 25%|██▌       | 15/60 [2:11:48<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 195 best_val_loss 13.243\n",
      "\r 25%|██▌       | 15/60 [2:12:32<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 25%|██▌       | 15/60 [2:12:32<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.328 Val loss 23.680\n",
      "\r 25%|██▌       | 15/60 [2:12:35<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.277 Val loss 13.705\n",
      "\r 25%|██▌       | 15/60 [2:13:16<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 115 best_val_loss 11.805\n",
      "\r 25%|██▌       | 15/60 [2:13:37<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 25%|██▌       | 15/60 [2:13:37<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.445 Val loss 22.492\n",
      "\r 25%|██▌       | 15/60 [2:13:41<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.280 Val loss 14.765\n",
      "\r 25%|██▌       | 15/60 [2:14:28<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 120 best_val_loss 13.287\n",
      "\r 25%|██▌       | 15/60 [2:14:50<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 25%|██▌       | 15/60 [2:14:50<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.473 Val loss 23.147\n",
      "\r 25%|██▌       | 15/60 [2:14:54<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.436 Val loss 14.430\n",
      "\r 25%|██▌       | 15/60 [2:15:31<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 146 best_val_loss 12.796\n",
      "\r 25%|██▌       | 15/60 [2:16:02<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 25%|██▌       | 15/60 [2:16:02<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.486 Val loss 22.326\n",
      "\r 25%|██▌       | 15/60 [2:16:06<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.567 Val loss 15.175\n",
      "\r 25%|██▌       | 15/60 [2:16:43<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 132 best_val_loss 13.265\n",
      "\r 25%|██▌       | 15/60 [2:17:13<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 12.87893\n",
      "\n",
      "\r 25%|██▌       | 15/60 [2:17:13<6:07:59, 490.66s/trial, best loss: 8.93785142164964]\r 27%|██▋       | 16/60 [2:17:13<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.2587572208909625, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.06414702691419144, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0002656419724491898, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.5560381752940059}\n",
      "\r 27%|██▋       | 16/60 [2:17:13<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 27%|██▋       | 16/60 [2:17:13<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 20.952 Val loss 20.104\n",
      "\r 27%|██▋       | 16/60 [2:17:16<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.401 Val loss 14.749\n",
      "\r 27%|██▋       | 16/60 [2:17:44<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 10.395 Val loss 12.362\n",
      "\r 27%|██▋       | 16/60 [2:18:13<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 297 best_val_loss 12.012\n",
      "\r 27%|██▋       | 16/60 [2:18:41<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 27%|██▋       | 16/60 [2:18:41<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.395 Val loss 20.025\n",
      "\r 27%|██▋       | 16/60 [2:18:45<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.094 Val loss 13.895\n",
      "\r 27%|██▋       | 16/60 [2:19:13<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 10.241 Val loss 11.405\n",
      "\r 27%|██▋       | 16/60 [2:19:43<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 228 best_val_loss 10.990\n",
      "\r 27%|██▋       | 16/60 [2:20:00<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 27%|██▋       | 16/60 [2:20:00<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.425 Val loss 20.257\n",
      "\r 27%|██▋       | 16/60 [2:20:04<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.273 Val loss 14.361\n",
      "\r 27%|██▋       | 16/60 [2:20:30<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 10.806 Val loss 12.221\n",
      "\r 27%|██▋       | 16/60 [2:20:57<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 286 best_val_loss 11.697\n",
      "\r 27%|██▋       | 16/60 [2:21:25<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 27%|██▋       | 16/60 [2:21:25<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.448 Val loss 20.584\n",
      "\r 27%|██▋       | 16/60 [2:21:28<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 13.816 Val loss 14.427\n",
      "\r 27%|██▋       | 16/60 [2:21:57<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 9.619 Val loss 12.497\n",
      "\r 27%|██▋       | 16/60 [2:22:28<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 224 best_val_loss 11.960\n",
      "\r 27%|██▋       | 16/60 [2:22:44<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 27%|██▋       | 16/60 [2:22:44<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.163 Val loss 20.232\n",
      "\r 27%|██▋       | 16/60 [2:22:47<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 14.251 Val loss 14.621\n",
      "\r 27%|██▋       | 16/60 [2:23:15<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 10.543 Val loss 12.530\n",
      "\r 27%|██▋       | 16/60 [2:23:42<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 270 best_val_loss 12.237\n",
      "\r 27%|██▋       | 16/60 [2:24:08<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 11.77942\n",
      "\n",
      "\r 27%|██▋       | 16/60 [2:24:08<5:32:08, 452.91s/trial, best loss: 8.93785142164964]\r 28%|██▊       | 17/60 [2:24:09<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.009408875725887056, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.45837937850487515, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.0004358064817870754, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.9787887460831937}\n",
      "\r 28%|██▊       | 17/60 [2:24:09<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 28%|██▊       | 17/60 [2:24:09<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.149 Val loss 19.141\n",
      "\r 28%|██▊       | 17/60 [2:24:12<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.314 Val loss 18.804\n",
      "\r 28%|██▊       | 17/60 [2:24:40<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 105 best_val_loss 13.601\n",
      "\r 28%|██▊       | 17/60 [2:24:50<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 28%|██▊       | 17/60 [2:24:50<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.512 Val loss 18.226\n",
      "\r 28%|██▊       | 17/60 [2:24:54<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 57 best_val_loss 13.800\n",
      "\r 28%|██▊       | 17/60 [2:25:21<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 28%|██▊       | 17/60 [2:25:21<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.687 Val loss 17.754\n",
      "\r 28%|██▊       | 17/60 [2:25:25<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 36 best_val_loss 13.954\n",
      "\r 28%|██▊       | 17/60 [2:25:45<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 28%|██▊       | 17/60 [2:25:45<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.724 Val loss 18.904\n",
      "\r 28%|██▊       | 17/60 [2:25:48<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.250 Val loss 16.638\n",
      "\r 28%|██▊       | 17/60 [2:26:19<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 78 best_val_loss 13.536\n",
      "\r 28%|██▊       | 17/60 [2:26:21<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 28%|██▊       | 17/60 [2:26:21<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.517 Val loss 18.126\n",
      "\r 28%|██▊       | 17/60 [2:26:25<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.794 Val loss 14.016\n",
      "\r 28%|██▊       | 17/60 [2:26:57<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 143 best_val_loss 12.767\n",
      "\r 28%|██▊       | 17/60 [2:27:19<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 13.53153\n",
      "\n",
      "\r 28%|██▊       | 17/60 [2:27:19<5:16:32, 441.68s/trial, best loss: 8.93785142164964]\r 30%|███       | 18/60 [2:27:19<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.22512855904281304, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.03768230970826186, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0006502930294299536, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.39546255937335817}\n",
      "\r 30%|███       | 18/60 [2:27:19<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 30%|███       | 18/60 [2:27:19<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.800 Val loss 17.704\n",
      "\r 30%|███       | 18/60 [2:27:23<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.466 Val loss 11.076\n",
      "\r 30%|███       | 18/60 [2:27:47<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.082 Val loss 10.159\n",
      "\r 30%|███       | 18/60 [2:28:13<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 226 best_val_loss 10.037\n",
      "\r 30%|███       | 18/60 [2:28:28<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 30%|███       | 18/60 [2:28:28<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.758 Val loss 17.041\n",
      "\r 30%|███       | 18/60 [2:28:31<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.561 Val loss 9.853\n",
      "\r 30%|███       | 18/60 [2:28:55<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.237 Val loss 8.750\n",
      "\r 30%|███       | 18/60 [2:29:20<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 222 best_val_loss 8.586\n",
      "\r 30%|███       | 18/60 [2:29:33<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 30%|███       | 18/60 [2:29:33<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.950 Val loss 17.139\n",
      "\r 30%|███       | 18/60 [2:29:36<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.599 Val loss 10.869\n",
      "\r 30%|███       | 18/60 [2:30:02<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.377 Val loss 9.990\n",
      "\r 30%|███       | 18/60 [2:30:27<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 252 best_val_loss 9.714\n",
      "\r 30%|███       | 18/60 [2:30:49<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 30%|███       | 18/60 [2:30:49<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.915 Val loss 16.457\n",
      "\r 30%|███       | 18/60 [2:30:53<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.366 Val loss 10.639\n",
      "\r 30%|███       | 18/60 [2:31:19<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.067 Val loss 9.625\n",
      "\r 30%|███       | 18/60 [2:31:45<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 234 best_val_loss 9.151\n",
      "\r 30%|███       | 18/60 [2:32:02<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 30%|███       | 18/60 [2:32:02<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 17.759 Val loss 16.741\n",
      "\r 30%|███       | 18/60 [2:32:05<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.673 Val loss 10.779\n",
      "\r 30%|███       | 18/60 [2:32:31<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.256 Val loss 10.392\n",
      "\r 30%|███       | 18/60 [2:32:57<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 212 best_val_loss 9.951\n",
      "\r 30%|███       | 18/60 [2:33:08<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.48767\n",
      "\n",
      "\r 30%|███       | 18/60 [2:33:08<4:16:25, 366.32s/trial, best loss: 8.93785142164964]\r 32%|███▏      | 19/60 [2:33:08<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.42298677309759625, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.18498038096268332, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.000377177798546637, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.6138249965134606}\n",
      "\r 32%|███▏      | 19/60 [2:33:08<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 32%|███▏      | 19/60 [2:33:08<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.265 Val loss 18.682\n",
      "\r 32%|███▏      | 19/60 [2:33:12<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.265 Val loss 12.789\n",
      "\r 32%|███▏      | 19/60 [2:33:55<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 8.010 Val loss 11.185\n",
      "\r 32%|███▏      | 19/60 [2:34:41<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 300 Train loss 7.001 Val loss 10.846\n",
      "\r 32%|███▏      | 19/60 [2:35:19<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 282 best_val_loss 10.516\n",
      "\r 32%|███▏      | 19/60 [2:35:24<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 32%|███▏      | 19/60 [2:35:24<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.351 Val loss 18.909\n",
      "\r 32%|███▏      | 19/60 [2:35:28<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.609 Val loss 11.773\n",
      "\r 32%|███▏      | 19/60 [2:36:12<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 8.344 Val loss 10.106\n",
      "\r 32%|███▏      | 19/60 [2:36:58<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 193 best_val_loss 9.410\n",
      "\r 32%|███▏      | 19/60 [2:37:09<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 32%|███▏      | 19/60 [2:37:09<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.353 Val loss 18.291\n",
      "\r 32%|███▏      | 19/60 [2:37:12<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.735 Val loss 12.326\n",
      "\r 32%|███▏      | 19/60 [2:37:55<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 8.151 Val loss 10.929\n",
      "\r 32%|███▏      | 19/60 [2:38:36<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 193 best_val_loss 10.471\n",
      "\r 32%|███▏      | 19/60 [2:38:46<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 32%|███▏      | 19/60 [2:38:46<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.386 Val loss 18.512\n",
      "\r 32%|███▏      | 19/60 [2:38:50<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.379 Val loss 11.613\n",
      "\r 32%|███▏      | 19/60 [2:39:36<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 122 best_val_loss 11.117\n",
      "\r 32%|███▏      | 19/60 [2:39:59<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 32%|███▏      | 19/60 [2:39:59<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 18.351 Val loss 18.818\n",
      "\r 32%|███▏      | 19/60 [2:40:03<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 10.533 Val loss 11.883\n",
      "\r 32%|███▏      | 19/60 [2:40:47<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 163 best_val_loss 10.933\n",
      "\r 32%|███▏      | 19/60 [2:41:27<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 10.48912\n",
      "\n",
      "\r 32%|███▏      | 19/60 [2:41:27<4:06:39, 360.97s/trial, best loss: 8.93785142164964]\r 33%|███▎      | 20/60 [2:41:27<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.18473656461141486, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.39361611599590285, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.0007568648673117694, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7244544832639846}\n",
      "\r 33%|███▎      | 20/60 [2:41:27<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 33%|███▎      | 20/60 [2:41:27<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.587 Val loss 22.660\n",
      "\r 33%|███▎      | 20/60 [2:41:31<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.001 Val loss 10.417\n",
      "\r 33%|███▎      | 20/60 [2:42:25<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 195 best_val_loss 9.509\n",
      "\r 33%|███▎      | 20/60 [2:43:12<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 33%|███▎      | 20/60 [2:43:12<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.851 Val loss 21.285\n",
      "\r 33%|███▎      | 20/60 [2:43:16<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.136 Val loss 9.193\n",
      "\r 33%|███▎      | 20/60 [2:44:06<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 185 best_val_loss 8.624\n",
      "\r 33%|███▎      | 20/60 [2:44:55<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 33%|███▎      | 20/60 [2:44:55<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.697 Val loss 21.420\n",
      "\r 33%|███▎      | 20/60 [2:44:59<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.124 Val loss 10.214\n",
      "\r 33%|███▎      | 20/60 [2:45:52<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 190 best_val_loss 8.961\n",
      "\r 33%|███▎      | 20/60 [2:46:45<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 33%|███▎      | 20/60 [2:46:45<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.769 Val loss 19.762\n",
      "\r 33%|███▎      | 20/60 [2:46:50<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.738 Val loss 10.080\n",
      "\r 33%|███▎      | 20/60 [2:47:40<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 186 best_val_loss 9.478\n",
      "\r 33%|███▎      | 20/60 [2:48:26<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 33%|███▎      | 20/60 [2:48:26<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.807 Val loss 20.305\n",
      "\r 33%|███▎      | 20/60 [2:48:29<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.338 Val loss 10.113\n",
      "\r 33%|███▎      | 20/60 [2:49:21<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 187 best_val_loss 9.379\n",
      "\r 33%|███▎      | 20/60 [2:50:07<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.18997\n",
      "\n",
      "\r 33%|███▎      | 20/60 [2:50:07<4:28:18, 402.46s/trial, best loss: 8.93785142164964]\r 35%|███▌      | 21/60 [2:50:07<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.15698076733875543, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.09798284328668512, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.0007127793247655958, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.21949097705917958}\n",
      "\r 35%|███▌      | 21/60 [2:50:07<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 35%|███▌      | 21/60 [2:50:07<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.416 Val loss 22.645\n",
      "\r 35%|███▌      | 21/60 [2:50:11<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.795 Val loss 10.270\n",
      "\r 35%|███▌      | 21/60 [2:51:04<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 182 best_val_loss 9.434\n",
      "\r 35%|███▌      | 21/60 [2:51:51<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 35%|███▌      | 21/60 [2:51:51<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.518 Val loss 20.743\n",
      "\r 35%|███▌      | 21/60 [2:51:55<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.718 Val loss 9.780\n",
      "\r 35%|███▌      | 21/60 [2:52:52<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 198 best_val_loss 8.543\n",
      "\r 35%|███▌      | 21/60 [2:53:39<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 35%|███▌      | 21/60 [2:53:39<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.586 Val loss 21.115\n",
      "\r 35%|███▌      | 21/60 [2:53:43<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.746 Val loss 9.824\n",
      "\r 35%|███▌      | 21/60 [2:54:27<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 195 best_val_loss 8.740\n",
      "\r 35%|███▌      | 21/60 [2:55:23<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 35%|███▌      | 21/60 [2:55:23<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.584 Val loss 20.444\n",
      "\r 35%|███▌      | 21/60 [2:55:27<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.318 Val loss 10.183\n",
      "\r 35%|███▌      | 21/60 [2:56:21<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 186 best_val_loss 9.477\n",
      "\r 35%|███▌      | 21/60 [2:57:14<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 35%|███▌      | 21/60 [2:57:14<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.586 Val loss 20.842\n",
      "\r 35%|███▌      | 21/60 [2:57:17<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 7.836 Val loss 10.479\n",
      "\r 35%|███▌      | 21/60 [2:58:10<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 186 best_val_loss 9.298\n",
      "\r 35%|███▌      | 21/60 [2:59:04<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 9.09845\n",
      "\n",
      "\r 35%|███▌      | 21/60 [2:59:04<4:44:31, 437.72s/trial, best loss: 8.93785142164964]\r 37%|███▋      | 22/60 [2:59:04<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.1833700562488127, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.302924694543007, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0009861557916851951, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7951647654479451}\n",
      "\r 37%|███▋      | 22/60 [2:59:04<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 37%|███▋      | 22/60 [2:59:04<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 20.990 Val loss 21.379\n",
      "\r 37%|███▋      | 22/60 [2:59:08<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.717 Val loss 10.927\n",
      "\r 37%|███▋      | 22/60 [3:00:06<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.802 Val loss 9.752\n",
      "\r 37%|███▋      | 22/60 [3:01:12<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 298 best_val_loss 9.289\n",
      "\r 37%|███▋      | 22/60 [3:02:20<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 37%|███▋      | 22/60 [3:02:20<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.209 Val loss 20.972\n",
      "\r 37%|███▋      | 22/60 [3:02:24<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.902 Val loss 9.866\n",
      "\r 37%|███▋      | 22/60 [3:03:18<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.983 Val loss 8.920\n",
      "\r 37%|███▋      | 22/60 [3:04:29<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 284 best_val_loss 8.464\n",
      "\r 37%|███▋      | 22/60 [3:05:39<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 37%|███▋      | 22/60 [3:05:39<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.255 Val loss 20.064\n",
      "\r 37%|███▋      | 22/60 [3:05:43<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.045 Val loss 9.934\n",
      "\r 37%|███▋      | 22/60 [3:06:53<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.985 Val loss 9.247\n",
      "\r 37%|███▋      | 22/60 [3:07:49<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 297 best_val_loss 8.667\n",
      "\r 37%|███▋      | 22/60 [3:08:48<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 37%|███▋      | 22/60 [3:08:48<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.279 Val loss 19.766\n",
      "\r 37%|███▋      | 22/60 [3:08:52<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.985 Val loss 10.638\n",
      "\r 37%|███▋      | 22/60 [3:09:52<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.778 Val loss 9.887\n",
      "\r 37%|███▋      | 22/60 [3:10:53<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 277 best_val_loss 9.267\n",
      "\r 37%|███▋      | 22/60 [3:11:55<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 37%|███▋      | 22/60 [3:11:55<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.341 Val loss 19.951\n",
      "\r 37%|███▋      | 22/60 [3:11:58<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.210 Val loss 10.890\n",
      "\r 37%|███▋      | 22/60 [3:13:06<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 7.200 Val loss 9.578\n",
      "\r 37%|███▋      | 22/60 [3:14:03<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 283 best_val_loss 9.133\n",
      "\r 37%|███▋      | 22/60 [3:15:13<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 8.96409\n",
      "\n",
      "\r 37%|███▋      | 22/60 [3:15:13<4:56:08, 467.59s/trial, best loss: 8.93785142164964]\r 38%|███▊      | 23/60 [3:15:13<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.20717600898815336, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.3014621439093969, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0009951564831559717, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8446885898544286}\n",
      "\r 38%|███▊      | 23/60 [3:15:13<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 1/5\n",
      "\r 38%|███▊      | 23/60 [3:15:13<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.384 Val loss 22.565\n",
      "\r 38%|███▊      | 23/60 [3:15:17<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.684 Val loss 10.743\n",
      "\r 38%|███▊      | 23/60 [3:16:26<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.775 Val loss 9.654\n",
      "\r 38%|███▊      | 23/60 [3:17:20<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 294 best_val_loss 9.294\n",
      "\r 38%|███▊      | 23/60 [3:18:26<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 2/5\n",
      "\r 38%|███▊      | 23/60 [3:18:26<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.716 Val loss 21.484\n",
      "\r 38%|███▊      | 23/60 [3:18:30<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.762 Val loss 9.423\n",
      "\r 38%|███▊      | 23/60 [3:19:35<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.951 Val loss 8.702\n",
      "\r 38%|███▊      | 23/60 [3:20:30<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 274 best_val_loss 8.381\n",
      "\r 38%|███▊      | 23/60 [3:21:29<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 3/5\n",
      "\r 38%|███▊      | 23/60 [3:21:29<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.680 Val loss 20.873\n",
      "\r 38%|███▊      | 23/60 [3:21:33<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.109 Val loss 10.119\n",
      "\r 38%|███▊      | 23/60 [3:22:24<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.951 Val loss 8.891\n",
      "\r 38%|███▊      | 23/60 [3:23:25<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 288 best_val_loss 8.566\n",
      "\r 38%|███▊      | 23/60 [3:24:18<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 4/5\n",
      "\r 38%|███▊      | 23/60 [3:24:18<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.888 Val loss 20.312\n",
      "\r 38%|███▊      | 23/60 [3:24:22<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 8.812 Val loss 10.714\n",
      "\r 38%|███▊      | 23/60 [3:25:26<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 6.753 Val loss 9.729\n",
      "\r 38%|███▊      | 23/60 [3:26:25<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEarly stopped at epoch 258 best_val_loss 9.468\n",
      "\r 38%|███▊      | 23/60 [3:27:17<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rFold: 5/5\n",
      "\r 38%|███▊      | 23/60 [3:27:17<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 0 Train loss 21.985 Val loss 20.855\n",
      "\r 38%|███▊      | 23/60 [3:27:21<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 100 Train loss 9.122 Val loss 10.904\n",
      "\r 38%|███▊      | 23/60 [3:28:30<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rEpoch 200 Train loss 7.035 Val loss 9.452\n",
      "\r 38%|███▊      | 23/60 [3:29:40<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rStopped at epoch 293 best_val_loss 8.964\n",
      "\r 38%|███▊      | 23/60 [3:30:51<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r                                                                                    \rval MSE loss mean: 8.93464\n",
      "\n",
      "\r 38%|███▊      | 23/60 [3:30:51<6:21:03, 617.94s/trial, best loss: 8.93785142164964]\r 40%|████      | 24/60 [3:30:51<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.21167779347973947, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.40261840258429676, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000840522087303575, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8712174245311994}\n",
      "\r 40%|████      | 24/60 [3:30:51<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 1/5\n",
      "\r 40%|████      | 24/60 [3:30:51<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.719 Val loss 22.592\n",
      "\r 40%|████      | 24/60 [3:30:55<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 8.947 Val loss 10.806\n",
      "\r 40%|████      | 24/60 [3:31:57<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 6.904 Val loss 9.820\n",
      "\r 40%|████      | 24/60 [3:33:03<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 278 best_val_loss 9.353\n",
      "\r 40%|████      | 24/60 [3:34:02<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 2/5\n",
      "\r 40%|████      | 24/60 [3:34:02<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.977 Val loss 21.030\n",
      "\r 40%|████      | 24/60 [3:34:06<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 9.377 Val loss 9.947\n",
      "\r 40%|████      | 24/60 [3:35:16<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 7.253 Val loss 8.818\n",
      "\r 40%|████      | 24/60 [3:36:25<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 287 best_val_loss 8.553\n",
      "\r 40%|████      | 24/60 [3:37:23<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 3/5\n",
      "\r 40%|████      | 24/60 [3:37:23<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.954 Val loss 21.499\n",
      "\r 40%|████      | 24/60 [3:37:27<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 9.269 Val loss 10.317\n",
      "\r 40%|████      | 24/60 [3:38:32<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 7.055 Val loss 9.220\n",
      "\r 40%|████      | 24/60 [3:39:38<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEarly stopped at epoch 252 best_val_loss 9.021\n",
      "\r 40%|████      | 24/60 [3:40:35<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 4/5\n",
      "\r 40%|████      | 24/60 [3:40:35<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.046 Val loss 20.920\n",
      "\r 40%|████      | 24/60 [3:40:40<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 8.842 Val loss 11.580\n",
      "\r 40%|████      | 24/60 [3:41:43<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 6.841 Val loss 9.729\n",
      "\r 40%|████      | 24/60 [3:42:46<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEarly stopped at epoch 266 best_val_loss 9.216\n",
      "\r 40%|████      | 24/60 [3:43:45<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 5/5\n",
      "\r 40%|████      | 24/60 [3:43:45<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.132 Val loss 20.576\n",
      "\r 40%|████      | 24/60 [3:43:49<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 9.209 Val loss 10.687\n",
      "\r 40%|████      | 24/60 [3:44:55<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 6.986 Val loss 9.443\n",
      "\r 40%|████      | 24/60 [3:46:02<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 293 best_val_loss 9.199\n",
      "\r 40%|████      | 24/60 [3:46:59<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r                                                                                     \rval MSE loss mean: 9.06849\n",
      "\n",
      "\r 40%|████      | 24/60 [3:46:59<7:08:20, 713.89s/trial, best loss: 8.934636864295372]\r 42%|████▏     | 25/60 [3:46:59<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.34641953877967496, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.4228035168999799, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000997798924492797, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.705718152218555}\n",
      "\r 42%|████▏     | 25/60 [3:46:59<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 1/5\n",
      "\r 42%|████▏     | 25/60 [3:46:59<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.001 Val loss 22.842\n",
      "\r 42%|████▏     | 25/60 [3:47:03<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 10.562 Val loss 11.971\n",
      "\r 42%|████▏     | 25/60 [3:48:15<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 8.349 Val loss 10.577\n",
      "\r 42%|████▏     | 25/60 [3:49:15<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 287 best_val_loss 10.002\n",
      "\r 42%|████▏     | 25/60 [3:50:22<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 2/5\n",
      "\r 42%|████▏     | 25/60 [3:50:22<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.089 Val loss 21.084\n",
      "\r 42%|████▏     | 25/60 [3:50:26<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 10.670 Val loss 10.380\n",
      "\r 42%|████▏     | 25/60 [3:51:20<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 8.516 Val loss 9.237\n",
      "\r 42%|████▏     | 25/60 [3:52:31<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 299 best_val_loss 8.833\n",
      "\r 42%|████▏     | 25/60 [3:53:26<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 3/5\n",
      "\r 42%|████▏     | 25/60 [3:53:26<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.122 Val loss 21.575\n",
      "\r 42%|████▏     | 25/60 [3:53:29<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 10.619 Val loss 11.057\n",
      "\r 42%|████▏     | 25/60 [3:54:32<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 8.295 Val loss 9.779\n",
      "\r 42%|████▏     | 25/60 [3:55:24<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 271 best_val_loss 9.410\n",
      "\r 42%|████▏     | 25/60 [3:56:31<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 4/5\n",
      "\r 42%|████▏     | 25/60 [3:56:31<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.220 Val loss 20.522\n",
      "\r 42%|████▏     | 25/60 [3:56:35<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 10.500 Val loss 11.428\n",
      "\r 42%|████▏     | 25/60 [3:57:42<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 8.079 Val loss 10.295\n",
      "\r 42%|████▏     | 25/60 [3:58:56<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 299 best_val_loss 9.761\n",
      "\r 42%|████▏     | 25/60 [4:00:07<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 5/5\n",
      "\r 42%|████▏     | 25/60 [4:00:07<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.279 Val loss 20.699\n",
      "\r 42%|████▏     | 25/60 [4:00:11<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 10.849 Val loss 11.629\n",
      "\r 42%|████▏     | 25/60 [4:01:21<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 8.439 Val loss 10.049\n",
      "\r 42%|████▏     | 25/60 [4:02:35<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 293 best_val_loss 9.648\n",
      "\r 42%|████▏     | 25/60 [4:03:42<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r                                                                                     \rval MSE loss mean: 9.53077\n",
      "\n",
      "\r 42%|████▏     | 25/60 [4:03:42<7:41:03, 790.38s/trial, best loss: 8.934636864295372]\r 43%|████▎     | 26/60 [4:03:42<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.08737024931921095, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.31126922541697244, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0005221251038770079, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6596446096427024}\n",
      "\r 43%|████▎     | 26/60 [4:03:42<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 1/5\n",
      "\r 43%|████▎     | 26/60 [4:03:42<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.652 Val loss 22.772\n",
      "\r 43%|████▎     | 26/60 [4:03:46<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 7.568 Val loss 10.724\n",
      "\r 43%|████▎     | 26/60 [4:04:54<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 5.482 Val loss 9.292\n",
      "\r 43%|████▎     | 26/60 [4:06:02<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEarly stopped at epoch 212 best_val_loss 8.928\n",
      "\r 43%|████▎     | 26/60 [4:06:30<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 2/5\n",
      "\r 43%|████▎     | 26/60 [4:06:30<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.939 Val loss 21.082\n",
      "\r 43%|████▎     | 26/60 [4:06:34<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 7.678 Val loss 9.490\n",
      "\r 43%|████▎     | 26/60 [4:07:42<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 5.738 Val loss 8.651\n",
      "\r 43%|████▎     | 26/60 [4:08:40<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEarly stopped at epoch 244 best_val_loss 8.484\n",
      "\r 43%|████▎     | 26/60 [4:09:28<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 3/5\n",
      "\r 43%|████▎     | 26/60 [4:09:28<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.837 Val loss 21.196\n",
      "\r 43%|████▎     | 26/60 [4:09:31<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 7.722 Val loss 9.877\n",
      "\r 43%|████▎     | 26/60 [4:10:31<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 5.629 Val loss 8.563\n",
      "\r 43%|████▎     | 26/60 [4:11:25<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 278 best_val_loss 8.231\n",
      "\r 43%|████▎     | 26/60 [4:12:25<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 4/5\n",
      "\r 43%|████▎     | 26/60 [4:12:25<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 21.956 Val loss 21.217\n",
      "\r 43%|████▎     | 26/60 [4:12:29<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 7.409 Val loss 10.160\n",
      "\r 43%|████▎     | 26/60 [4:13:34<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 5.399 Val loss 9.438\n",
      "\r 43%|████▎     | 26/60 [4:14:41<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 273 best_val_loss 9.072\n",
      "\r 43%|████▎     | 26/60 [4:15:46<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rFold: 5/5\n",
      "\r 43%|████▎     | 26/60 [4:15:46<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 0 Train loss 22.079 Val loss 20.560\n",
      "\r 43%|████▎     | 26/60 [4:15:49<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 100 Train loss 7.652 Val loss 10.706\n",
      "\r 43%|████▎     | 26/60 [4:16:55<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rEpoch 200 Train loss 5.524 Val loss 9.288\n",
      "\r 43%|████▎     | 26/60 [4:18:00<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rStopped at epoch 293 best_val_loss 8.874\n",
      "\r 43%|████▎     | 26/60 [4:18:53<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r                                                                                     \rval MSE loss mean: 8.71757\n",
      "\n",
      "\r 43%|████▎     | 26/60 [4:18:53<8:03:53, 853.94s/trial, best loss: 8.934636864295372]\r 45%|████▌     | 27/60 [4:18:53<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.10109755869938028, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.301822545063468, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0004624037275480181, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6539365364899532}\n",
      "\r 45%|████▌     | 27/60 [4:18:53<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 45%|████▌     | 27/60 [4:18:53<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.661 Val loss 22.337\n",
      "\r 45%|████▌     | 27/60 [4:18:57<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.744 Val loss 11.097\n",
      "\r 45%|████▌     | 27/60 [4:20:05<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.664 Val loss 9.358\n",
      "\r 45%|████▌     | 27/60 [4:21:02<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 225 best_val_loss 9.151\n",
      "\r 45%|████▌     | 27/60 [4:21:33<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 45%|████▌     | 27/60 [4:21:33<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.966 Val loss 20.896\n",
      "\r 45%|████▌     | 27/60 [4:21:37<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.972 Val loss 9.193\n",
      "\r 45%|████▌     | 27/60 [4:22:31<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.767 Val loss 8.500\n",
      "\r 45%|████▌     | 27/60 [4:23:25<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 206 best_val_loss 8.334\n",
      "\r 45%|████▌     | 27/60 [4:23:50<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 45%|████▌     | 27/60 [4:23:50<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.838 Val loss 22.130\n",
      "\r 45%|████▌     | 27/60 [4:23:55<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.041 Val loss 10.072\n",
      "\r 45%|████▌     | 27/60 [4:25:00<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.781 Val loss 8.945\n",
      "\r 45%|████▌     | 27/60 [4:26:00<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 297 best_val_loss 8.348\n",
      "\r 45%|████▌     | 27/60 [4:27:04<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 45%|████▌     | 27/60 [4:27:04<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.043 Val loss 20.851\n",
      "\r 45%|████▌     | 27/60 [4:27:08<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.497 Val loss 10.145\n",
      "\r 45%|████▌     | 27/60 [4:28:08<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.571 Val loss 9.295\n",
      "\r 45%|████▌     | 27/60 [4:29:08<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 211 best_val_loss 9.118\n",
      "\r 45%|████▌     | 27/60 [4:29:36<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 45%|████▌     | 27/60 [4:29:36<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.036 Val loss 21.251\n",
      "\r 45%|████▌     | 27/60 [4:29:40<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.179 Val loss 11.083\n",
      "\r 45%|████▌     | 27/60 [4:30:47<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.707 Val loss 9.106\n",
      "\r 45%|████▌     | 27/60 [4:31:43<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 229 best_val_loss 8.965\n",
      "\r 45%|████▌     | 27/60 [4:32:24<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 8.78317\n",
      "\n",
      "\r 45%|████▌     | 27/60 [4:32:24<7:59:08, 871.17s/trial, best loss: 8.717567209097055]\r 47%|████▋     | 28/60 [4:32:24<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.11062591904370614, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.21535513001588943, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000529602866486694, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6399347227648545}\n",
      "\r 47%|████▋     | 28/60 [4:32:24<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 47%|████▋     | 28/60 [4:32:24<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.253 Val loss 23.325\n",
      "\r 47%|████▋     | 28/60 [4:32:28<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 9.260 Val loss 11.179\n",
      "\r 47%|████▋     | 28/60 [4:32:55<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.043 Val loss 9.826\n",
      "\r 47%|████▋     | 28/60 [4:33:21<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 222 best_val_loss 9.479\n",
      "\r 47%|████▋     | 28/60 [4:33:35<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 47%|████▋     | 28/60 [4:33:35<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.142 Val loss 21.662\n",
      "\r 47%|████▋     | 28/60 [4:33:39<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 9.059 Val loss 9.728\n",
      "\r 47%|████▋     | 28/60 [4:34:07<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.037 Val loss 8.517\n",
      "\r 47%|████▋     | 28/60 [4:34:35<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 251 best_val_loss 8.091\n",
      "\r 47%|████▋     | 28/60 [4:34:58<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 47%|████▋     | 28/60 [4:34:58<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.072 Val loss 21.921\n",
      "\r 47%|████▋     | 28/60 [4:35:02<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 9.043 Val loss 10.941\n",
      "\r 47%|████▋     | 28/60 [4:35:32<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.978 Val loss 9.487\n",
      "\r 47%|████▋     | 28/60 [4:36:00<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 293 best_val_loss 9.050\n",
      "\r 47%|████▋     | 28/60 [4:36:27<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 47%|████▋     | 28/60 [4:36:27<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.350 Val loss 20.751\n",
      "\r 47%|████▋     | 28/60 [4:36:30<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.667 Val loss 10.814\n",
      "\r 47%|████▋     | 28/60 [4:36:58<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.761 Val loss 9.660\n",
      "\r 47%|████▋     | 28/60 [4:37:26<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 228 best_val_loss 9.179\n",
      "\r 47%|████▋     | 28/60 [4:37:42<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 47%|████▋     | 28/60 [4:37:42<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.357 Val loss 20.547\n",
      "\r 47%|████▋     | 28/60 [4:37:46<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.744 Val loss 11.539\n",
      "\r 47%|████▋     | 28/60 [4:38:14<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.906 Val loss 9.713\n",
      "\r 47%|████▋     | 28/60 [4:38:42<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 276 best_val_loss 9.570\n",
      "\r 47%|████▋     | 28/60 [4:39:08<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 9.07368\n",
      "\n",
      "\r 47%|████▋     | 28/60 [4:39:08<7:35:03, 853.22s/trial, best loss: 8.717567209097055]\r 48%|████▊     | 29/60 [4:39:08<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.06784434842820367, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.3060730023054156, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00046517163731519135, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6793968111308506}\n",
      "\r 48%|████▊     | 29/60 [4:39:08<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 48%|████▊     | 29/60 [4:39:08<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.577 Val loss 21.745\n",
      "\r 48%|████▊     | 29/60 [4:39:12<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.321 Val loss 11.263\n",
      "\r 48%|████▊     | 29/60 [4:40:18<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.203 Val loss 9.499\n",
      "\r 48%|████▊     | 29/60 [4:43:24<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 298 best_val_loss 9.100\n",
      "\r 48%|████▊     | 29/60 [4:45:59<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 48%|████▊     | 29/60 [4:45:59<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.838 Val loss 20.235\n",
      "\r 48%|████▊     | 29/60 [4:46:10<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.480 Val loss 9.652\n",
      "\r 48%|████▊     | 29/60 [4:48:38<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.352 Val loss 8.712\n",
      "\r 48%|████▊     | 29/60 [4:50:54<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 201 best_val_loss 8.469\n",
      "\r 48%|████▊     | 29/60 [4:51:39<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 48%|████▊     | 29/60 [4:51:39<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.763 Val loss 21.081\n",
      "\r 48%|████▊     | 29/60 [4:51:46<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.563 Val loss 10.671\n",
      "\r 48%|████▊     | 29/60 [4:53:19<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.276 Val loss 8.822\n",
      "\r 48%|████▊     | 29/60 [4:54:13<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 268 best_val_loss 8.322\n",
      "\r 48%|████▊     | 29/60 [4:55:01<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 48%|████▊     | 29/60 [4:55:01<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.979 Val loss 19.775\n",
      "\r 48%|████▊     | 29/60 [4:55:06<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.250 Val loss 10.651\n",
      "\r 48%|████▊     | 29/60 [4:56:11<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 108 best_val_loss 9.976\n",
      "\r 48%|████▊     | 29/60 [4:56:31<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 48%|████▊     | 29/60 [4:56:31<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.037 Val loss 20.531\n",
      "\r 48%|████▊     | 29/60 [4:56:35<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.688 Val loss 10.658\n",
      "\r 48%|████▊     | 29/60 [4:57:47<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.225 Val loss 9.521\n",
      "\r 48%|████▊     | 29/60 [4:58:55<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 236 best_val_loss 9.159\n",
      "\r 48%|████▊     | 29/60 [4:59:34<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 9.00521\n",
      "\n",
      "\r 48%|████▊     | 29/60 [4:59:34<6:11:11, 718.43s/trial, best loss: 8.717567209097055]\r 50%|█████     | 30/60 [4:59:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.005956606572678838, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.21539899956509545, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.00017150916771336032, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.2874688494395946}\n",
      "\r 50%|█████     | 30/60 [4:59:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 50%|█████     | 30/60 [4:59:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.566 Val loss 23.930\n",
      "\r 50%|█████     | 30/60 [4:59:38<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.221 Val loss 11.482\n",
      "\r 50%|█████     | 30/60 [5:00:51<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.829 Val loss 10.050\n",
      "\r 50%|█████     | 30/60 [5:02:06<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.858 Val loss 9.125\n",
      "\r 50%|█████     | 30/60 [5:03:15<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 391 best_val_loss 8.857\n",
      "\r 50%|█████     | 30/60 [5:04:36<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 50%|█████     | 30/60 [5:04:36<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.905 Val loss 21.890\n",
      "\r 50%|█████     | 30/60 [5:04:40<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.770 Val loss 19.866\n",
      "\r 50%|█████     | 30/60 [5:06:04<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.122 Val loss 13.281\n",
      "\r 50%|█████     | 30/60 [5:07:27<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 231 best_val_loss 8.665\n",
      "\r 50%|█████     | 30/60 [5:08:14<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 50%|█████     | 30/60 [5:08:15<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.909 Val loss 22.655\n",
      "\r 50%|█████     | 30/60 [5:08:18<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.988 Val loss 10.696\n",
      "\r 50%|█████     | 30/60 [5:09:40<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 133 best_val_loss 9.991\n",
      "\r 50%|█████     | 30/60 [5:10:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 50%|█████     | 30/60 [5:10:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.999 Val loss 20.859\n",
      "\r 50%|█████     | 30/60 [5:10:38<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.621 Val loss 11.649\n",
      "\r 50%|█████     | 30/60 [5:11:56<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.003 Val loss 10.472\n",
      "\r 50%|█████     | 30/60 [5:13:10<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 191 best_val_loss 9.707\n",
      "\r 50%|█████     | 30/60 [5:13:29<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 50%|█████     | 30/60 [5:13:29<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.140 Val loss 21.017\n",
      "\r 50%|█████     | 30/60 [5:13:33<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.915 Val loss 12.347\n",
      "\r 50%|█████     | 30/60 [5:14:49<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.029 Val loss 10.328\n",
      "\r 50%|█████     | 30/60 [5:16:08<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.971 Val loss 9.178\n",
      "\r 50%|█████     | 30/60 [5:17:29<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 275 best_val_loss 9.017\n",
      "\r 50%|█████     | 30/60 [5:17:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 9.24747\n",
      "\n",
      "\r 50%|█████     | 30/60 [5:17:34<7:15:18, 870.62s/trial, best loss: 8.717567209097055]\r 52%|█████▏    | 31/60 [5:17:34<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.11686063034582332, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.27877532421000967, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000220487837408281, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.4962698422677321}\n",
      "\r 52%|█████▏    | 31/60 [5:17:34<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 52%|█████▏    | 31/60 [5:17:34<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.953 Val loss 22.302\n",
      "\r 52%|█████▏    | 31/60 [5:17:38<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 9.265 Val loss 11.424\n",
      "\r 52%|█████▏    | 31/60 [5:19:00<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.979 Val loss 9.444\n",
      "\r 52%|█████▏    | 31/60 [5:20:21<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 280 best_val_loss 9.164\n",
      "\r 52%|█████▏    | 31/60 [5:21:41<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 52%|█████▏    | 31/60 [5:21:41<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.218 Val loss 22.231\n",
      "\r 52%|█████▏    | 31/60 [5:21:46<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 9.856 Val loss 10.401\n",
      "\r 52%|█████▏    | 31/60 [5:23:03<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.385 Val loss 8.891\n",
      "\r 52%|█████▏    | 31/60 [5:24:25<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 272 best_val_loss 8.244\n",
      "\r 52%|█████▏    | 31/60 [5:25:42<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 52%|█████▏    | 31/60 [5:25:42<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.126 Val loss 21.851\n",
      "\r 52%|█████▏    | 31/60 [5:25:47<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 10.463 Val loss 11.245\n",
      "\r 52%|█████▏    | 31/60 [5:27:06<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.575 Val loss 9.073\n",
      "\r 52%|█████▏    | 31/60 [5:28:30<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 294 best_val_loss 8.647\n",
      "\r 52%|█████▏    | 31/60 [5:29:55<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 52%|█████▏    | 31/60 [5:29:55<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.288 Val loss 21.771\n",
      "\r 52%|█████▏    | 31/60 [5:29:59<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 10.595 Val loss 12.125\n",
      "\r 52%|█████▏    | 31/60 [5:31:26<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.545 Val loss 9.732\n",
      "\r 52%|█████▏    | 31/60 [5:32:46<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 280 best_val_loss 9.340\n",
      "\r 52%|█████▏    | 31/60 [5:34:02<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 52%|█████▏    | 31/60 [5:34:02<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.263 Val loss 20.249\n",
      "\r 52%|█████▏    | 31/60 [5:34:07<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 10.460 Val loss 11.932\n",
      "\r 52%|█████▏    | 31/60 [5:35:21<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.520 Val loss 9.609\n",
      "\r 52%|█████▏    | 31/60 [5:36:37<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 293 best_val_loss 9.169\n",
      "\r 52%|█████▏    | 31/60 [5:37:54<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 8.91282\n",
      "\n",
      "\r 52%|█████▏    | 31/60 [5:37:54<7:31:09, 933.43s/trial, best loss: 8.717567209097055]\r 53%|█████▎    | 32/60 [5:37:54<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.25396188612869597, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.3808136294516007, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00035159080527576327, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8779121631127946}\n",
      "\r 53%|█████▎    | 32/60 [5:37:54<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 1/5\n",
      "\r 53%|█████▎    | 32/60 [5:37:54<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.027 Val loss 22.850\n",
      "\r 53%|█████▎    | 32/60 [5:37:58<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 11.598 Val loss 12.696\n",
      "\r 53%|█████▎    | 32/60 [5:39:06<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 7.454 Val loss 9.859\n",
      "\r 53%|█████▎    | 32/60 [5:40:09<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rStopped at epoch 299 best_val_loss 9.490\n",
      "\r 53%|█████▎    | 32/60 [5:41:08<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 2/5\n",
      "\r 53%|█████▎    | 32/60 [5:41:08<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.337 Val loss 21.780\n",
      "\r 53%|█████▎    | 32/60 [5:41:12<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 11.555 Val loss 11.261\n",
      "\r 53%|█████▎    | 32/60 [5:42:23<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 7.446 Val loss 8.848\n",
      "\r 53%|█████▎    | 32/60 [5:43:34<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rStopped at epoch 298 best_val_loss 8.499\n",
      "\r 53%|█████▎    | 32/60 [5:44:44<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 3/5\n",
      "\r 53%|█████▎    | 32/60 [5:44:44<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.211 Val loss 22.339\n",
      "\r 53%|█████▎    | 32/60 [5:44:48<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 11.693 Val loss 12.337\n",
      "\r 53%|█████▎    | 32/60 [5:45:55<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 7.506 Val loss 9.492\n",
      "\r 53%|█████▎    | 32/60 [5:47:04<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rStopped at epoch 287 best_val_loss 8.965\n",
      "\r 53%|█████▎    | 32/60 [5:48:07<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 4/5\n",
      "\r 53%|█████▎    | 32/60 [5:48:07<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.463 Val loss 21.133\n",
      "\r 53%|█████▎    | 32/60 [5:48:11<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 10.964 Val loss 11.608\n",
      "\r 53%|█████▎    | 32/60 [5:49:27<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 7.211 Val loss 9.902\n",
      "\r 53%|█████▎    | 32/60 [5:50:39<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rStopped at epoch 290 best_val_loss 9.524\n",
      "\r 53%|█████▎    | 32/60 [5:51:43<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 5/5\n",
      "\r 53%|█████▎    | 32/60 [5:51:43<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.543 Val loss 21.337\n",
      "\r 53%|█████▎    | 32/60 [5:51:47<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 12.052 Val loss 12.486\n",
      "\r 53%|█████▎    | 32/60 [5:53:01<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 7.513 Val loss 9.899\n",
      "\r 53%|█████▎    | 32/60 [5:54:17<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rStopped at epoch 293 best_val_loss 9.451\n",
      "\r 53%|█████▎    | 32/60 [5:55:22<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r                                                                                      \rval MSE loss mean: 9.18596\n",
      "\n",
      "\r 53%|█████▎    | 32/60 [5:55:22<7:55:43, 1019.41s/trial, best loss: 8.717567209097055]\r 55%|█████▌    | 33/60 [5:55:22<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.08066738779268025, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.2063548570751166, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00044190724288049204, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7270296332471297}\n",
      "\r 55%|█████▌    | 33/60 [5:55:22<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 1/5\n",
      "\r 55%|█████▌    | 33/60 [5:55:22<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.121 Val loss 23.093\n",
      "\r 55%|█████▌    | 33/60 [5:55:26<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 9.089 Val loss 11.233\n",
      "\r 55%|█████▌    | 33/60 [5:55:57<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 5.717 Val loss 9.534\n",
      "\r 55%|█████▌    | 33/60 [5:56:27<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEarly stopped at epoch 247 best_val_loss 9.040\n",
      "\r 55%|█████▌    | 33/60 [5:56:50<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 2/5\n",
      "\r 55%|█████▌    | 33/60 [5:56:50<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.090 Val loss 22.124\n",
      "\r 55%|█████▌    | 33/60 [5:56:53<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 8.842 Val loss 9.755\n",
      "\r 55%|█████▌    | 33/60 [5:57:23<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEarly stopped at epoch 154 best_val_loss 8.249\n",
      "\r 55%|█████▌    | 33/60 [5:57:47<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 3/5\n",
      "\r 55%|█████▌    | 33/60 [5:57:47<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.003 Val loss 21.977\n",
      "\r 55%|█████▌    | 33/60 [5:57:51<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 8.986 Val loss 11.062\n",
      "\r 55%|█████▌    | 33/60 [5:58:20<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 5.783 Val loss 9.473\n",
      "\r 55%|█████▌    | 33/60 [5:58:46<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEarly stopped at epoch 226 best_val_loss 9.188\n",
      "\r 55%|█████▌    | 33/60 [5:59:02<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 4/5\n",
      "\r 55%|█████▌    | 33/60 [5:59:02<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.366 Val loss 20.451\n",
      "\r 55%|█████▌    | 33/60 [5:59:06<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 8.409 Val loss 10.714\n",
      "\r 55%|█████▌    | 33/60 [5:59:37<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 5.657 Val loss 9.279\n",
      "\r 55%|█████▌    | 33/60 [6:00:06<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEarly stopped at epoch 209 best_val_loss 8.838\n",
      "\r 55%|█████▌    | 33/60 [6:00:19<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rFold: 5/5\n",
      "\r 55%|█████▌    | 33/60 [6:00:19<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 0 Train loss 22.266 Val loss 20.662\n",
      "\r 55%|█████▌    | 33/60 [6:00:23<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 100 Train loss 8.915 Val loss 11.271\n",
      "\r 55%|█████▌    | 33/60 [6:00:53<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEpoch 200 Train loss 5.926 Val loss 10.350\n",
      "\r 55%|█████▌    | 33/60 [6:01:21<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rEarly stopped at epoch 236 best_val_loss 9.600\n",
      "\r 55%|█████▌    | 33/60 [6:01:41<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r                                                                                      \rval MSE loss mean: 8.98298\n",
      "\n",
      "\r 55%|█████▌    | 33/60 [6:01:41<7:42:35, 1027.99s/trial, best loss: 8.717567209097055]\r 57%|█████▋    | 34/60 [6:01:41<6:01:05, 833.29s/trial, best loss: 8.717567209097055] \r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.0289494683814763, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.4438948723503384, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0005785306405108856, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6494091266531659}\n",
      "\r 57%|█████▋    | 34/60 [6:01:41<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 57%|█████▋    | 34/60 [6:01:41<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 20.930 Val loss 22.708\n",
      "\r 57%|█████▋    | 34/60 [6:01:45<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 61 best_val_loss 10.537\n",
      "\r 57%|█████▋    | 34/60 [6:02:41<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 57%|█████▋    | 34/60 [6:02:41<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.123 Val loss 20.700\n",
      "\r 57%|█████▋    | 34/60 [6:02:45<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.640 Val loss 10.119\n",
      "\r 57%|█████▋    | 34/60 [6:03:47<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 74 best_val_loss 9.422\n",
      "\r 57%|█████▋    | 34/60 [6:03:51<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 57%|█████▋    | 34/60 [6:03:51<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.281 Val loss 21.665\n",
      "\r 57%|█████▋    | 34/60 [6:03:55<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.676 Val loss 12.290\n",
      "\r 57%|█████▋    | 34/60 [6:04:53<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 4.625 Val loss 9.538\n",
      "\r 57%|█████▋    | 34/60 [6:06:01<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 217 best_val_loss 8.397\n",
      "\r 57%|█████▋    | 34/60 [6:06:32<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 57%|█████▋    | 34/60 [6:06:32<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.192 Val loss 20.058\n",
      "\r 57%|█████▋    | 34/60 [6:06:36<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.429 Val loss 10.595\n",
      "\r 57%|█████▋    | 34/60 [6:07:44<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 4.498 Val loss 10.107\n",
      "\r 57%|█████▋    | 34/60 [6:08:46<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 298 best_val_loss 8.916\n",
      "\r 57%|█████▋    | 34/60 [6:09:52<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 57%|█████▋    | 34/60 [6:09:52<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.500 Val loss 20.560\n",
      "\r 57%|█████▋    | 34/60 [6:09:56<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.730 Val loss 12.142\n",
      "\r 57%|█████▋    | 34/60 [6:11:04<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 4.885 Val loss 10.036\n",
      "\r 57%|█████▋    | 34/60 [6:12:14<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 220 best_val_loss 9.166\n",
      "\r 57%|█████▋    | 34/60 [6:12:49<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 9.28729\n",
      "\n",
      "\r 57%|█████▋    | 34/60 [6:12:49<6:01:05, 833.29s/trial, best loss: 8.717567209097055]\r 58%|█████▊    | 35/60 [6:12:49<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.04143572976648039, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.15635123404467557, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.0006678850086718243, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7762736919479498}\n",
      "\r 58%|█████▊    | 35/60 [6:12:49<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 58%|█████▊    | 35/60 [6:12:49<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.270 Val loss 21.787\n",
      "\r 58%|█████▊    | 35/60 [6:12:53<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.946 Val loss 10.318\n",
      "\r 58%|█████▊    | 35/60 [6:13:59<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.242 Val loss 9.774\n",
      "\r 58%|█████▊    | 35/60 [6:15:08<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 179 best_val_loss 9.263\n",
      "\r 58%|█████▊    | 35/60 [6:15:15<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 58%|█████▊    | 35/60 [6:15:15<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.556 Val loss 21.252\n",
      "\r 58%|█████▊    | 35/60 [6:15:19<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.019 Val loss 10.185\n",
      "\r 58%|█████▊    | 35/60 [6:16:25<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 91 best_val_loss 8.875\n",
      "\r 58%|█████▊    | 35/60 [6:16:40<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 58%|█████▊    | 35/60 [6:16:40<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.497 Val loss 21.300\n",
      "\r 58%|█████▊    | 35/60 [6:16:43<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.359 Val loss 10.328\n",
      "\r 58%|█████▊    | 35/60 [6:17:46<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.363 Val loss 10.163\n",
      "\r 58%|█████▊    | 35/60 [6:18:49<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.307 Val loss 8.559\n",
      "\r 58%|█████▊    | 35/60 [6:19:56<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 292 best_val_loss 8.300\n",
      "\r 58%|█████▊    | 35/60 [6:20:11<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 58%|█████▊    | 35/60 [6:20:11<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.656 Val loss 20.377\n",
      "\r 58%|█████▊    | 35/60 [6:20:16<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 6.748 Val loss 10.451\n",
      "\r 58%|█████▊    | 35/60 [6:21:24<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.144 Val loss 9.486\n",
      "\r 58%|█████▊    | 35/60 [6:22:29<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.202 Val loss 9.102\n",
      "\r 58%|█████▊    | 35/60 [6:23:32<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 308 best_val_loss 8.736\n",
      "\r 58%|█████▊    | 35/60 [6:23:58<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 58%|█████▊    | 35/60 [6:23:58<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.690 Val loss 19.824\n",
      "\r 58%|█████▊    | 35/60 [6:24:03<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.135 Val loss 12.030\n",
      "\r 58%|█████▊    | 35/60 [6:25:12<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.401 Val loss 9.668\n",
      "\r 58%|█████▊    | 35/60 [6:26:11<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 224 best_val_loss 9.149\n",
      "\r 58%|█████▊    | 35/60 [6:26:43<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 8.86457\n",
      "\n",
      "\r 58%|█████▊    | 35/60 [6:26:43<5:26:36, 783.84s/trial, best loss: 8.717567209097055]\r 60%|██████    | 36/60 [6:26:43<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.10571877081916116, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.32509572693102845, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0004856674398891815, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.2880890491261555}\n",
      "\r 60%|██████    | 36/60 [6:26:43<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 60%|██████    | 36/60 [6:26:43<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.690 Val loss 22.713\n",
      "\r 60%|██████    | 36/60 [6:26:47<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.682 Val loss 10.429\n",
      "\r 60%|██████    | 36/60 [6:27:48<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.677 Val loss 9.283\n",
      "\r 60%|██████    | 36/60 [6:28:50<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 280 best_val_loss 8.891\n",
      "\r 60%|██████    | 36/60 [6:29:49<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 60%|██████    | 36/60 [6:29:49<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.879 Val loss 21.738\n",
      "\r 60%|██████    | 36/60 [6:29:53<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.029 Val loss 9.606\n",
      "\r 60%|██████    | 36/60 [6:31:02<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.833 Val loss 8.582\n",
      "\r 60%|██████    | 36/60 [6:32:15<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 248 best_val_loss 8.340\n",
      "\r 60%|██████    | 36/60 [6:33:14<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 60%|██████    | 36/60 [6:33:14<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.790 Val loss 21.575\n",
      "\r 60%|██████    | 36/60 [6:33:18<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.025 Val loss 10.094\n",
      "\r 60%|██████    | 36/60 [6:34:30<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.816 Val loss 8.783\n",
      "\r 60%|██████    | 36/60 [6:35:43<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 244 best_val_loss 8.407\n",
      "\r 60%|██████    | 36/60 [6:36:35<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 60%|██████    | 36/60 [6:36:35<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.035 Val loss 20.820\n",
      "\r 60%|██████    | 36/60 [6:36:39<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.723 Val loss 10.720\n",
      "\r 60%|██████    | 36/60 [6:37:50<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.683 Val loss 9.428\n",
      "\r 60%|██████    | 36/60 [6:39:06<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 284 best_val_loss 9.054\n",
      "\r 60%|██████    | 36/60 [6:40:18<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 60%|██████    | 36/60 [6:40:18<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.040 Val loss 20.303\n",
      "\r 60%|██████    | 36/60 [6:40:23<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.203 Val loss 10.533\n",
      "\r 60%|██████    | 36/60 [6:41:22<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.930 Val loss 9.302\n",
      "\r 60%|██████    | 36/60 [6:42:33<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 228 best_val_loss 9.019\n",
      "\r 60%|██████    | 36/60 [6:43:10<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 8.74205\n",
      "\n",
      "\r 60%|██████    | 36/60 [6:43:10<5:19:30, 798.79s/trial, best loss: 8.717567209097055]\r 62%|██████▏   | 37/60 [6:43:11<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.4956739188984182, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.32670940365884954, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00030266020530090546, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.1542659966575419}\n",
      "\r 62%|██████▏   | 37/60 [6:43:11<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 62%|██████▏   | 37/60 [6:43:11<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.849 Val loss 23.699\n",
      "\r 62%|██████▏   | 37/60 [6:43:14<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 17.380 Val loss 17.916\n",
      "\r 62%|██████▏   | 37/60 [6:43:45<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 16.922 Val loss 17.774\n",
      "\r 62%|██████▏   | 37/60 [6:44:15<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 245 best_val_loss 17.736\n",
      "\r 62%|██████▏   | 37/60 [6:44:37<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 62%|██████▏   | 37/60 [6:44:37<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.937 Val loss 22.145\n",
      "\r 62%|██████▏   | 37/60 [6:44:41<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 17.623 Val loss 16.959\n",
      "\r 62%|██████▏   | 37/60 [6:45:10<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 17.422 Val loss 16.812\n",
      "\r 62%|██████▏   | 37/60 [6:45:39<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 291 best_val_loss 16.758\n",
      "\r 62%|██████▏   | 37/60 [6:46:06<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 62%|██████▏   | 37/60 [6:46:06<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.777 Val loss 22.303\n",
      "\r 62%|██████▏   | 37/60 [6:46:09<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 17.664 Val loss 17.183\n",
      "\r 62%|██████▏   | 37/60 [6:46:38<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 17.364 Val loss 17.027\n",
      "\r 62%|██████▏   | 37/60 [6:47:08<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 271 best_val_loss 16.998\n",
      "\r 62%|██████▏   | 37/60 [6:47:38<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 62%|██████▏   | 37/60 [6:47:38<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 22.999 Val loss 21.078\n",
      "\r 62%|██████▏   | 37/60 [6:47:42<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 17.834 Val loss 16.096\n",
      "\r 62%|██████▏   | 37/60 [6:48:11<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 17.377 Val loss 16.022\n",
      "\r 62%|██████▏   | 37/60 [6:48:40<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 272 best_val_loss 15.986\n",
      "\r 62%|██████▏   | 37/60 [6:49:07<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 62%|██████▏   | 37/60 [6:49:07<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 23.038 Val loss 20.932\n",
      "\r 62%|██████▏   | 37/60 [6:49:10<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 17.647 Val loss 16.303\n",
      "\r 62%|██████▏   | 37/60 [6:49:40<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 17.468 Val loss 16.210\n",
      "\r 62%|██████▏   | 37/60 [6:50:09<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rStopped at epoch 285 best_val_loss 16.195\n",
      "\r 62%|██████▏   | 37/60 [6:50:38<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 16.73462\n",
      "\n",
      "\r 62%|██████▏   | 37/60 [6:50:38<5:27:53, 855.37s/trial, best loss: 8.717567209097055]\r 63%|██████▎   | 38/60 [6:50:38<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.16497450048050535, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.004010316577744644, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.000576073526867885, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.29962346731351863}\n",
      "\r 63%|██████▎   | 38/60 [6:50:38<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 1/5\n",
      "\r 63%|██████▎   | 38/60 [6:50:38<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 20.897 Val loss 21.380\n",
      "\r 63%|██████▎   | 38/60 [6:50:42<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.610 Val loss 10.318\n",
      "\r 63%|██████▎   | 38/60 [6:51:52<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.014 Val loss 9.293\n",
      "\r 63%|██████▎   | 38/60 [6:52:52<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.942 Val loss 8.959\n",
      "\r 63%|██████▎   | 38/60 [6:53:54<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 296 best_val_loss 8.750\n",
      "\r 63%|██████▎   | 38/60 [6:54:12<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 2/5\n",
      "\r 63%|██████▎   | 38/60 [6:54:12<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.056 Val loss 20.765\n",
      "\r 63%|██████▎   | 38/60 [6:54:16<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.819 Val loss 10.183\n",
      "\r 63%|██████▎   | 38/60 [6:55:16<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 5.966 Val loss 9.263\n",
      "\r 63%|██████▎   | 38/60 [6:56:18<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.811 Val loss 8.490\n",
      "\r 63%|██████▎   | 38/60 [6:57:24<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 281 best_val_loss 8.286\n",
      "\r 63%|██████▎   | 38/60 [6:57:33<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 3/5\n",
      "\r 63%|██████▎   | 38/60 [6:57:33<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.348 Val loss 20.902\n",
      "\r 63%|██████▎   | 38/60 [6:57:37<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.896 Val loss 9.993\n",
      "\r 63%|██████▎   | 38/60 [6:58:41<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.118 Val loss 9.328\n",
      "\r 63%|██████▎   | 38/60 [6:59:45<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 4.942 Val loss 8.433\n",
      "\r 63%|██████▎   | 38/60 [7:00:49<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 280 best_val_loss 8.298\n",
      "\r 63%|██████▎   | 38/60 [7:00:56<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 4/5\n",
      "\r 63%|██████▎   | 38/60 [7:00:56<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.281 Val loss 20.315\n",
      "\r 63%|██████▎   | 38/60 [7:01:00<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 7.696 Val loss 10.695\n",
      "\r 63%|██████▎   | 38/60 [7:02:14<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.059 Val loss 9.532\n",
      "\r 63%|██████▎   | 38/60 [7:03:25<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 194 best_val_loss 9.288\n",
      "\r 63%|██████▎   | 38/60 [7:03:43<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rFold: 5/5\n",
      "\r 63%|██████▎   | 38/60 [7:03:43<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 0 Train loss 21.221 Val loss 20.377\n",
      "\r 63%|██████▎   | 38/60 [7:03:47<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 100 Train loss 8.007 Val loss 10.161\n",
      "\r 63%|██████▎   | 38/60 [7:04:54<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 200 Train loss 6.151 Val loss 9.465\n",
      "\r 63%|██████▎   | 38/60 [7:05:58<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEpoch 300 Train loss 5.128 Val loss 9.021\n",
      "\r 63%|██████▎   | 38/60 [7:07:09<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rEarly stopped at epoch 289 best_val_loss 8.832\n",
      "\r 63%|██████▎   | 38/60 [7:07:22<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r                                                                                     \rval MSE loss mean: 8.69078\n",
      "\n",
      "\r 63%|██████▎   | 38/60 [7:07:22<4:28:44, 732.91s/trial, best loss: 8.717567209097055]\r 65%|██████▌   | 39/60 [7:07:22<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.16504715161203032, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.13381465300295942, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0005629432385898477, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.13110731747513504}\n",
      "\r 65%|██████▌   | 39/60 [7:07:22<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 65%|██████▌   | 39/60 [7:07:22<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.116 Val loss 19.953\n",
      "\r 65%|██████▌   | 39/60 [7:07:26<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.762 Val loss 11.993\n",
      "\r 65%|██████▌   | 39/60 [7:08:40<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.793 Val loss 9.860\n",
      "\r 65%|██████▌   | 39/60 [7:09:54<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 200 best_val_loss 9.860\n",
      "\r 65%|██████▌   | 39/60 [7:10:17<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 65%|██████▌   | 39/60 [7:10:17<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.457 Val loss 19.349\n",
      "\r 65%|██████▌   | 39/60 [7:10:21<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.706 Val loss 9.643\n",
      "\r 65%|██████▌   | 39/60 [7:11:30<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.548 Val loss 9.545\n",
      "\r 65%|██████▌   | 39/60 [7:12:44<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 181 best_val_loss 8.938\n",
      "\r 65%|██████▌   | 39/60 [7:12:52<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 65%|██████▌   | 39/60 [7:12:52<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.584 Val loss 19.785\n",
      "\r 65%|██████▌   | 39/60 [7:12:57<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.552 Val loss 11.073\n",
      "\r 65%|██████▌   | 39/60 [7:14:13<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 165 best_val_loss 9.430\n",
      "\r 65%|██████▌   | 39/60 [7:15:28<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 65%|██████▌   | 39/60 [7:15:28<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.536 Val loss 18.952\n",
      "\r 65%|██████▌   | 39/60 [7:15:32<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.211 Val loss 11.306\n",
      "\r 65%|██████▌   | 39/60 [7:16:53<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 151 best_val_loss 10.036\n",
      "\r 65%|██████▌   | 39/60 [7:17:57<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 65%|██████▌   | 39/60 [7:17:57<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.448 Val loss 20.516\n",
      "\r 65%|██████▌   | 39/60 [7:18:00<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.825 Val loss 12.609\n",
      "\r 65%|██████▌   | 39/60 [7:19:19<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 122 best_val_loss 10.334\n",
      "\r 65%|██████▌   | 39/60 [7:19:58<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 9.71947\n",
      "\n",
      "\r 65%|██████▌   | 39/60 [7:19:58<4:45:02, 814.42s/trial, best loss: 8.690782282902642]\r 67%|██████▋   | 40/60 [7:19:58<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.2761633748462557, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.0020419173399081614, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0006923085975028816, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.3309205012060326}\n",
      "\r 67%|██████▋   | 40/60 [7:19:58<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 67%|██████▋   | 40/60 [7:19:58<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.906 Val loss 21.438\n",
      "\r 67%|██████▋   | 40/60 [7:20:02<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.967 Val loss 11.118\n",
      "\r 67%|██████▋   | 40/60 [7:21:09<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.178 Val loss 9.688\n",
      "\r 67%|██████▋   | 40/60 [7:22:17<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.208 Val loss 9.389\n",
      "\r 67%|██████▋   | 40/60 [7:23:23<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 333 best_val_loss 9.179\n",
      "\r 67%|██████▋   | 40/60 [7:24:11<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 67%|██████▋   | 40/60 [7:24:11<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.122 Val loss 21.151\n",
      "\r 67%|██████▋   | 40/60 [7:24:15<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.845 Val loss 10.092\n",
      "\r 67%|██████▋   | 40/60 [7:25:27<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.137 Val loss 8.998\n",
      "\r 67%|██████▋   | 40/60 [7:26:39<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.029 Val loss 8.701\n",
      "\r 67%|██████▋   | 40/60 [7:27:38<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 299 best_val_loss 8.538\n",
      "\r 67%|██████▋   | 40/60 [7:28:00<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 67%|██████▋   | 40/60 [7:28:00<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.355 Val loss 21.273\n",
      "\r 67%|██████▋   | 40/60 [7:28:04<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.088 Val loss 10.246\n",
      "\r 67%|██████▋   | 40/60 [7:29:16<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.298 Val loss 9.269\n",
      "\r 67%|██████▋   | 40/60 [7:30:29<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.096 Val loss 8.693\n",
      "\r 67%|██████▋   | 40/60 [7:31:42<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 333 best_val_loss 8.620\n",
      "\r 67%|██████▋   | 40/60 [7:32:24<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 67%|██████▋   | 40/60 [7:32:24<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.193 Val loss 20.813\n",
      "\r 67%|██████▋   | 40/60 [7:32:28<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.709 Val loss 10.550\n",
      "\r 67%|██████▋   | 40/60 [7:33:32<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.039 Val loss 9.743\n",
      "\r 67%|██████▋   | 40/60 [7:34:34<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.946 Val loss 9.252\n",
      "\r 67%|██████▋   | 40/60 [7:35:37<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 363 best_val_loss 9.047\n",
      "\r 67%|██████▋   | 40/60 [7:36:37<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 67%|██████▋   | 40/60 [7:36:37<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.256 Val loss 20.149\n",
      "\r 67%|██████▋   | 40/60 [7:36:41<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.130 Val loss 10.822\n",
      "\r 67%|██████▋   | 40/60 [7:37:46<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.320 Val loss 9.466\n",
      "\r 67%|██████▋   | 40/60 [7:38:51<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 247 best_val_loss 9.157\n",
      "\r 67%|██████▋   | 40/60 [7:39:39<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.90831\n",
      "\n",
      "\r 67%|██████▋   | 40/60 [7:39:39<4:25:34, 796.70s/trial, best loss: 8.690782282902642]\r 68%|██████▊   | 41/60 [7:39:39<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.24109735253863102, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.005780537501259199, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0005796171505886989, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.20405761684985071}\n",
      "\r 68%|██████▊   | 41/60 [7:39:39<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 68%|██████▊   | 41/60 [7:39:39<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.873 Val loss 18.028\n",
      "\r 68%|██████▊   | 41/60 [7:39:43<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.339 Val loss 10.698\n",
      "\r 68%|██████▊   | 41/60 [7:40:13<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.364 Val loss 10.288\n",
      "\r 68%|██████▊   | 41/60 [7:40:43<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 174 best_val_loss 9.894\n",
      "\r 68%|██████▊   | 41/60 [7:40:45<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 68%|██████▊   | 41/60 [7:40:45<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.866 Val loss 17.190\n",
      "\r 68%|██████▊   | 41/60 [7:40:48<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.858 Val loss 9.576\n",
      "\r 68%|██████▊   | 41/60 [7:41:20<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.773 Val loss 8.760\n",
      "\r 68%|██████▊   | 41/60 [7:41:48<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 246 best_val_loss 8.343\n",
      "\r 68%|██████▊   | 41/60 [7:42:11<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 68%|██████▊   | 41/60 [7:42:11<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.075 Val loss 17.307\n",
      "\r 68%|██████▊   | 41/60 [7:42:14<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.467 Val loss 10.632\n",
      "\r 68%|██████▊   | 41/60 [7:42:43<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 160 best_val_loss 9.817\n",
      "\r 68%|██████▊   | 41/60 [7:43:11<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 68%|██████▊   | 41/60 [7:43:11<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.953 Val loss 16.717\n",
      "\r 68%|██████▊   | 41/60 [7:43:14<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.272 Val loss 10.684\n",
      "\r 68%|██████▊   | 41/60 [7:43:43<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.305 Val loss 9.906\n",
      "\r 68%|██████▊   | 41/60 [7:44:13<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 196 best_val_loss 9.520\n",
      "\r 68%|██████▊   | 41/60 [7:44:21<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 68%|██████▊   | 41/60 [7:44:21<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.714 Val loss 16.553\n",
      "\r 68%|██████▊   | 41/60 [7:44:25<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.652 Val loss 10.887\n",
      "\r 68%|██████▊   | 41/60 [7:44:54<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.619 Val loss 10.487\n",
      "\r 68%|██████▊   | 41/60 [7:45:24<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 221 best_val_loss 9.850\n",
      "\r 68%|██████▊   | 41/60 [7:45:39<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 9.48465\n",
      "\n",
      "\r 68%|██████▊   | 41/60 [7:45:39<4:48:50, 912.12s/trial, best loss: 8.690782282902642]\r 70%|███████   | 42/60 [7:45:39<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.12933223215979595, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.23557259160484265, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0004093278072231643, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.4808046288347562}\n",
      "\r 70%|███████   | 42/60 [7:45:39<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 70%|███████   | 42/60 [7:45:39<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.747 Val loss 22.087\n",
      "\r 70%|███████   | 42/60 [7:45:43<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.450 Val loss 11.712\n",
      "\r 70%|███████   | 42/60 [7:46:12<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.109 Val loss 9.336\n",
      "\r 70%|███████   | 42/60 [7:46:40<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.367 Val loss 9.031\n",
      "\r 70%|███████   | 42/60 [7:47:09<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 314 best_val_loss 8.868\n",
      "\r 70%|███████   | 42/60 [7:47:21<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 70%|███████   | 42/60 [7:47:21<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.764 Val loss 21.518\n",
      "\r 70%|███████   | 42/60 [7:47:24<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.734 Val loss 11.603\n",
      "\r 70%|███████   | 42/60 [7:47:52<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.651 Val loss 8.952\n",
      "\r 70%|███████   | 42/60 [7:48:21<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.050 Val loss 8.759\n",
      "\r 70%|███████   | 42/60 [7:48:49<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 356 best_val_loss 8.513\n",
      "\r 70%|███████   | 42/60 [7:49:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 70%|███████   | 42/60 [7:49:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.063 Val loss 21.292\n",
      "\r 70%|███████   | 42/60 [7:49:17<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.499 Val loss 11.839\n",
      "\r 70%|███████   | 42/60 [7:49:45<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.525 Val loss 10.857\n",
      "\r 70%|███████   | 42/60 [7:50:14<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.261 Val loss 8.900\n",
      "\r 70%|███████   | 42/60 [7:50:44<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 397 best_val_loss 8.583\n",
      "\r 70%|███████   | 42/60 [7:51:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 70%|███████   | 42/60 [7:51:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.665 Val loss 21.107\n",
      "\r 70%|███████   | 42/60 [7:51:17<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.116 Val loss 11.887\n",
      "\r 70%|███████   | 42/60 [7:51:48<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.343 Val loss 10.101\n",
      "\r 70%|███████   | 42/60 [7:52:18<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.060 Val loss 9.326\n",
      "\r 70%|███████   | 42/60 [7:52:50<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 348 best_val_loss 9.114\n",
      "\r 70%|███████   | 42/60 [7:53:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 70%|███████   | 42/60 [7:53:13<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.903 Val loss 20.939\n",
      "\r 70%|███████   | 42/60 [7:53:16<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.920 Val loss 12.262\n",
      "\r 70%|███████   | 42/60 [7:53:45<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.114 Val loss 10.006\n",
      "\r 70%|███████   | 42/60 [7:54:15<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 248 best_val_loss 9.344\n",
      "\r 70%|███████   | 42/60 [7:54:38<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.88442\n",
      "\n",
      "\r 70%|███████   | 42/60 [7:54:38<3:43:58, 746.60s/trial, best loss: 8.690782282902642]\r 72%|███████▏  | 43/60 [7:54:38<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.3329510051553818, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.271575420045479, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0005132152562112077, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.23308709424058255}\n",
      "\r 72%|███████▏  | 43/60 [7:54:38<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 72%|███████▏  | 43/60 [7:54:38<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.607 Val loss 18.111\n",
      "\r 72%|███████▏  | 43/60 [7:54:42<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.704 Val loss 11.388\n",
      "\r 72%|███████▏  | 43/60 [7:55:50<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.719 Val loss 10.953\n",
      "\r 72%|███████▏  | 43/60 [7:56:58<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 224 best_val_loss 10.633\n",
      "\r 72%|███████▏  | 43/60 [7:57:35<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 72%|███████▏  | 43/60 [7:57:35<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.697 Val loss 17.755\n",
      "\r 72%|███████▏  | 43/60 [7:57:39<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.005 Val loss 10.498\n",
      "\r 72%|███████▏  | 43/60 [7:58:47<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.692 Val loss 9.660\n",
      "\r 72%|███████▏  | 43/60 [7:59:52<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 193 best_val_loss 9.487\n",
      "\r 72%|███████▏  | 43/60 [8:00:10<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 72%|███████▏  | 43/60 [8:00:10<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.886 Val loss 17.718\n",
      "\r 72%|███████▏  | 43/60 [8:00:14<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.657 Val loss 11.474\n",
      "\r 72%|███████▏  | 43/60 [8:01:21<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 119 best_val_loss 10.384\n",
      "\r 72%|███████▏  | 43/60 [8:01:56<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 72%|███████▏  | 43/60 [8:01:56<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.790 Val loss 16.970\n",
      "\r 72%|███████▏  | 43/60 [8:02:00<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.541 Val loss 11.119\n",
      "\r 72%|███████▏  | 43/60 [8:03:08<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 124 best_val_loss 10.806\n",
      "\r 72%|███████▏  | 43/60 [8:03:45<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 72%|███████▏  | 43/60 [8:03:45<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.558 Val loss 18.394\n",
      "\r 72%|███████▏  | 43/60 [8:03:49<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.932 Val loss 12.067\n",
      "\r 72%|███████▏  | 43/60 [8:04:55<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 89 best_val_loss 11.280\n",
      "\r 72%|███████▏  | 43/60 [8:05:07<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 10.51808\n",
      "\n",
      "\r 72%|███████▏  | 43/60 [8:05:07<3:13:50, 684.15s/trial, best loss: 8.690782282902642]\r 73%|███████▎  | 44/60 [8:05:07<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.40430792858815423, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.09943675861957746, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0006068112291093558, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.548703491968174}\n",
      "\r 73%|███████▎  | 44/60 [8:05:07<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 73%|███████▎  | 44/60 [8:05:07<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.421 Val loss 22.448\n",
      "\r 73%|███████▎  | 44/60 [8:05:11<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.133 Val loss 11.823\n",
      "\r 73%|███████▎  | 44/60 [8:05:50<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.965 Val loss 10.104\n",
      "\r 73%|███████▎  | 44/60 [8:06:33<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.775 Val loss 9.486\n",
      "\r 73%|███████▎  | 44/60 [8:07:14<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 361 best_val_loss 9.364\n",
      "\r 73%|███████▎  | 44/60 [8:07:52<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 73%|███████▎  | 44/60 [8:07:52<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.633 Val loss 20.756\n",
      "\r 73%|███████▎  | 44/60 [8:07:56<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.598 Val loss 10.306\n",
      "\r 73%|███████▎  | 44/60 [8:08:35<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 8.108 Val loss 9.005\n",
      "\r 73%|███████▎  | 44/60 [8:09:20<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.899 Val loss 8.522\n",
      "\r 73%|███████▎  | 44/60 [8:10:00<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 330 best_val_loss 8.426\n",
      "\r 73%|███████▎  | 44/60 [8:10:24<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 73%|███████▎  | 44/60 [8:10:24<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.680 Val loss 21.451\n",
      "\r 73%|███████▎  | 44/60 [8:10:28<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.485 Val loss 11.077\n",
      "\r 73%|███████▎  | 44/60 [8:11:07<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.971 Val loss 9.852\n",
      "\r 73%|███████▎  | 44/60 [8:11:48<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.730 Val loss 9.363\n",
      "\r 73%|███████▎  | 44/60 [8:12:28<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 324 best_val_loss 9.158\n",
      "\r 73%|███████▎  | 44/60 [8:12:51<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 73%|███████▎  | 44/60 [8:12:51<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.650 Val loss 20.742\n",
      "\r 73%|███████▎  | 44/60 [8:12:55<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.663 Val loss 11.295\n",
      "\r 73%|███████▎  | 44/60 [8:13:34<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.920 Val loss 9.994\n",
      "\r 73%|███████▎  | 44/60 [8:14:14<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.858 Val loss 9.523\n",
      "\r 73%|███████▎  | 44/60 [8:14:55<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 350 best_val_loss 9.270\n",
      "\r 73%|███████▎  | 44/60 [8:15:27<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 73%|███████▎  | 44/60 [8:15:27<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.830 Val loss 20.598\n",
      "\r 73%|███████▎  | 44/60 [8:15:32<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.392 Val loss 11.703\n",
      "\r 73%|███████▎  | 44/60 [8:16:13<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 8.102 Val loss 10.258\n",
      "\r 73%|███████▎  | 44/60 [8:16:55<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.795 Val loss 9.673\n",
      "\r 73%|███████▎  | 44/60 [8:17:35<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 307 best_val_loss 9.574\n",
      "\r 73%|███████▎  | 44/60 [8:17:52<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 9.15810\n",
      "\n",
      "\r 73%|███████▎  | 44/60 [8:17:52<2:58:04, 667.76s/trial, best loss: 8.690782282902642]\r 75%|███████▌  | 45/60 [8:17:52<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.05948826924592995, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.1646442045464584, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00010286714352994789, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.36565707456104823}\n",
      "\r 75%|███████▌  | 45/60 [8:17:52<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 75%|███████▌  | 45/60 [8:17:52<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.797 Val loss 22.749\n",
      "\r 75%|███████▌  | 45/60 [8:17:55<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.703 Val loss 11.071\n",
      "\r 75%|███████▌  | 45/60 [8:18:45<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.015 Val loss 9.707\n",
      "\r 75%|███████▌  | 45/60 [8:19:37<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 242 best_val_loss 9.221\n",
      "\r 75%|███████▌  | 45/60 [8:20:15<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 75%|███████▌  | 45/60 [8:20:15<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.096 Val loss 21.545\n",
      "\r 75%|███████▌  | 45/60 [8:20:18<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.533 Val loss 10.028\n",
      "\r 75%|███████▌  | 45/60 [8:21:09<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.785 Val loss 8.930\n",
      "\r 75%|███████▌  | 45/60 [8:22:01<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 238 best_val_loss 8.554\n",
      "\r 75%|███████▌  | 45/60 [8:22:36<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 75%|███████▌  | 45/60 [8:22:36<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.175 Val loss 21.829\n",
      "\r 75%|███████▌  | 45/60 [8:22:40<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.797 Val loss 10.349\n",
      "\r 75%|███████▌  | 45/60 [8:23:31<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.869 Val loss 9.146\n",
      "\r 75%|███████▌  | 45/60 [8:24:22<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 4.707 Val loss 8.449\n",
      "\r 75%|███████▌  | 45/60 [8:25:12<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 301 best_val_loss 8.400\n",
      "\r 75%|███████▌  | 45/60 [8:25:29<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 75%|███████▌  | 45/60 [8:25:29<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.081 Val loss 21.063\n",
      "\r 75%|███████▌  | 45/60 [8:25:33<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.444 Val loss 10.756\n",
      "\r 75%|███████▌  | 45/60 [8:26:24<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.773 Val loss 9.819\n",
      "\r 75%|███████▌  | 45/60 [8:27:16<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 4.567 Val loss 9.051\n",
      "\r 75%|███████▌  | 45/60 [8:28:08<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 346 best_val_loss 8.848\n",
      "\r 75%|███████▌  | 45/60 [8:28:48<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 75%|███████▌  | 45/60 [8:28:48<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.087 Val loss 21.257\n",
      "\r 75%|███████▌  | 45/60 [8:28:52<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.102 Val loss 11.335\n",
      "\r 75%|███████▌  | 45/60 [8:29:43<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.949 Val loss 9.938\n",
      "\r 75%|███████▌  | 45/60 [8:30:33<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 4.757 Val loss 9.228\n",
      "\r 75%|███████▌  | 45/60 [8:31:24<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 343 best_val_loss 8.820\n",
      "\r 75%|███████▌  | 45/60 [8:32:02<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.76852\n",
      "\n",
      "\r 75%|███████▌  | 45/60 [8:32:02<2:54:10, 696.72s/trial, best loss: 8.690782282902642]\r 77%|███████▋  | 46/60 [8:32:02<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.18865434435840456, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.24254502097156322, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0007285571955866902, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.4385388433858737}\n",
      "\r 77%|███████▋  | 46/60 [8:32:02<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 77%|███████▋  | 46/60 [8:32:02<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.260 Val loss 17.712\n",
      "\r 77%|███████▋  | 46/60 [8:32:06<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.029 Val loss 12.843\n",
      "\r 77%|███████▋  | 46/60 [8:32:40<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 177 best_val_loss 11.091\n",
      "\r 77%|███████▋  | 46/60 [8:33:14<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 77%|███████▋  | 46/60 [8:33:14<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.203 Val loss 17.428\n",
      "\r 77%|███████▋  | 46/60 [8:33:18<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.180 Val loss 11.512\n",
      "\r 77%|███████▋  | 46/60 [8:33:51<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 10.474\n",
      "\r 77%|███████▋  | 46/60 [8:34:14<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 77%|███████▋  | 46/60 [8:34:14<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.567 Val loss 17.133\n",
      "\r 77%|███████▋  | 46/60 [8:34:18<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.023 Val loss 11.738\n",
      "\r 77%|███████▋  | 46/60 [8:34:50<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 162 best_val_loss 11.019\n",
      "\r 77%|███████▋  | 46/60 [8:35:20<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 77%|███████▋  | 46/60 [8:35:20<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.146 Val loss 17.072\n",
      "\r 77%|███████▋  | 46/60 [8:35:23<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.790 Val loss 12.210\n",
      "\r 77%|███████▋  | 46/60 [8:35:58<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 114 best_val_loss 11.045\n",
      "\r 77%|███████▋  | 46/60 [8:36:13<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 77%|███████▋  | 46/60 [8:36:13<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 18.171 Val loss 17.966\n",
      "\r 77%|███████▋  | 46/60 [8:36:16<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.866 Val loss 12.687\n",
      "\r 77%|███████▋  | 46/60 [8:36:52<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 167 best_val_loss 11.344\n",
      "\r 77%|███████▋  | 46/60 [8:37:22<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 10.99482\n",
      "\n",
      "\r 77%|███████▋  | 46/60 [8:37:22<2:53:20, 742.87s/trial, best loss: 8.690782282902642]\r 78%|███████▊  | 47/60 [8:37:22<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.23091994487987838, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.35857950871382804, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0008289655143345785, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.593382136673366}\n",
      "\r 78%|███████▊  | 47/60 [8:37:22<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 78%|███████▊  | 47/60 [8:37:22<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.393 Val loss 21.759\n",
      "\r 78%|███████▊  | 47/60 [8:37:26<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.982 Val loss 10.840\n",
      "\r 78%|███████▊  | 47/60 [8:38:08<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.993 Val loss 9.800\n",
      "\r 78%|███████▊  | 47/60 [8:38:50<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 171 best_val_loss 9.460\n",
      "\r 78%|███████▊  | 47/60 [8:38:50<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 78%|███████▊  | 47/60 [8:38:50<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.560 Val loss 20.089\n",
      "\r 78%|███████▊  | 47/60 [8:38:54<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.500 Val loss 10.258\n",
      "\r 78%|███████▊  | 47/60 [8:39:36<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.129 Val loss 9.096\n",
      "\r 78%|███████▊  | 47/60 [8:40:17<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 239 best_val_loss 8.370\n",
      "\r 78%|███████▊  | 47/60 [8:40:46<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 78%|███████▊  | 47/60 [8:40:46<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.589 Val loss 20.717\n",
      "\r 78%|███████▊  | 47/60 [8:40:50<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.391 Val loss 10.365\n",
      "\r 78%|███████▊  | 47/60 [8:41:30<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.146 Val loss 9.262\n",
      "\r 78%|███████▊  | 47/60 [8:42:12<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.018 Val loss 8.799\n",
      "\r 78%|███████▊  | 47/60 [8:42:53<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 328 best_val_loss 8.629\n",
      "\r 78%|███████▊  | 47/60 [8:43:18<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 78%|███████▊  | 47/60 [8:43:18<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.548 Val loss 20.061\n",
      "\r 78%|███████▊  | 47/60 [8:43:22<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.895 Val loss 10.415\n",
      "\r 78%|███████▊  | 47/60 [8:44:03<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 5.914 Val loss 9.818\n",
      "\r 78%|███████▊  | 47/60 [8:44:45<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 4.803 Val loss 9.182\n",
      "\r 78%|███████▊  | 47/60 [8:45:25<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 343 best_val_loss 8.951\n",
      "\r 78%|███████▊  | 47/60 [8:45:56<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 78%|███████▊  | 47/60 [8:45:56<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.637 Val loss 19.666\n",
      "\r 78%|███████▊  | 47/60 [8:46:00<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.192 Val loss 10.569\n",
      "\r 78%|███████▊  | 47/60 [8:46:42<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.155 Val loss 9.725\n",
      "\r 78%|███████▊  | 47/60 [8:47:22<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 189 best_val_loss 9.513\n",
      "\r 78%|███████▊  | 47/60 [8:47:30<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.98460\n",
      "\n",
      "\r 78%|███████▊  | 47/60 [8:47:30<2:13:28, 616.05s/trial, best loss: 8.690782282902642]\r 80%|████████  | 48/60 [8:47:30<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.14425822166055818, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.18753546529678855, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00023502611715834373, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.28626293871372965}\n",
      "\r 80%|████████  | 48/60 [8:47:30<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 80%|████████  | 48/60 [8:47:30<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.819 Val loss 18.130\n",
      "\r 80%|████████  | 48/60 [8:47:34<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.785 Val loss 12.367\n",
      "\r 80%|████████  | 48/60 [8:48:05<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 158 best_val_loss 11.518\n",
      "\r 80%|████████  | 48/60 [8:48:30<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 80%|████████  | 48/60 [8:48:30<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.813 Val loss 17.530\n",
      "\r 80%|████████  | 48/60 [8:48:34<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.631 Val loss 11.130\n",
      "\r 80%|████████  | 48/60 [8:49:03<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 134 best_val_loss 10.269\n",
      "\r 80%|████████  | 48/60 [8:49:21<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 80%|████████  | 48/60 [8:49:21<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.914 Val loss 17.313\n",
      "\r 80%|████████  | 48/60 [8:49:25<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.598 Val loss 11.942\n",
      "\r 80%|████████  | 48/60 [8:49:54<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 173 best_val_loss 11.241\n",
      "\r 80%|████████  | 48/60 [8:50:21<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 80%|████████  | 48/60 [8:50:21<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.971 Val loss 16.931\n",
      "\r 80%|████████  | 48/60 [8:50:25<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.464 Val loss 11.993\n",
      "\r 80%|████████  | 48/60 [8:50:54<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 11.041\n",
      "\r 80%|████████  | 48/60 [8:51:16<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 80%|████████  | 48/60 [8:51:16<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.970 Val loss 16.868\n",
      "\r 80%|████████  | 48/60 [8:51:20<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.590 Val loss 14.683\n",
      "\r 80%|████████  | 48/60 [8:51:49<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 12.839\n",
      "\r 80%|████████  | 48/60 [8:51:49<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 11.38159\n",
      "\n",
      "\r 80%|████████  | 48/60 [8:51:49<2:02:43, 613.65s/trial, best loss: 8.690782282902642]\r 82%|████████▏ | 49/60 [8:51:49<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.2818422689575933, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.08051212009674728, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0006286448108027349, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.5331206381681346}\n",
      "\r 82%|████████▏ | 49/60 [8:51:49<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 82%|████████▏ | 49/60 [8:51:49<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 20.968 Val loss 21.815\n",
      "\r 82%|████████▏ | 49/60 [8:51:54<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.928 Val loss 11.303\n",
      "\r 82%|████████▏ | 49/60 [8:53:00<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.066 Val loss 9.871\n",
      "\r 82%|████████▏ | 49/60 [8:54:08<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.132 Val loss 9.343\n",
      "\r 82%|████████▏ | 49/60 [8:55:14<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 377 best_val_loss 9.112\n",
      "\r 82%|████████▏ | 49/60 [8:56:20<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 82%|████████▏ | 49/60 [8:56:20<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.170 Val loss 21.116\n",
      "\r 82%|████████▏ | 49/60 [8:56:25<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.272 Val loss 9.725\n",
      "\r 82%|████████▏ | 49/60 [8:57:31<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.427 Val loss 9.079\n",
      "\r 82%|████████▏ | 49/60 [8:58:37<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 182 best_val_loss 8.893\n",
      "\r 82%|████████▏ | 49/60 [8:58:45<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 82%|████████▏ | 49/60 [8:58:45<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.396 Val loss 20.883\n",
      "\r 82%|████████▏ | 49/60 [8:58:50<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.044 Val loss 10.221\n",
      "\r 82%|████████▏ | 49/60 [8:59:55<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.285 Val loss 9.469\n",
      "\r 82%|████████▏ | 49/60 [9:01:03<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.098 Val loss 8.791\n",
      "\r 82%|████████▏ | 49/60 [9:02:12<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 330 best_val_loss 8.634\n",
      "\r 82%|████████▏ | 49/60 [9:02:53<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 82%|████████▏ | 49/60 [9:02:53<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.395 Val loss 20.315\n",
      "\r 82%|████████▏ | 49/60 [9:02:58<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.677 Val loss 10.618\n",
      "\r 82%|████████▏ | 49/60 [9:04:05<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.093 Val loss 9.704\n",
      "\r 82%|████████▏ | 49/60 [9:05:09<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.012 Val loss 9.269\n",
      "\r 82%|████████▏ | 49/60 [9:06:14<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 380 best_val_loss 9.045\n",
      "\r 82%|████████▏ | 49/60 [9:07:17<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 82%|████████▏ | 49/60 [9:07:17<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.358 Val loss 20.062\n",
      "\r 82%|████████▏ | 49/60 [9:07:22<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.328 Val loss 10.560\n",
      "\r 82%|████████▏ | 49/60 [9:08:28<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.411 Val loss 9.790\n",
      "\r 82%|████████▏ | 49/60 [9:09:34<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.254 Val loss 9.406\n",
      "\r 82%|████████▏ | 49/60 [9:10:42<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 371 best_val_loss 9.200\n",
      "\r 82%|████████▏ | 49/60 [9:11:45<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.97693\n",
      "\n",
      "\r 82%|████████▏ | 49/60 [9:11:45<1:32:59, 507.27s/trial, best loss: 8.690782282902642]\r 83%|████████▎ | 50/60 [9:11:45<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.07350655250119917, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.38192710893204096, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0003622323352864902, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.08336634339366705}\n",
      "\r 83%|████████▎ | 50/60 [9:11:46<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 83%|████████▎ | 50/60 [9:11:46<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.984 Val loss 22.500\n",
      "\r 83%|████████▎ | 50/60 [9:11:50<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.855 Val loss 12.549\n",
      "\r 83%|████████▎ | 50/60 [9:12:20<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.371 Val loss 10.166\n",
      "\r 83%|████████▎ | 50/60 [9:12:47<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.246 Val loss 9.649\n",
      "\r 83%|████████▎ | 50/60 [9:13:16<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 336 best_val_loss 9.445\n",
      "\r 83%|████████▎ | 50/60 [9:13:36<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 83%|████████▎ | 50/60 [9:13:36<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.348 Val loss 21.911\n",
      "\r 83%|████████▎ | 50/60 [9:13:40<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 10.667 Val loss 11.732\n",
      "\r 83%|████████▎ | 50/60 [9:14:10<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.614 Val loss 10.060\n",
      "\r 83%|████████▎ | 50/60 [9:14:38<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.447 Val loss 9.195\n",
      "\r 83%|████████▎ | 50/60 [9:15:06<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 307 best_val_loss 8.924\n",
      "\r 83%|████████▎ | 50/60 [9:15:18<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 83%|████████▎ | 50/60 [9:15:18<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.053 Val loss 21.603\n",
      "\r 83%|████████▎ | 50/60 [9:15:21<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.889 Val loss 12.618\n",
      "\r 83%|████████▎ | 50/60 [9:15:51<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.367 Val loss 9.912\n",
      "\r 83%|████████▎ | 50/60 [9:16:19<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.333 Val loss 9.301\n",
      "\r 83%|████████▎ | 50/60 [9:16:47<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 371 best_val_loss 9.043\n",
      "\r 83%|████████▎ | 50/60 [9:17:17<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 83%|████████▎ | 50/60 [9:17:17<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.340 Val loss 21.515\n",
      "\r 83%|████████▎ | 50/60 [9:17:20<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.666 Val loss 13.006\n",
      "\r 83%|████████▎ | 50/60 [9:17:50<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.307 Val loss 10.877\n",
      "\r 83%|████████▎ | 50/60 [9:18:21<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.152 Val loss 10.044\n",
      "\r 83%|████████▎ | 50/60 [9:18:52<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 335 best_val_loss 9.830\n",
      "\r 83%|████████▎ | 50/60 [9:19:12<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 83%|████████▎ | 50/60 [9:19:12<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 22.699 Val loss 21.222\n",
      "\r 83%|████████▎ | 50/60 [9:19:16<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 9.961 Val loss 11.882\n",
      "\r 83%|████████▎ | 50/60 [9:19:48<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 7.428 Val loss 10.579\n",
      "\r 83%|████████▎ | 50/60 [9:20:17<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 6.618 Val loss 10.301\n",
      "\r 83%|████████▎ | 50/60 [9:20:48<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 314 best_val_loss 9.757\n",
      "\r 83%|████████▎ | 50/60 [9:21:02<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 9.39984\n",
      "\n",
      "\r 83%|████████▎ | 50/60 [9:21:02<1:58:58, 713.89s/trial, best loss: 8.690782282902642]\r 85%|████████▌ | 51/60 [9:21:02<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.0362128279451521, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.11273003173579764, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.0003328323443210746, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.9387605046115793}\n",
      "\r 85%|████████▌ | 51/60 [9:21:02<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 85%|████████▌ | 51/60 [9:21:02<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.202 Val loss 17.789\n",
      "\r 85%|████████▌ | 51/60 [9:21:06<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.585 Val loss 11.292\n",
      "\r 85%|████████▌ | 51/60 [9:21:47<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 166 best_val_loss 9.845\n",
      "\r 85%|████████▌ | 51/60 [9:22:26<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 85%|████████▌ | 51/60 [9:22:26<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.487 Val loss 17.015\n",
      "\r 85%|████████▌ | 51/60 [9:22:30<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.621 Val loss 9.622\n",
      "\r 85%|████████▌ | 51/60 [9:23:10<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 160 best_val_loss 9.046\n",
      "\r 85%|████████▌ | 51/60 [9:23:47<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 85%|████████▌ | 51/60 [9:23:47<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.603 Val loss 16.891\n",
      "\r 85%|████████▌ | 51/60 [9:23:51<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.513 Val loss 10.796\n",
      "\r 85%|████████▌ | 51/60 [9:24:32<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 146 best_val_loss 9.760\n",
      "\r 85%|████████▌ | 51/60 [9:25:04<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 85%|████████▌ | 51/60 [9:25:04<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.471 Val loss 17.217\n",
      "\r 85%|████████▌ | 51/60 [9:25:08<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.902 Val loss 10.904\n",
      "\r 85%|████████▌ | 51/60 [9:25:49<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 130 best_val_loss 10.506\n",
      "\r 85%|████████▌ | 51/60 [9:26:14<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 85%|████████▌ | 51/60 [9:26:14<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 17.538 Val loss 16.744\n",
      "\r 85%|████████▌ | 51/60 [9:26:17<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 7.648 Val loss 11.699\n",
      "\r 85%|████████▌ | 51/60 [9:26:57<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 10.269\n",
      "\r 85%|████████▌ | 51/60 [9:27:15<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 9.88532\n",
      "\n",
      "\r 85%|████████▌ | 51/60 [9:27:15<1:40:00, 666.71s/trial, best loss: 8.690782282902642]\r 87%|████████▋ | 52/60 [9:27:15<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.20519606167732984, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.46384535606246435, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00040533647179335624, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.004359172532549305}\n",
      "\r 87%|████████▋ | 52/60 [9:27:15<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 87%|████████▋ | 52/60 [9:27:15<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.205 Val loss 22.219\n",
      "\r 87%|████████▋ | 52/60 [9:27:19<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.618 Val loss 10.803\n",
      "\r 87%|████████▋ | 52/60 [9:28:24<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.691 Val loss 9.568\n",
      "\r 87%|████████▋ | 52/60 [9:29:29<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.579 Val loss 9.124\n",
      "\r 87%|████████▋ | 52/60 [9:30:35<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 295 best_val_loss 8.992\n",
      "\r 87%|████████▋ | 52/60 [9:30:52<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 87%|████████▋ | 52/60 [9:30:52<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.406 Val loss 21.000\n",
      "\r 87%|████████▋ | 52/60 [9:30:56<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.714 Val loss 9.436\n",
      "\r 87%|████████▋ | 52/60 [9:32:01<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.659 Val loss 8.769\n",
      "\r 87%|████████▋ | 52/60 [9:33:05<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.497 Val loss 8.405\n",
      "\r 87%|████████▋ | 52/60 [9:34:11<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 375 best_val_loss 8.292\n",
      "\r 87%|████████▋ | 52/60 [9:35:15<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 87%|████████▋ | 52/60 [9:35:15<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.471 Val loss 21.208\n",
      "\r 87%|████████▋ | 52/60 [9:35:19<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.708 Val loss 10.018\n",
      "\r 87%|████████▋ | 52/60 [9:36:25<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.607 Val loss 8.883\n",
      "\r 87%|████████▋ | 52/60 [9:37:32<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.574 Val loss 8.277\n",
      "\r 87%|████████▋ | 52/60 [9:38:38<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 365 best_val_loss 8.198\n",
      "\r 87%|████████▋ | 52/60 [9:39:40<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 4/5\n",
      "\r 87%|████████▋ | 52/60 [9:39:40<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.544 Val loss 20.612\n",
      "\r 87%|████████▋ | 52/60 [9:39:44<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.583 Val loss 11.075\n",
      "\r 87%|████████▋ | 52/60 [9:40:52<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.646 Val loss 9.745\n",
      "\r 87%|████████▋ | 52/60 [9:42:00<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 225 best_val_loss 9.194\n",
      "\r 87%|████████▋ | 52/60 [9:42:36<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 5/5\n",
      "\r 87%|████████▋ | 52/60 [9:42:36<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.579 Val loss 20.367\n",
      "\r 87%|████████▋ | 52/60 [9:42:40<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 8.757 Val loss 10.274\n",
      "\r 87%|████████▋ | 52/60 [9:43:50<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 6.866 Val loss 9.505\n",
      "\r 87%|████████▋ | 52/60 [9:44:55<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 5.787 Val loss 8.908\n",
      "\r 87%|████████▋ | 52/60 [9:46:05<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rEarly stopped at epoch 327 best_val_loss 8.781\n",
      "\r 87%|████████▋ | 52/60 [9:46:43<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r                                                                                     \rval MSE loss mean: 8.69153\n",
      "\n",
      "\r 87%|████████▋ | 52/60 [9:46:43<1:17:08, 578.56s/trial, best loss: 8.690782282902642]\r 88%|████████▊ | 53/60 [9:46:43<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.39906512920427184, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.49878302848017564, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0002001025273599027, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.08231060510174013}\n",
      "\r 88%|████████▊ | 53/60 [9:46:43<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 1/5\n",
      "\r 88%|████████▊ | 53/60 [9:46:43<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.501 Val loss 22.931\n",
      "\r 88%|████████▊ | 53/60 [9:46:47<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 15.087 Val loss 15.273\n",
      "\r 88%|████████▊ | 53/60 [9:47:55<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 9.147 Val loss 10.894\n",
      "\r 88%|████████▊ | 53/60 [9:49:02<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 7.420 Val loss 9.716\n",
      "\r 88%|████████▊ | 53/60 [9:50:10<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 397 best_val_loss 9.415\n",
      "\r 88%|████████▊ | 53/60 [9:51:16<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 2/5\n",
      "\r 88%|████████▊ | 53/60 [9:51:16<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.708 Val loss 22.000\n",
      "\r 88%|████████▊ | 53/60 [9:51:21<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 16.386 Val loss 15.688\n",
      "\r 88%|████████▊ | 53/60 [9:52:24<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 9.900 Val loss 10.251\n",
      "\r 88%|████████▊ | 53/60 [9:53:31<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 7.560 Val loss 8.792\n",
      "\r 88%|████████▊ | 53/60 [9:54:35<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 395 best_val_loss 8.531\n",
      "\r 88%|████████▊ | 53/60 [9:55:43<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rFold: 3/5\n",
      "\r 88%|████████▊ | 53/60 [9:55:43<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 0 Train loss 21.746 Val loss 22.126\n",
      "\r 88%|████████▊ | 53/60 [9:55:47<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 100 Train loss 16.057 Val loss 15.475\n",
      "\r 88%|████████▊ | 53/60 [9:56:51<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 200 Train loss 9.678 Val loss 10.687\n",
      "\r 88%|████████▊ | 53/60 [9:57:56<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rEpoch 300 Train loss 7.715 Val loss 9.356\n",
      "\r 88%|████████▊ | 53/60 [9:59:01<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                     \rStopped at epoch 399 best_val_loss 8.925\n",
      "\r 88%|████████▊ | 53/60 [10:00:04<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 4/5\n",
      "\r 88%|████████▊ | 53/60 [10:00:04<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.802 Val loss 21.281\n",
      "\r 88%|████████▊ | 53/60 [10:00:08<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 16.326 Val loss 15.362\n",
      "\r 88%|████████▊ | 53/60 [10:01:13<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 9.731 Val loss 10.962\n",
      "\r 88%|████████▊ | 53/60 [10:02:15<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 300 Train loss 7.376 Val loss 9.698\n",
      "\r 88%|████████▊ | 53/60 [10:03:23<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rStopped at epoch 382 best_val_loss 9.452\n",
      "\r 88%|████████▊ | 53/60 [10:04:28<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 5/5\n",
      "\r 88%|████████▊ | 53/60 [10:04:28<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.801 Val loss 21.370\n",
      "\r 88%|████████▊ | 53/60 [10:04:32<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 16.277 Val loss 15.754\n",
      "\r 88%|████████▊ | 53/60 [10:05:36<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 10.161 Val loss 11.243\n",
      "\r 88%|████████▊ | 53/60 [10:06:40<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 300 Train loss 7.728 Val loss 9.873\n",
      "\r 88%|████████▊ | 53/60 [10:07:46<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rStopped at epoch 377 best_val_loss 9.581\n",
      "\r 88%|████████▊ | 53/60 [10:08:50<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r                                                                                      \rval MSE loss mean: 9.18112\n",
      "\n",
      "\r 88%|████████▊ | 53/60 [10:08:50<1:28:08, 755.49s/trial, best loss: 8.690782282902642]\r 90%|█████████ | 54/60 [10:08:50<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.32091100037182657, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.45882606990495023, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00027987960087670725, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.012848506543981205}\n",
      "\r 90%|█████████ | 54/60 [10:08:50<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 1/5\n",
      "\r 90%|█████████ | 54/60 [10:08:50<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.346 Val loss 23.316\n",
      "\r 90%|█████████ | 54/60 [10:08:54<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 14.634 Val loss 16.300\n",
      "\r 90%|█████████ | 54/60 [10:09:29<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 11.990 Val loss 15.358\n",
      "\r 90%|█████████ | 54/60 [10:10:02<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 242 best_val_loss 14.282\n",
      "\r 90%|█████████ | 54/60 [10:10:28<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 2/5\n",
      "\r 90%|█████████ | 54/60 [10:10:28<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.200 Val loss 22.216\n",
      "\r 90%|█████████ | 54/60 [10:10:32<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 14.905 Val loss 15.888\n",
      "\r 90%|█████████ | 54/60 [10:11:10<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 12.640 Val loss 14.336\n",
      "\r 90%|█████████ | 54/60 [10:11:47<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 300 Train loss 11.334 Val loss 13.910\n",
      "\r 90%|█████████ | 54/60 [10:12:24<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 281 best_val_loss 13.578\n",
      "\r 90%|█████████ | 54/60 [10:12:28<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 3/5\n",
      "\r 90%|█████████ | 54/60 [10:12:28<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.365 Val loss 23.479\n",
      "\r 90%|█████████ | 54/60 [10:12:32<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 46 best_val_loss 16.704\n",
      "\r 90%|█████████ | 54/60 [10:12:59<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 4/5\n",
      "\r 90%|█████████ | 54/60 [10:12:59<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.393 Val loss 23.075\n",
      "\r 90%|█████████ | 54/60 [10:13:03<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 15.005 Val loss 17.142\n",
      "\r 90%|█████████ | 54/60 [10:13:42<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 141 best_val_loss 15.529\n",
      "\r 90%|█████████ | 54/60 [10:14:12<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 5/5\n",
      "\r 90%|█████████ | 54/60 [10:14:12<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 21.270 Val loss 20.691\n",
      "\r 90%|█████████ | 54/60 [10:14:16<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 14.263 Val loss 16.541\n",
      "\r 90%|█████████ | 54/60 [10:14:51<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 12.235 Val loss 15.048\n",
      "\r 90%|█████████ | 54/60 [10:15:27<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 236 best_val_loss 14.337\n",
      "\r 90%|█████████ | 54/60 [10:15:49<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r                                                                                      \rval MSE loss mean: 14.88602\n",
      "\n",
      "\r 90%|█████████ | 54/60 [10:15:49<1:32:41, 926.96s/trial, best loss: 8.690782282902642]\r 92%|█████████▏| 55/60 [10:15:49<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.35631440065191045, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.022761020708970178, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0003878480054178839, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.17427061612840133}\n",
      "\r 92%|█████████▏| 55/60 [10:15:49<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 1/5\n",
      "\r 92%|█████████▏| 55/60 [10:15:49<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 18.004 Val loss 18.028\n",
      "\r 92%|█████████▏| 55/60 [10:15:53<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 8.828 Val loss 11.197\n",
      "\r 92%|█████████▏| 55/60 [10:16:34<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 7.070 Val loss 9.936\n",
      "\r 92%|█████████▏| 55/60 [10:17:13<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 300 Train loss 6.086 Val loss 9.583\n",
      "\r 92%|█████████▏| 55/60 [10:17:56<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 317 best_val_loss 9.467\n",
      "\r 92%|█████████▏| 55/60 [10:18:16<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 2/5\n",
      "\r 92%|█████████▏| 55/60 [10:18:16<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 17.905 Val loss 17.247\n",
      "\r 92%|█████████▏| 55/60 [10:18:20<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 9.137 Val loss 10.226\n",
      "\r 92%|█████████▏| 55/60 [10:19:00<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 7.127 Val loss 9.290\n",
      "\r 92%|█████████▏| 55/60 [10:19:40<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 268 best_val_loss 8.587\n",
      "\r 92%|█████████▏| 55/60 [10:20:22<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 3/5\n",
      "\r 92%|█████████▏| 55/60 [10:20:22<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 18.031 Val loss 17.143\n",
      "\r 92%|█████████▏| 55/60 [10:20:25<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 9.203 Val loss 10.416\n",
      "\r 92%|█████████▏| 55/60 [10:21:06<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 7.213 Val loss 9.431\n",
      "\r 92%|█████████▏| 55/60 [10:21:48<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 300 Train loss 6.153 Val loss 9.261\n",
      "\r 92%|█████████▏| 55/60 [10:22:28<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 298 best_val_loss 9.090\n",
      "\r 92%|█████████▏| 55/60 [10:22:39<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 4/5\n",
      "\r 92%|█████████▏| 55/60 [10:22:39<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 18.118 Val loss 16.816\n",
      "\r 92%|█████████▏| 55/60 [10:22:43<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 8.895 Val loss 10.647\n",
      "\r 92%|█████████▏| 55/60 [10:23:19<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 200 Train loss 7.008 Val loss 10.068\n",
      "\r 92%|█████████▏| 55/60 [10:23:54<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 209 best_val_loss 9.870\n",
      "\r 92%|█████████▏| 55/60 [10:24:08<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rFold: 5/5\n",
      "\r 92%|█████████▏| 55/60 [10:24:08<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 0 Train loss 17.993 Val loss 16.982\n",
      "\r 92%|█████████▏| 55/60 [10:24:12<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEpoch 100 Train loss 8.970 Val loss 10.759\n",
      "\r 92%|█████████▏| 55/60 [10:24:49<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rEarly stopped at epoch 167 best_val_loss 10.038\n",
      "\r 92%|█████████▏| 55/60 [10:25:22<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r                                                                                      \rval MSE loss mean: 9.41039\n",
      "\n",
      "\r 92%|█████████▏| 55/60 [10:25:22<1:04:32, 774.47s/trial, best loss: 8.690782282902642]\r 93%|█████████▎| 56/60 [10:25:22<47:36, 714.17s/trial, best loss: 8.690782282902642]  \r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.20183184098384313, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.06883165399287891, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0004158013808218624, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.2526705124289905}\n",
      "\r 93%|█████████▎| 56/60 [10:25:23<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 1/5\n",
      "\r 93%|█████████▎| 56/60 [10:25:23<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 20.819 Val loss 22.132\n",
      "\r 93%|█████████▎| 56/60 [10:25:26<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.042 Val loss 10.335\n",
      "\r 93%|█████████▎| 56/60 [10:26:24<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.441 Val loss 9.602\n",
      "\r 93%|█████████▎| 56/60 [10:27:29<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 5.198 Val loss 8.945\n",
      "\r 93%|█████████▎| 56/60 [10:28:26<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 356 best_val_loss 8.806\n",
      "\r 93%|█████████▎| 56/60 [10:29:15<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 2/5\n",
      "\r 93%|█████████▎| 56/60 [10:29:15<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.131 Val loss 20.648\n",
      "\r 93%|█████████▎| 56/60 [10:29:19<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 7.982 Val loss 9.090\n",
      "\r 93%|█████████▎| 56/60 [10:30:15<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.217 Val loss 8.390\n",
      "\r 93%|█████████▎| 56/60 [10:31:11<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 226 best_val_loss 8.194\n",
      "\r 93%|█████████▎| 56/60 [10:31:48<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 3/5\n",
      "\r 93%|█████████▎| 56/60 [10:31:48<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.086 Val loss 20.588\n",
      "\r 93%|█████████▎| 56/60 [10:31:52<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.090 Val loss 9.662\n",
      "\r 93%|█████████▎| 56/60 [10:32:54<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.300 Val loss 8.976\n",
      "\r 93%|█████████▎| 56/60 [10:33:48<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 5.215 Val loss 8.505\n",
      "\r 93%|█████████▎| 56/60 [10:34:45<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 358 best_val_loss 8.367\n",
      "\r 93%|█████████▎| 56/60 [10:35:33<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 4/5\n",
      "\r 93%|█████████▎| 56/60 [10:35:33<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.239 Val loss 20.274\n",
      "\r 93%|█████████▎| 56/60 [10:35:37<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 7.746 Val loss 10.238\n",
      "\r 93%|█████████▎| 56/60 [10:36:36<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 5.990 Val loss 9.310\n",
      "\r 93%|█████████▎| 56/60 [10:37:38<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 200 best_val_loss 9.310\n",
      "\r 93%|█████████▎| 56/60 [10:37:57<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 5/5\n",
      "\r 93%|█████████▎| 56/60 [10:37:57<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.192 Val loss 20.370\n",
      "\r 93%|█████████▎| 56/60 [10:38:01<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.145 Val loss 10.387\n",
      "\r 93%|█████████▎| 56/60 [10:39:06<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.451 Val loss 9.440\n",
      "\r 93%|█████████▎| 56/60 [10:40:07<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 257 best_val_loss 9.163\n",
      "\r 93%|█████████▎| 56/60 [10:41:03<47:36, 714.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rval MSE loss mean: 8.76807\n",
      "\n",
      "\r 93%|█████████▎| 56/60 [10:41:03<47:36, 714.17s/trial, best loss: 8.690782282902642]\r 95%|█████████▌| 57/60 [10:41:03<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.1604249290353432, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.43067835200826177, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0009133840205269229, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.0021881045770406615}\n",
      "\r 95%|█████████▌| 57/60 [10:41:03<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 1/5\n",
      "\r 95%|█████████▌| 57/60 [10:41:03<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.410 Val loss 22.226\n",
      "\r 95%|█████████▌| 57/60 [10:41:07<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.025 Val loss 10.655\n",
      "\r 95%|█████████▌| 57/60 [10:41:40<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.178 Val loss 9.415\n",
      "\r 95%|█████████▌| 57/60 [10:42:12<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 206 best_val_loss 9.173\n",
      "\r 95%|█████████▌| 57/60 [10:42:24<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 2/5\n",
      "\r 95%|█████████▌| 57/60 [10:42:24<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.486 Val loss 20.676\n",
      "\r 95%|█████████▌| 57/60 [10:42:27<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.528 Val loss 9.215\n",
      "\r 95%|█████████▌| 57/60 [10:43:02<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.505 Val loss 8.639\n",
      "\r 95%|█████████▌| 57/60 [10:43:37<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 250 best_val_loss 8.219\n",
      "\r 95%|█████████▌| 57/60 [10:44:04<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 3/5\n",
      "\r 95%|█████████▌| 57/60 [10:44:04<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.503 Val loss 20.848\n",
      "\r 95%|█████████▌| 57/60 [10:44:07<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.195 Val loss 10.585\n",
      "\r 95%|█████████▌| 57/60 [10:44:41<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.260 Val loss 9.389\n",
      "\r 95%|█████████▌| 57/60 [10:45:14<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 193 best_val_loss 9.099\n",
      "\r 95%|█████████▌| 57/60 [10:45:22<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 4/5\n",
      "\r 95%|█████████▌| 57/60 [10:45:22<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.452 Val loss 19.717\n",
      "\r 95%|█████████▌| 57/60 [10:45:25<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 7.620 Val loss 10.285\n",
      "\r 95%|█████████▌| 57/60 [10:45:58<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 118 best_val_loss 9.505\n",
      "\r 95%|█████████▌| 57/60 [10:46:16<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 5/5\n",
      "\r 95%|█████████▌| 57/60 [10:46:16<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.400 Val loss 19.784\n",
      "\r 95%|█████████▌| 57/60 [10:46:19<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 8.104 Val loss 11.055\n",
      "\r 95%|█████████▌| 57/60 [10:46:51<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 6.243 Val loss 10.648\n",
      "\r 95%|█████████▌| 57/60 [10:47:26<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 245 best_val_loss 9.480\n",
      "\r 95%|█████████▌| 57/60 [10:47:51<39:06, 782.13s/trial, best loss: 8.690782282902642]\r                                                                                    \rval MSE loss mean: 9.09557\n",
      "\n",
      "\r 95%|█████████▌| 57/60 [10:47:51<39:06, 782.13s/trial, best loss: 8.690782282902642]\r 97%|█████████▋| 58/60 [10:47:51<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.27167477153376046, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.4678336094858372, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00010897261829432187, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.06237068132897669}\n",
      "\r 97%|█████████▋| 58/60 [10:47:51<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 1/5\n",
      "\r 97%|█████████▋| 58/60 [10:47:51<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 19.104 Val loss 18.139\n",
      "\r 97%|█████████▋| 58/60 [10:47:55<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 11.739 Val loss 14.777\n",
      "\r 97%|█████████▋| 58/60 [10:48:59<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 167 best_val_loss 12.517\n",
      "\r 97%|█████████▋| 58/60 [10:50:01<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 2/5\n",
      "\r 97%|█████████▋| 58/60 [10:50:01<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 19.184 Val loss 17.912\n",
      "\r 97%|█████████▋| 58/60 [10:50:05<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 11.763 Val loss 13.226\n",
      "\r 97%|█████████▋| 58/60 [10:51:08<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 9.323 Val loss 11.933\n",
      "\r 97%|█████████▋| 58/60 [10:52:14<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 172 best_val_loss 11.538\n",
      "\r 97%|█████████▋| 58/60 [10:52:16<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 3/5\n",
      "\r 97%|█████████▋| 58/60 [10:52:16<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 19.318 Val loss 17.385\n",
      "\r 97%|█████████▋| 58/60 [10:52:20<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 11.947 Val loss 13.532\n",
      "\r 97%|█████████▋| 58/60 [10:53:22<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 118 best_val_loss 12.931\n",
      "\r 97%|█████████▋| 58/60 [10:53:53<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 4/5\n",
      "\r 97%|█████████▋| 58/60 [10:53:53<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 19.386 Val loss 17.413\n",
      "\r 97%|█████████▋| 58/60 [10:53:57<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 11.738 Val loss 15.039\n",
      "\r 97%|█████████▋| 58/60 [10:55:02<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 78 best_val_loss 13.995\n",
      "\r 97%|█████████▋| 58/60 [10:55:08<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 5/5\n",
      "\r 97%|█████████▋| 58/60 [10:55:08<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 19.249 Val loss 18.084\n",
      "\r 97%|█████████▋| 58/60 [10:55:12<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 12.076 Val loss 13.578\n",
      "\r 97%|█████████▋| 58/60 [10:56:15<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 146 best_val_loss 12.889\n",
      "\r 97%|█████████▋| 58/60 [10:57:05<22:19, 669.70s/trial, best loss: 8.690782282902642]\r                                                                                    \rval MSE loss mean: 12.77382\n",
      "\n",
      "\r 97%|█████████▋| 58/60 [10:57:05<22:19, 669.70s/trial, best loss: 8.690782282902642]\r 98%|█████████▊| 59/60 [10:57:05<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.22400639242235032, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.40745445396207297, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0004874449252820546, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.1274568892666213}\n",
      "\r 98%|█████████▊| 59/60 [10:57:05<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 1/5\n",
      "\r 98%|█████████▊| 59/60 [10:57:05<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.540 Val loss 22.175\n",
      "\r 98%|█████████▊| 59/60 [10:57:09<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 12.991 Val loss 13.617\n",
      "\r 98%|█████████▊| 59/60 [10:57:44<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 7.713 Val loss 9.944\n",
      "\r 98%|█████████▊| 59/60 [10:58:22<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 6.221 Val loss 9.175\n",
      "\r 98%|█████████▊| 59/60 [10:58:56<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rStopped at epoch 380 best_val_loss 8.971\n",
      "\r 98%|█████████▊| 59/60 [10:59:32<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 2/5\n",
      "\r 98%|█████████▊| 59/60 [10:59:32<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.470 Val loss 21.479\n",
      "\r 98%|█████████▊| 59/60 [10:59:36<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 14.063 Val loss 13.476\n",
      "\r 98%|█████████▊| 59/60 [11:00:10<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 8.349 Val loss 9.611\n",
      "\r 98%|█████████▊| 59/60 [11:00:46<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 6.355 Val loss 8.586\n",
      "\r 98%|█████████▊| 59/60 [11:01:27<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 299 best_val_loss 8.508\n",
      "\r 98%|█████████▊| 59/60 [11:01:38<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 3/5\n",
      "\r 98%|█████████▊| 59/60 [11:01:38<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.482 Val loss 21.453\n",
      "\r 98%|█████████▊| 59/60 [11:01:42<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 12.460 Val loss 12.662\n",
      "\r 98%|█████████▊| 59/60 [11:02:15<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 7.515 Val loss 9.445\n",
      "\r 98%|█████████▊| 59/60 [11:02:46<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 6.134 Val loss 8.910\n",
      "\r 98%|█████████▊| 59/60 [11:03:16<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rStopped at epoch 369 best_val_loss 8.626\n",
      "\r 98%|█████████▊| 59/60 [11:03:46<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 4/5\n",
      "\r 98%|█████████▊| 59/60 [11:03:46<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.551 Val loss 21.186\n",
      "\r 98%|█████████▊| 59/60 [11:03:50<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 13.112 Val loss 13.249\n",
      "\r 98%|█████████▊| 59/60 [11:04:22<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 7.302 Val loss 10.122\n",
      "\r 98%|█████████▊| 59/60 [11:04:56<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 6.069 Val loss 9.493\n",
      "\r 98%|█████████▊| 59/60 [11:05:31<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rStopped at epoch 369 best_val_loss 9.215\n",
      "\r 98%|█████████▊| 59/60 [11:06:03<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rFold: 5/5\n",
      "\r 98%|█████████▊| 59/60 [11:06:03<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 0 Train loss 21.440 Val loss 20.881\n",
      "\r 98%|█████████▊| 59/60 [11:06:07<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 100 Train loss 13.135 Val loss 13.797\n",
      "\r 98%|█████████▊| 59/60 [11:06:37<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 200 Train loss 7.981 Val loss 10.206\n",
      "\r 98%|█████████▊| 59/60 [11:07:07<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEpoch 300 Train loss 6.005 Val loss 9.429\n",
      "\r 98%|█████████▊| 59/60 [11:07:39<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rEarly stopped at epoch 346 best_val_loss 9.233\n",
      "\r 98%|█████████▊| 59/60 [11:08:04<10:35, 635.17s/trial, best loss: 8.690782282902642]\r                                                                                    \rval MSE loss mean: 8.91069\n",
      "\n",
      "\r 98%|█████████▊| 59/60 [11:08:04<10:35, 635.17s/trial, best loss: 8.690782282902642]\r100%|██████████| 60/60 [11:08:04<00:00, 642.40s/trial, best loss: 8.690782282902642]\r100%|██████████| 60/60 [11:08:04<00:00, 668.08s/trial, best loss: 8.690782282902642]\n",
      "Best params:{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.16497450048050535, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.004010316577744644, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.000576073526867885, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.29962346731351863}\n",
      "\n",
      "Fold: 1/5\n",
      "[Epoch 0 fold 1 logkcatkm] Train loss 20.897 Val loss 21.380\n",
      "[Epoch 50 fold 1 logkcatkm] Train loss 9.633 Val loss 11.935\n",
      "[Epoch 100 fold 1 logkcatkm] Train loss 7.610 Val loss 10.318\n",
      "[Epoch 150 fold 1 logkcatkm] Train loss 6.836 Val loss 9.922\n",
      "[Epoch 200 fold 1 logkcatkm] Train loss 6.014 Val loss 9.293\n",
      "[Epoch 250 fold 1 logkcatkm] Train loss 5.435 Val loss 9.275\n",
      "[Epoch 300 fold 1 logkcatkm] Train loss 4.942 Val loss 8.959\n",
      "Early stopped at epoch 296 best_val_loss 8.750\n",
      "Fold: 2/5\n",
      "[Epoch 0 fold 2 logkcatkm] Train loss 21.056 Val loss 20.765\n",
      "[Epoch 50 fold 2 logkcatkm] Train loss 9.564 Val loss 11.036\n",
      "[Epoch 100 fold 2 logkcatkm] Train loss 7.819 Val loss 10.183\n",
      "[Epoch 150 fold 2 logkcatkm] Train loss 6.742 Val loss 9.026\n",
      "[Epoch 200 fold 2 logkcatkm] Train loss 5.966 Val loss 9.263\n",
      "[Epoch 250 fold 2 logkcatkm] Train loss 5.359 Val loss 8.662\n",
      "[Epoch 300 fold 2 logkcatkm] Train loss 4.811 Val loss 8.490\n",
      "Early stopped at epoch 281 best_val_loss 8.286\n",
      "Fold: 3/5\n",
      "[Epoch 0 fold 3 logkcatkm] Train loss 21.348 Val loss 20.902\n",
      "[Epoch 50 fold 3 logkcatkm] Train loss 9.626 Val loss 10.840\n",
      "[Epoch 100 fold 3 logkcatkm] Train loss 7.896 Val loss 9.993\n",
      "[Epoch 150 fold 3 logkcatkm] Train loss 6.830 Val loss 9.355\n",
      "[Epoch 200 fold 3 logkcatkm] Train loss 6.118 Val loss 9.328\n",
      "[Epoch 250 fold 3 logkcatkm] Train loss 5.481 Val loss 8.699\n",
      "[Epoch 300 fold 3 logkcatkm] Train loss 4.942 Val loss 8.433\n",
      "Early stopped at epoch 280 best_val_loss 8.298\n",
      "Fold: 4/5\n",
      "[Epoch 0 fold 4 logkcatkm] Train loss 21.281 Val loss 20.315\n",
      "[Epoch 50 fold 4 logkcatkm] Train loss 9.398 Val loss 11.117\n",
      "[Epoch 100 fold 4 logkcatkm] Train loss 7.696 Val loss 10.695\n",
      "[Epoch 150 fold 4 logkcatkm] Train loss 6.744 Val loss 9.877\n",
      "[Epoch 200 fold 4 logkcatkm] Train loss 6.059 Val loss 9.532\n",
      "Early stopped at epoch 194 best_val_loss 9.288\n",
      "Fold: 5/5\n",
      "[Epoch 0 fold 5 logkcatkm] Train loss 21.221 Val loss 20.377\n",
      "[Epoch 50 fold 5 logkcatkm] Train loss 9.823 Val loss 11.685\n",
      "[Epoch 100 fold 5 logkcatkm] Train loss 8.007 Val loss 10.161\n",
      "[Epoch 150 fold 5 logkcatkm] Train loss 7.042 Val loss 9.824\n",
      "[Epoch 200 fold 5 logkcatkm] Train loss 6.151 Val loss 9.465\n",
      "[Epoch 250 fold 5 logkcatkm] Train loss 5.831 Val loss 9.459\n",
      "[Epoch 300 fold 5 logkcatkm] Train loss 5.128 Val loss 9.021\n",
      "Early stopped at epoch 289 best_val_loss 8.832\n",
      "Dimension of x: 1328\n",
      "[Val_mean] rmse 2.9593 mae 2.1689 r2 0.4922 pcc 0.7072 [Test_mean] rmse 3.0284 mae 2.2081 r2 0.4614 pcc 0.6865\n",
      "\n",
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval  # 超参数搜索\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "\n",
    "\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    y_true = np.ravel(y_true)\n",
    "    y_pred = np.ravel(y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "\n",
    "def return_data_loader(x, y, batch_size, shuffle=True, seed=66):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    x = torch.FloatTensor(x)\n",
    "    y = torch.FloatTensor(y)\n",
    "    label_loader = Data.DataLoader(Data.TensorDataset(x, y), batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return label_loader\n",
    "\n",
    "def return_x_y(df_filtered):\n",
    "    y = df_filtered[label_name].values\n",
    "    mask = ~np.isnan(y)\n",
    "\n",
    "    # factors\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_filtered['ph'].values.reshape(-1, 1)\n",
    "        t = df_filtered['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_filtered['mw'].values.reshape(-1, 1)\n",
    "        logp = df_filtered['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_filtered[protein_column].tolist())\n",
    "    substrate_data = np.array(df_filtered[substrate_column].tolist())\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    accu_loss_train = torch.zeros(1).to(device)  # 累计损失\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        data, label_value = data[0].to(device), data[1].to(device)\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = loss_function(pred.float().squeeze(), label_value.float())\n",
    "        loss.backward()\n",
    "        accu_loss_train += loss.detach()\n",
    "\n",
    "        # 在更新权重之前，对梯度进行裁剪，使其不超过clip_value\n",
    "        torch.nn.utils.clip_grad_value_([p for p in model.parameters() if p.requires_grad], clip_value=clip_value)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return accu_loss_train.item() / (step + 1), model\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, mode='search'):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_function = torch.nn.MSELoss()\n",
    "        accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "\n",
    "        for step, data in enumerate(data_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_function(outputs.float().squeeze(), labels.float())\n",
    "            accu_loss += loss.detach()\n",
    "\n",
    "            if mode != 'search':\n",
    "                all_pred.extend(outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    torch.cuda.empty_cache()  # 清理未使用的缓存\n",
    "\n",
    "    if mode == 'search':\n",
    "        return accu_loss.item() / len(data_loader)  # 返回平均损失\n",
    "\n",
    "    else:\n",
    "        return all_pred, all_labels\n",
    "\n",
    "def search_model(params, train_x, train_y, val_x, val_y):\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = TransformerKP(\n",
    "                input_dim=len(train_x[0]),\n",
    "                hidden_dim_list=params['hidden_dim_list'],\n",
    "                encoder_dim_list=params['encoder_dim_list'],\n",
    "                drop_ratio=params['drop_ratio'],\n",
    "                norm_fun=params['norm_fun'],\n",
    "                act_fun=params['act_fun'],\n",
    "                encoder_with_res=params['encoder_with_res'],\n",
    "                encoder_norm=params['encoder_norm'],\n",
    "                encoder_drop_ratio=params['encoder_drop_ratio'],\n",
    "                num_heads=params['num_heads'],\n",
    "                residual_coef=params['residual_coef']\n",
    "            ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums = 0, 0\n",
    "\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        # train\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "        if epoch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch_idx} Train loss {train_loss:.3f} Val loss {val_loss:.3f}')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            break\n",
    "\n",
    "    # print Log\n",
    "    if patience_nums > patience:\n",
    "        print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "    else:\n",
    "        print(f'Stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "\n",
    "def _search_params(params):\n",
    "    print(params)\n",
    "    val_loss_list = []\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "        print(f\"Fold: {fold_idx}/5\")\n",
    "        df_train = df_train_val.iloc[train_index]\n",
    "        df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "        train_x, train_y = return_x_y(df_train)\n",
    "        val_x, val_y = return_x_y(df_val)\n",
    "\n",
    "        val_loss = search_model(params, train_x, train_y, val_x, val_y)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    val_loss_mean = np.mean(val_loss_list, axis=0)\n",
    "    print(f\"val MSE loss mean: {val_loss_mean:.5f}\\n\")\n",
    "\n",
    "    return val_loss_mean\n",
    "\n",
    "\n",
    "def search_best_param(max_evals):\n",
    "    space = {\n",
    "        \"lr\": hp.uniform(\"lr\", 1e-4, 1e-3),\n",
    "        'lrf': hp.choice('lrf', [0.01]),\n",
    "        \"drop_ratio\": hp.uniform(\"drop_ratio\", 0, 0.5),\n",
    "        'hidden_dim_list': hp.choice('hidden_dim_list', [\n",
    "            (2048, 1024, 256),\n",
    "            (1024, 256),\n",
    "            (2048, 256)\n",
    "        ]),\n",
    "        'encoder_dim_list': hp.choice('encoder_dim_list', [\n",
    "            [(8, 32), (1, 64)],\n",
    "            [(8, 32), (2, 64), (1, 64)],\n",
    "            [(4, 64), (2, 128), (1, 128)],\n",
    "            [(4, 64), (2, 128), (1, 64)]\n",
    "        ]),\n",
    "        'norm_fun': hp.choice('norm_fun', ['batch_norm', 'layer_norm']),\n",
    "        'act_fun': hp.choice('act_fun', ['gelu', 'relu']),\n",
    "        'encoder_with_res': hp.choice('encoder_with_res', [False, True]),\n",
    "        'encoder_norm': hp.choice('encoder_norm', ['layer_norm', None]),\n",
    "        \"encoder_drop_ratio\": hp.uniform(\"encoder_drop_ratio\", 0, 0.5),\n",
    "        'num_heads': hp.choice('num_heads', [1, 2, 4]),\n",
    "        'residual_coef': hp.uniform('residual_coef', 0, 1.0),\n",
    "        'batch_size': hp.choice('batch_size', [256, 512, 1024, 2048]),\n",
    "        'epochs': hp.choice('epochs', [200, 300, 400]),\n",
    "    }\n",
    "\n",
    "    trials = Trials()\n",
    "    print(f'[Info] Starting parameter search with MSE_Loss...')\n",
    "    best_params = fmin(fn=_search_params, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "    best_params = space_eval(space, best_params)\n",
    "\n",
    "    # Save the best params to JSON\n",
    "    with open(params_json_path, 'w') as json_file:\n",
    "        json.dump(best_params, json_file)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "search_max_evals = 60\n",
    "patience = 30\n",
    "clip_value = 0.8\n",
    "\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'transformer'\n",
    "label_name = 'logkcatkm'\n",
    "\n",
    "df_input = pd.read_pickle(f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl')\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "params_json_path = f'{current_dir}/model_dict/{input_model}_params.json'\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path) as json_file:\n",
    "        params = json.load(json_file)\n",
    "else:\n",
    "    params = search_best_param(search_max_evals)\n",
    "\n",
    "print(f'Best params:{params}\\n')\n",
    "\n",
    "# Train\n",
    "val_scores_list, test_scores_list = [], []\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "    print(f\"Fold: {fold_idx}/5\")\n",
    "    df_train = df_train_val.iloc[train_index]\n",
    "    df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "    train_x, train_y = return_x_y(df_train)\n",
    "    val_x, val_y = return_x_y(df_val)\n",
    "    test_x, test_y = return_x_y(df_test)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "    test_loader = return_data_loader(test_x, test_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = TransformerKP(\n",
    "                input_dim=len(train_x[0]),\n",
    "                hidden_dim_list=params['hidden_dim_list'],\n",
    "                encoder_dim_list=params['encoder_dim_list'],\n",
    "                drop_ratio=params['drop_ratio'],\n",
    "                norm_fun=params['norm_fun'],\n",
    "                act_fun=params['act_fun'],\n",
    "                encoder_with_res=params['encoder_with_res'],\n",
    "                encoder_norm=params['encoder_norm'],\n",
    "                encoder_drop_ratio=params['encoder_drop_ratio'],\n",
    "                num_heads=params['num_heads'],\n",
    "                residual_coef=params['residual_coef']\n",
    "            ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums, best_model = 0, 0, None\n",
    "\n",
    "    # train\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_model = model\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "            break\n",
    "        if epoch_idx % 50 == 0:\n",
    "            print(f\"[Epoch {epoch_idx} fold {fold_idx} {label_name}] Train loss {train_loss:.3f} Val loss {val_loss:.3f}\")\n",
    "\n",
    "    val_pred, val_labels = evaluate_model(best_model, val_loader, mode='val')\n",
    "    test_pred, test_labels = evaluate_model(best_model, test_loader, mode='test')\n",
    "\n",
    "    # scores\n",
    "    val_scores = return_scores(val_labels, val_pred)\n",
    "    test_scores = return_scores(test_labels, test_pred)\n",
    "    val_scores_list.append(val_scores)\n",
    "    test_scores_list.append(test_scores)\n",
    "\n",
    "    # fold\n",
    "    fold_results.append([\n",
    "        fold_idx,\n",
    "        val_scores[0], val_scores[1], val_scores[2], val_scores[3],\n",
    "        test_scores[0], test_scores[1], test_scores[2], test_scores[3]\n",
    "    ])\n",
    "\n",
    "# mean\n",
    "val_scores_mean = np.mean(val_scores_list, axis=0)\n",
    "test_scores_mean = np.mean(test_scores_list, axis=0)\n",
    "\n",
    "print(f\"Dimension of x: {train_x.shape[1]}\")\n",
    "print(f\"[Val_mean] rmse {val_scores_mean[0]:.4f} mae {val_scores_mean[1]:.4f} r2 {val_scores_mean[2]:.4f} pcc {val_scores_mean[3]:.4f} \"\n",
    "      f\"[Test_mean] rmse {test_scores_mean[0]:.4f} mae {test_scores_mean[1]:.4f} r2 {test_scores_mean[2]:.4f} pcc {test_scores_mean[3]:.4f}\\n\")\n",
    "\n",
    "# save cvs\n",
    "df_cv_results = pd.DataFrame(fold_results, columns=[\n",
    "    \"Fold\",\n",
    "    \"Val_RMSE\", \"Val_MAE\", \"Val_R2\", \"Val_PCC\",\n",
    "    \"Test_RMSE\", \"Test_MAE\", \"Test_R2\", \"Test_PCC\"])\n",
    "df_cv_results.to_excel(f\"{current_dir}/results/{input_model}_cv_results.xlsx\", index=False)\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8850ebf-9d12-4e79-8277-8de6768df232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynoMTGBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db0e6cebfd42dbe7de32cf1b0daf517db5c30eda4a99fad3eb7c5d8b4a7bde0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
