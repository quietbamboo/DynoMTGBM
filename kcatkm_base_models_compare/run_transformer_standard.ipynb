{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ce531d-e4f3-492a-ac72-242191f5be1c",
   "metadata": {},
   "source": [
    "# Transformer with Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9345e-514d-4a5b-9c5c-074dd8adb058",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c830e5e27788ec4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda/envs/DynoMTGBM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class TransformerKP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list=[1024, 256], encoder_dim_list=[(8, 32), (1, 64)],\n",
    "                 drop_ratio=0.12, norm_fun='batch_norm',\n",
    "                 act_fun='gelu', encoder_with_res=False, encoder_norm=None,\n",
    "                 encoder_drop_ratio=0.0, num_heads=1, residual_coef=1.0, device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")):\n",
    "        super(TransformerKP, self).__init__()\n",
    "\n",
    "        # fc blocks\n",
    "        self.fc_layers = FCBlock(input_dim, hidden_dim_list, norm_fun, act_fun, drop_ratio)\n",
    "\n",
    "        # encoder layers\n",
    "        self.encoder_layers = TransformerBlock(hidden_dim_list, encoder_dim_list, drop_ratio, norm_fun,\n",
    "                 act_fun, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef)\n",
    "\n",
    "        self.output_layer = nn.Linear(encoder_dim_list[-1][0] * encoder_dim_list[-1][1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list, norm_fun, act_fun, drop_ratio):\n",
    "        super(FCBlock, self).__init__()\n",
    "\n",
    "        self.act = nn.GELU() if act_fun == 'gelu' else nn.ReLU()\n",
    "\n",
    "        if norm_fun == 'batch_norm':\n",
    "            self.norm_fc = nn.ModuleList(nn.BatchNorm1d(dim) for dim in hidden_dim_list[1:])\n",
    "        elif norm_fun == 'layer_norm':\n",
    "            self.norm_fc = nn.ModuleList(nn.LayerNorm(dim) for dim in hidden_dim_list[1:])\n",
    "        else:\n",
    "            self.norm_fc = nn.ModuleList(nn.Identity() for dim in hidden_dim_list[1:])\n",
    "\n",
    "        # self.norm_fc = nn.ModuleList([nn.BatchNorm1d(dim) if norm_fun == 'batch_norm' else nn.LayerNorm(dim) for dim in hidden_dim_list[1:]])\n",
    "        self.drop = nn.Dropout(p=drop_ratio)\n",
    "\n",
    "        # fc blocks\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_layers.append(nn.Linear(input_dim, hidden_dim_list[0]))\n",
    "\n",
    "        self.norm_fcs = nn.ModuleList()\n",
    "\n",
    "        for idx in range(len(hidden_dim_list) - 1):\n",
    "            self.fc_layers.append(nn.Linear(hidden_dim_list[idx], hidden_dim_list[idx + 1]))\n",
    "            self.norm_fcs.append(self.norm_fc[idx])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.act(self.fc_layers[0](x)))\n",
    "\n",
    "        for fc_layer, norm in zip(self.fc_layers[1:], self.norm_fcs):\n",
    "            x = self.drop(norm(self.act(fc_layer(x))))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim_list, encoder_dim_list, drop_ratio, norm_fun,\n",
    "                 act_fun, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.act = return_act_fun(act_fun)\n",
    "\n",
    "\n",
    "        self.drop = nn.Dropout(p=drop_ratio)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "        encoder_dim = hidden_dim_list[-1]  # 256\n",
    "        for _num, _encoder_dim in encoder_dim_list:  # [(8, 32), (1, 64)]\n",
    "            if norm_fun == 'batch_norm':\n",
    "                self.norm_fun = nn.BatchNorm1d(_num * _encoder_dim)\n",
    "            elif norm_fun == 'layer_norm':\n",
    "                self.norm_fun = nn.LayerNorm(_num * _encoder_dim)\n",
    "            else:\n",
    "                self.norm_fun = nn.Identity()\n",
    "\n",
    "            linear_ = nn.Sequential(\n",
    "                nn.Linear(encoder_dim, _num * _encoder_dim),  # (8, 32)\n",
    "                self.act,\n",
    "                self.norm_fun,\n",
    "                self.drop,\n",
    "            )\n",
    "            encoder_dim = _num * _encoder_dim\n",
    "            reshape_layer = ReshapeLayer(_num, _encoder_dim)\n",
    "            attention_ = SelfAttention(_encoder_dim, encoder_with_res, encoder_norm, encoder_drop_ratio, num_heads, residual_coef)\n",
    "            flatten1_ = nn.Flatten()\n",
    "\n",
    "            self.encoder_layers.append(linear_)\n",
    "            self.encoder_layers.append(reshape_layer)\n",
    "            self.encoder_layers.append(attention_)\n",
    "            self.encoder_layers.append(flatten1_)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def return_act_fun(name):\n",
    "    if name == 'silu':\n",
    "        return nn.SiLU()\n",
    "    elif name == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'gelu':\n",
    "        return nn.GELU()\n",
    "    elif name == 'lrelu':\n",
    "        return nn.LeakyReLU(negative_slope=0.01)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation function: {name}\")\n",
    "\n",
    "\n",
    "class ReshapeLayer(nn.Module):\n",
    "    def __init__(self, num, dim):\n",
    "        super(ReshapeLayer, self).__init__()\n",
    "        self.num = num\n",
    "        self.dim = dim\n",
    "\n",
    "    # @autocast(True)\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), self.num, self.dim)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, output_dim, encoder_with_res=False, encoder_norm=None, encoder_drop_ratio=0.0, num_heads=1, residual_coef=1.0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.encoder_with_res = encoder_with_res\n",
    "        self.residual_coef = residual_coef\n",
    "        self.num_heads = num_heads\n",
    "        self.encoder_norm = nn.LayerNorm(output_dim) if encoder_norm else None\n",
    "        self.dropout = nn.Dropout(p=encoder_drop_ratio) if encoder_drop_ratio > 0 else None\n",
    "\n",
    "        head_dim = output_dim // num_heads\n",
    "        assert head_dim * num_heads == output_dim, \"output_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Define the weights\n",
    "        self.WQ = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.WK = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.WV = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.WQ)\n",
    "        nn.init.xavier_uniform_(self.WK)\n",
    "        nn.init.xavier_uniform_(self.WV)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "\n",
    "        # Linear projections\n",
    "        Q = torch.matmul(x, self.WQ).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "        K = torch.matmul(x, self.WK).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "        V = torch.matmul(x, self.WV).view(batch_size, seq_length, self.num_heads, self.output_dim // self.num_heads)\n",
    "\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        QK = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.output_dim // self.num_heads)\n",
    "        QK = F.softmax(QK, dim=-1)\n",
    "\n",
    "        output = torch.matmul(QK, V).permute(0, 2, 1, 3).contiguous().view(batch_size, seq_length, self.output_dim)\n",
    "\n",
    "        # Apply dropout if specified\n",
    "        if self.dropout:\n",
    "            output = self.dropout(output)\n",
    "\n",
    "        # Apply normalization if specified\n",
    "        if self.encoder_norm:\n",
    "            output = self.encoder_norm(output)\n",
    "\n",
    "        # Add residual connection if specified\n",
    "        if self.encoder_with_res:\n",
    "            output = output + self.residual_coef * x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb2564-e987-4664-8bb3-e2c86d8e1431",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Starting parameter search with MSE_Loss...\n",
      "  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.07092260282354129, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.29414980561749815, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00031078770564890295, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.567234092333582}\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rFold: 1/5\n",
      "\r  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 16.729 Val loss 15.734\n",
      "\r  0%|          | 0/60 [00:07<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 3.935 Val loss 8.970\n",
      "\r  0%|          | 0/60 [01:18<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 83 best_val_loss 8.629\n",
      "\r  0%|          | 0/60 [01:28<?, ?trial/s, best loss=?]\r                                                      \rFold: 2/5\n",
      "\r  0%|          | 0/60 [01:28<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 16.909 Val loss 14.269\n",
      "\r  0%|          | 0/60 [01:31<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 52 best_val_loss 7.946\n",
      "\r  0%|          | 0/60 [02:32<?, ?trial/s, best loss=?]\r                                                      \rFold: 3/5\n",
      "\r  0%|          | 0/60 [02:32<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 17.165 Val loss 14.721\n",
      "\r  0%|          | 0/60 [02:35<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.115 Val loss 8.096\n",
      "\r  0%|          | 0/60 [03:44<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 72 best_val_loss 7.755\n",
      "\r  0%|          | 0/60 [03:46<?, ?trial/s, best loss=?]\r                                                      \rFold: 4/5\n",
      "\r  0%|          | 0/60 [03:46<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 16.977 Val loss 14.472\n",
      "\r  0%|          | 0/60 [03:49<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 32 best_val_loss 8.371\n",
      "\r  0%|          | 0/60 [04:32<?, ?trial/s, best loss=?]\r                                                      \rFold: 5/5\n",
      "\r  0%|          | 0/60 [04:32<?, ?trial/s, best loss=?]\r                                                      \rEpoch 0 Train loss 16.692 Val loss 14.417\n",
      "\r  0%|          | 0/60 [04:35<?, ?trial/s, best loss=?]\r                                                      \rEpoch 100 Train loss 4.353 Val loss 8.332\n",
      "\r  0%|          | 0/60 [05:46<?, ?trial/s, best loss=?]\r                                                      \rEarly stopped at epoch 70 best_val_loss 8.081\n",
      "\r  0%|          | 0/60 [05:47<?, ?trial/s, best loss=?]\r                                                      \rval MSE loss mean: 8.15630\n",
      "\n",
      "\r  0%|          | 0/60 [05:47<?, ?trial/s, best loss=?]\r  2%|▏         | 1/60 [05:47<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.3183670660663709, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.09268186181156346, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.000980336455820193, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.1312258030121195}\n",
      "\r  2%|▏         | 1/60 [05:47<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 1/5\n",
      "\r  2%|▏         | 1/60 [05:47<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 16.951 Val loss 16.547\n",
      "\r  2%|▏         | 1/60 [05:51<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 62 best_val_loss 8.752\n",
      "\r  2%|▏         | 1/60 [06:19<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 2/5\n",
      "\r  2%|▏         | 1/60 [06:19<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.289 Val loss 15.704\n",
      "\r  2%|▏         | 1/60 [06:22<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 23 best_val_loss 8.015\n",
      "\r  2%|▏         | 1/60 [06:38<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 3/5\n",
      "\r  2%|▏         | 1/60 [06:38<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.320 Val loss 16.559\n",
      "\r  2%|▏         | 1/60 [06:42<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 59 best_val_loss 8.234\n",
      "\r  2%|▏         | 1/60 [07:08<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 4/5\n",
      "\r  2%|▏         | 1/60 [07:08<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.280 Val loss 15.134\n",
      "\r  2%|▏         | 1/60 [07:12<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 57 best_val_loss 8.317\n",
      "\r  2%|▏         | 1/60 [07:37<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 5/5\n",
      "\r  2%|▏         | 1/60 [07:37<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.393 Val loss 15.895\n",
      "\r  2%|▏         | 1/60 [07:41<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 67 best_val_loss 8.376\n",
      "\r  2%|▏         | 1/60 [08:11<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r                                                                                  \rval MSE loss mean: 8.33873\n",
      "\n",
      "\r  2%|▏         | 1/60 [08:11<5:41:49, 347.62s/trial, best loss: 8.156302349384015]\r  3%|▎         | 2/60 [08:11<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.4666840428027123, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.1920888432236409, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0007147432146692689, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.32457219487506095}\n",
      "\r  3%|▎         | 2/60 [08:11<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 1/5\n",
      "\r  3%|▎         | 2/60 [08:11<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.449 Val loss 19.144\n",
      "\r  3%|▎         | 2/60 [08:15<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 53 best_val_loss 9.257\n",
      "\r  3%|▎         | 2/60 [09:19<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 2/5\n",
      "\r  3%|▎         | 2/60 [09:19<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.681 Val loss 16.865\n",
      "\r  3%|▎         | 2/60 [09:23<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 59 best_val_loss 8.728\n",
      "\r  3%|▎         | 2/60 [10:32<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 3/5\n",
      "\r  3%|▎         | 2/60 [10:32<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.528 Val loss 17.458\n",
      "\r  3%|▎         | 2/60 [10:36<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 100 Train loss 5.672 Val loss 9.025\n",
      "\r  3%|▎         | 2/60 [11:53<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 76 best_val_loss 8.250\n",
      "\r  3%|▎         | 2/60 [11:59<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 4/5\n",
      "\r  3%|▎         | 2/60 [11:59<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.781 Val loss 17.920\n",
      "\r  3%|▎         | 2/60 [12:02<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 100 Train loss 5.908 Val loss 10.017\n",
      "\r  3%|▎         | 2/60 [13:12<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 76 best_val_loss 9.125\n",
      "\r  3%|▎         | 2/60 [13:18<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 5/5\n",
      "\r  3%|▎         | 2/60 [13:18<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 17.466 Val loss 18.903\n",
      "\r  3%|▎         | 2/60 [13:21<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 44 best_val_loss 9.082\n",
      "\r  3%|▎         | 2/60 [14:18<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r                                                                                  \rval MSE loss mean: 8.88845\n",
      "\n",
      "\r  3%|▎         | 2/60 [14:18<3:40:25, 228.02s/trial, best loss: 8.156302349384015]\r  5%|▌         | 3/60 [14:18<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.06531243634724254, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.22944661162425872, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0008213243191282325, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.1996389263493633}\n",
      "\r  5%|▌         | 3/60 [14:18<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 1/5\n",
      "\r  5%|▌         | 3/60 [14:18<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 18.387 Val loss 17.341\n",
      "\r  5%|▌         | 3/60 [14:22<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 100 Train loss 3.840 Val loss 8.742\n",
      "\r  5%|▌         | 3/60 [15:29<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 89 best_val_loss 8.223\n",
      "\r  5%|▌         | 3/60 [15:43<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 2/5\n",
      "\r  5%|▌         | 3/60 [15:43<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 18.733 Val loss 15.849\n",
      "\r  5%|▌         | 3/60 [15:47<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 100 Train loss 3.794 Val loss 8.038\n",
      "\r  5%|▌         | 3/60 [16:53<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 69 best_val_loss 7.700\n",
      "\r  5%|▌         | 3/60 [16:53<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 3/5\n",
      "\r  5%|▌         | 3/60 [16:53<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 18.444 Val loss 17.279\n",
      "\r  5%|▌         | 3/60 [16:56<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 44 best_val_loss 7.816\n",
      "\r  5%|▌         | 3/60 [17:49<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 4/5\n",
      "\r  5%|▌         | 3/60 [17:49<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 18.411 Val loss 16.532\n",
      "\r  5%|▌         | 3/60 [17:53<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 100 Train loss 3.668 Val loss 8.292\n",
      "\r  5%|▌         | 3/60 [19:02<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 80 best_val_loss 7.834\n",
      "\r  5%|▌         | 3/60 [19:11<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rFold: 5/5\n",
      "\r  5%|▌         | 3/60 [19:11<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEpoch 0 Train loss 18.669 Val loss 14.874\n",
      "\r  5%|▌         | 3/60 [19:14<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rEarly stopped at epoch 68 best_val_loss 8.003\n",
      "\r  5%|▌         | 3/60 [20:26<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r                                                                                  \rval MSE loss mean: 7.91544\n",
      "\n",
      "\r  5%|▌         | 3/60 [20:26<4:36:49, 291.39s/trial, best loss: 8.156302349384015]\r  7%|▋         | 4/60 [20:26<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.12429876129514322, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.3800009240044361, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0006871110824393927, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.8174030572291857}\n",
      "\r  7%|▋         | 4/60 [20:27<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r  7%|▋         | 4/60 [20:27<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.848 Val loss 23.557\n",
      "\r  7%|▋         | 4/60 [20:30<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 60 best_val_loss 10.984\n",
      "\r  7%|▋         | 4/60 [21:00<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r  7%|▋         | 4/60 [21:00<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.954 Val loss 25.782\n",
      "\r  7%|▋         | 4/60 [21:03<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.448 Val loss 12.019\n",
      "\r  7%|▋         | 4/60 [21:36<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 72 best_val_loss 10.623\n",
      "\r  7%|▋         | 4/60 [21:36<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r  7%|▋         | 4/60 [21:36<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.024 Val loss 23.642\n",
      "\r  7%|▋         | 4/60 [21:40<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.228 Val loss 12.295\n",
      "\r  7%|▋         | 4/60 [22:12<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 115 best_val_loss 11.544\n",
      "\r  7%|▋         | 4/60 [22:27<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r  7%|▋         | 4/60 [22:27<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.017 Val loss 23.326\n",
      "\r  7%|▋         | 4/60 [22:30<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.256 Val loss 11.656\n",
      "\r  7%|▋         | 4/60 [23:03<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 142 best_val_loss 10.990\n",
      "\r  7%|▋         | 4/60 [23:24<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r  7%|▋         | 4/60 [23:24<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.072 Val loss 20.058\n",
      "\r  7%|▋         | 4/60 [23:28<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 57 best_val_loss 11.932\n",
      "\r  7%|▋         | 4/60 [23:54<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 11.21468\n",
      "\n",
      "\r  7%|▋         | 4/60 [23:54<5:00:17, 321.74s/trial, best loss: 7.915440486027644]\r  8%|▊         | 5/60 [23:54<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.3745148470439757, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.2729412011049862, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0009605894978159132, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.6855545996569364}\n",
      "\r  8%|▊         | 5/60 [23:55<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r  8%|▊         | 5/60 [23:55<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.705 Val loss 22.891\n",
      "\r  8%|▊         | 5/60 [23:58<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.068 Val loss 10.319\n",
      "\r  8%|▊         | 5/60 [24:46<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 97 best_val_loss 9.604\n",
      "\r  8%|▊         | 5/60 [24:59<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r  8%|▊         | 5/60 [24:59<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.715 Val loss 21.186\n",
      "\r  8%|▊         | 5/60 [25:03<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.050 Val loss 9.598\n",
      "\r  8%|▊         | 5/60 [25:49<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 89 best_val_loss 9.362\n",
      "\r  8%|▊         | 5/60 [25:59<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r  8%|▊         | 5/60 [25:59<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.897 Val loss 21.317\n",
      "\r  8%|▊         | 5/60 [26:03<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.392 Val loss 10.126\n",
      "\r  8%|▊         | 5/60 [26:50<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 81 best_val_loss 9.750\n",
      "\r  8%|▊         | 5/60 [26:55<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r  8%|▊         | 5/60 [26:55<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.997 Val loss 19.275\n",
      "\r  8%|▊         | 5/60 [26:59<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 60 best_val_loss 9.900\n",
      "\r  8%|▊         | 5/60 [27:37<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r  8%|▊         | 5/60 [27:37<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 20.927 Val loss 20.688\n",
      "\r  8%|▊         | 5/60 [27:41<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.145 Val loss 10.480\n",
      "\r  8%|▊         | 5/60 [28:28<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 92 best_val_loss 9.663\n",
      "\r  8%|▊         | 5/60 [28:39<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 9.65578\n",
      "\n",
      "\r  8%|▊         | 5/60 [28:39<4:17:14, 280.62s/trial, best loss: 7.915440486027644]\r 10%|█         | 6/60 [28:39<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.21626706093748677, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.3458543833351759, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0007867570166193107, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.7303566467215511}\n",
      "\r 10%|█         | 6/60 [28:39<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r 10%|█         | 6/60 [28:39<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.564 Val loss 17.386\n",
      "\r 10%|█         | 6/60 [28:43<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.448 Val loss 8.286\n",
      "\r 10%|█         | 6/60 [29:10<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 99 best_val_loss 8.203\n",
      "\r 10%|█         | 6/60 [29:19<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r 10%|█         | 6/60 [29:19<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.534 Val loss 16.660\n",
      "\r 10%|█         | 6/60 [29:23<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 51 best_val_loss 8.007\n",
      "\r 10%|█         | 6/60 [29:46<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r 10%|█         | 6/60 [29:46<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.544 Val loss 16.149\n",
      "\r 10%|█         | 6/60 [29:50<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.802 Val loss 8.632\n",
      "\r 10%|█         | 6/60 [30:19<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 200 Train loss 3.771 Val loss 7.861\n",
      "\r 10%|█         | 6/60 [30:48<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 175 best_val_loss 7.632\n",
      "\r 10%|█         | 6/60 [30:50<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r 10%|█         | 6/60 [30:50<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.483 Val loss 16.292\n",
      "\r 10%|█         | 6/60 [30:53<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 46 best_val_loss 8.718\n",
      "\r 10%|█         | 6/60 [31:17<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r 10%|█         | 6/60 [31:17<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.382 Val loss 16.476\n",
      "\r 10%|█         | 6/60 [31:20<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.726 Val loss 8.593\n",
      "\r 10%|█         | 6/60 [31:50<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 119 best_val_loss 8.123\n",
      "\r 10%|█         | 6/60 [32:03<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 8.13639\n",
      "\n",
      "\r 10%|█         | 6/60 [32:03<4:13:51, 282.07s/trial, best loss: 7.915440486027644]\r 12%|█▏        | 7/60 [32:03<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 512, 'drop_ratio': 0.29719459690320094, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.09986611007971241, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0006103768681869008, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.19488066373363544}\n",
      "\r 12%|█▏        | 7/60 [32:03<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r 12%|█▏        | 7/60 [32:03<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 17.290 Val loss 16.452\n",
      "\r 12%|█▏        | 7/60 [32:07<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 33 best_val_loss 8.653\n",
      "\r 12%|█▏        | 7/60 [32:34<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r 12%|█▏        | 7/60 [32:34<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 17.252 Val loss 15.011\n",
      "\r 12%|█▏        | 7/60 [32:37<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.221 Val loss 8.162\n",
      "\r 12%|█▏        | 7/60 [33:20<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 86 best_val_loss 7.656\n",
      "\r 12%|█▏        | 7/60 [33:27<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r 12%|█▏        | 7/60 [33:27<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 17.409 Val loss 15.343\n",
      "\r 12%|█▏        | 7/60 [33:31<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.494 Val loss 8.525\n",
      "\r 12%|█▏        | 7/60 [34:13<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 156 best_val_loss 7.971\n",
      "\r 12%|█▏        | 7/60 [34:49<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r 12%|█▏        | 7/60 [34:49<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 17.706 Val loss 15.173\n",
      "\r 12%|█▏        | 7/60 [34:53<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.330 Val loss 8.595\n",
      "\r 12%|█▏        | 7/60 [35:34<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 73 best_val_loss 8.397\n",
      "\r 12%|█▏        | 7/60 [35:36<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r 12%|█▏        | 7/60 [35:36<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 17.313 Val loss 15.649\n",
      "\r 12%|█▏        | 7/60 [35:39<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.115 Val loss 8.834\n",
      "\r 12%|█▏        | 7/60 [36:21<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 78 best_val_loss 8.224\n",
      "\r 12%|█▏        | 7/60 [36:25<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 8.18013\n",
      "\n",
      "\r 12%|█▏        | 7/60 [36:25<3:46:40, 256.62s/trial, best loss: 7.915440486027644]\r 13%|█▎        | 8/60 [36:25<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.16587906638553274, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.4270632809649764, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0009169623662915778, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.05469285216454578}\n",
      "\r 13%|█▎        | 8/60 [36:25<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r 13%|█▎        | 8/60 [36:25<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.635 Val loss 17.968\n",
      "\r 13%|█▎        | 8/60 [36:28<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.650 Val loss 8.656\n",
      "\r 13%|█▎        | 8/60 [36:59<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 74 best_val_loss 8.376\n",
      "\r 13%|█▎        | 8/60 [37:01<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r 13%|█▎        | 8/60 [37:01<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.576 Val loss 17.464\n",
      "\r 13%|█▎        | 8/60 [37:04<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 48 best_val_loss 8.160\n",
      "\r 13%|█▎        | 8/60 [37:29<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r 13%|█▎        | 8/60 [37:29<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.616 Val loss 17.444\n",
      "\r 13%|█▎        | 8/60 [37:32<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.783 Val loss 8.081\n",
      "\r 13%|█▎        | 8/60 [38:03<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 156 best_val_loss 7.739\n",
      "\r 13%|█▎        | 8/60 [38:29<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r 13%|█▎        | 8/60 [38:29<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.615 Val loss 16.940\n",
      "\r 13%|█▎        | 8/60 [38:33<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 4.586 Val loss 8.771\n",
      "\r 13%|█▎        | 8/60 [39:05<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 132 best_val_loss 8.544\n",
      "\r 13%|█▎        | 8/60 [39:25<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r 13%|█▎        | 8/60 [39:26<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 18.528 Val loss 18.387\n",
      "\r 13%|█▎        | 8/60 [39:29<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 5.819 Val loss 9.054\n",
      "\r 13%|█▎        | 8/60 [40:01<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 123 best_val_loss 8.317\n",
      "\r 13%|█▎        | 8/60 [40:17<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 8.22702\n",
      "\n",
      "\r 13%|█▎        | 8/60 [40:17<3:43:45, 258.19s/trial, best loss: 7.915440486027644]\r 15%|█▌        | 9/60 [40:17<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.44325444664009933, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.2907545463123231, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00025692342544241073, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.2124388727587495}\n",
      "\r 15%|█▌        | 9/60 [40:17<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 1/5\n",
      "\r 15%|█▌        | 9/60 [40:17<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.430 Val loss 23.285\n",
      "\r 15%|█▌        | 9/60 [40:21<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 6.343 Val loss 9.157\n",
      "\r 15%|█▌        | 9/60 [41:35<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 200 Train loss 4.924 Val loss 8.310\n",
      "\r 15%|█▌        | 9/60 [42:46<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 209 best_val_loss 8.297\n",
      "\r 15%|█▌        | 9/60 [43:17<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 2/5\n",
      "\r 15%|█▌        | 9/60 [43:17<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.486 Val loss 22.426\n",
      "\r 15%|█▌        | 9/60 [43:21<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 6.470 Val loss 8.346\n",
      "\r 15%|█▌        | 9/60 [44:31<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 200 Train loss 5.107 Val loss 7.852\n",
      "\r 15%|█▌        | 9/60 [45:46<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 242 best_val_loss 7.543\n",
      "\r 15%|█▌        | 9/60 [46:43<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 3/5\n",
      "\r 15%|█▌        | 9/60 [46:43<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.742 Val loss 22.014\n",
      "\r 15%|█▌        | 9/60 [46:46<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 6.515 Val loss 8.772\n",
      "\r 15%|█▌        | 9/60 [48:03<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 200 Train loss 5.104 Val loss 8.024\n",
      "\r 15%|█▌        | 9/60 [49:19<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 220 best_val_loss 7.916\n",
      "\r 15%|█▌        | 9/60 [49:58<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 4/5\n",
      "\r 15%|█▌        | 9/60 [49:58<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.740 Val loss 21.560\n",
      "\r 15%|█▌        | 9/60 [50:02<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 6.547 Val loss 9.025\n",
      "\r 15%|█▌        | 9/60 [51:09<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 200 Train loss 4.834 Val loss 8.285\n",
      "\r 15%|█▌        | 9/60 [52:26<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rStopped at epoch 284 best_val_loss 8.004\n",
      "\r 15%|█▌        | 9/60 [53:42<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rFold: 5/5\n",
      "\r 15%|█▌        | 9/60 [53:42<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 0 Train loss 21.679 Val loss 21.284\n",
      "\r 15%|█▌        | 9/60 [53:46<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEpoch 100 Train loss 6.980 Val loss 8.793\n",
      "\r 15%|█▌        | 9/60 [55:00<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rEarly stopped at epoch 144 best_val_loss 8.084\n",
      "\r 15%|█▌        | 9/60 [55:57<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r                                                                                  \rval MSE loss mean: 7.96888\n",
      "\n",
      "\r 15%|█▌        | 9/60 [55:57<3:32:38, 250.16s/trial, best loss: 7.915440486027644]\r 17%|█▋        | 10/60 [55:57<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.38999563442712737, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.12606017465497132, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.000761852652070988, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.6204627020400217}\n",
      "\r 17%|█▋        | 10/60 [55:57<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rFold: 1/5\n",
      "\r 17%|█▋        | 10/60 [55:57<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 0 Train loss 17.168 Val loss 16.560\n",
      "\r 17%|█▋        | 10/60 [56:01<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEarly stopped at epoch 63 best_val_loss 9.035\n",
      "\r 17%|█▋        | 10/60 [56:57<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rFold: 2/5\n",
      "\r 17%|█▋        | 10/60 [56:57<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 0 Train loss 17.301 Val loss 16.553\n",
      "\r 17%|█▋        | 10/60 [57:00<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 100 Train loss 5.616 Val loss 8.497\n",
      "\r 17%|█▋        | 10/60 [57:59<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEarly stopped at epoch 130 best_val_loss 8.030\n",
      "\r 17%|█▋        | 10/60 [58:34<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rFold: 3/5\n",
      "\r 17%|█▋        | 10/60 [58:34<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 0 Train loss 17.179 Val loss 16.509\n",
      "\r 17%|█▋        | 10/60 [58:38<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 100 Train loss 5.131 Val loss 8.514\n",
      "\r 17%|█▋        | 10/60 [59:34<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEarly stopped at epoch 71 best_val_loss 8.463\n",
      "\r 17%|█▋        | 10/60 [59:35<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rFold: 4/5\n",
      "\r 17%|█▋        | 10/60 [59:35<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEpoch 0 Train loss 17.324 Val loss 15.401\n",
      "\r 17%|█▋        | 10/60 [59:39<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                   \rEarly stopped at epoch 55 best_val_loss 8.936\n",
      "\r 17%|█▋        | 10/60 [1:00:24<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 5/5\n",
      "\r 17%|█▋        | 10/60 [1:00:24<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 17.154 Val loss 16.753\n",
      "\r 17%|█▋        | 10/60 [1:00:28<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 5.644 Val loss 9.132\n",
      "\r 17%|█▋        | 10/60 [1:01:27<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 135 best_val_loss 8.288\n",
      "\r 17%|█▋        | 10/60 [1:02:06<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r                                                                                     \rval MSE loss mean: 8.55052\n",
      "\n",
      "\r 17%|█▋        | 10/60 [1:02:06<6:25:57, 463.16s/trial, best loss: 7.915440486027644]\r 18%|█▊        | 11/60 [1:02:06<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.08409960816100293, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.4422971497396002, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.00031183276834529283, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.5504283990897214}\n",
      "\r 18%|█▊        | 11/60 [1:02:06<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 1/5\n",
      "\r 18%|█▊        | 11/60 [1:02:06<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 18.742 Val loss 17.788\n",
      "\r 18%|█▊        | 11/60 [1:02:10<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.396 Val loss 8.464\n",
      "\r 18%|█▊        | 11/60 [1:02:40<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 84 best_val_loss 8.200\n",
      "\r 18%|█▊        | 11/60 [1:02:43<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 2/5\n",
      "\r 18%|█▊        | 11/60 [1:02:43<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 18.524 Val loss 17.631\n",
      "\r 18%|█▊        | 11/60 [1:02:47<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.357 Val loss 7.930\n",
      "\r 18%|█▊        | 11/60 [1:03:16<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 141 best_val_loss 7.721\n",
      "\r 18%|█▊        | 11/60 [1:03:37<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 3/5\n",
      "\r 18%|█▊        | 11/60 [1:03:37<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 19.012 Val loss 17.232\n",
      "\r 18%|█▊        | 11/60 [1:03:41<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.527 Val loss 7.893\n",
      "\r 18%|█▊        | 11/60 [1:04:11<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 7.721\n",
      "\r 18%|█▊        | 11/60 [1:04:19<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 4/5\n",
      "\r 18%|█▊        | 11/60 [1:04:19<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 18.777 Val loss 17.405\n",
      "\r 18%|█▊        | 11/60 [1:04:22<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.362 Val loss 8.904\n",
      "\r 18%|█▊        | 11/60 [1:04:53<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 107 best_val_loss 8.315\n",
      "\r 18%|█▊        | 11/60 [1:05:05<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 5/5\n",
      "\r 18%|█▊        | 11/60 [1:05:05<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 18.829 Val loss 17.944\n",
      "\r 18%|█▊        | 11/60 [1:05:08<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.561 Val loss 8.348\n",
      "\r 18%|█▊        | 11/60 [1:05:38<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 126 best_val_loss 8.115\n",
      "\r 18%|█▊        | 11/60 [1:05:54<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r                                                                                     \rval MSE loss mean: 8.01434\n",
      "\n",
      "\r 18%|█▊        | 11/60 [1:05:54<5:54:41, 434.32s/trial, best loss: 7.915440486027644]\r 20%|██        | 12/60 [1:05:54<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.23296748776589687, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.17135399913909316, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0006524305563838732, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.5228632239270082}\n",
      "\r 20%|██        | 12/60 [1:05:54<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 1/5\n",
      "\r 20%|██        | 12/60 [1:05:54<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 20.289 Val loss 22.400\n",
      "\r 20%|██        | 12/60 [1:05:58<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.024 Val loss 8.169\n",
      "\r 20%|██        | 12/60 [1:06:22<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 82 best_val_loss 8.017\n",
      "\r 20%|██        | 12/60 [1:06:25<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 2/5\n",
      "\r 20%|██        | 12/60 [1:06:25<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 20.443 Val loss 20.714\n",
      "\r 20%|██        | 12/60 [1:06:29<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.090 Val loss 7.664\n",
      "\r 20%|██        | 12/60 [1:06:55<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 144 best_val_loss 7.325\n",
      "\r 20%|██        | 12/60 [1:07:15<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 3/5\n",
      "\r 20%|██        | 12/60 [1:07:15<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 20.636 Val loss 21.153\n",
      "\r 20%|██        | 12/60 [1:07:18<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.231 Val loss 8.224\n",
      "\r 20%|██        | 12/60 [1:07:45<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 69 best_val_loss 8.086\n",
      "\r 20%|██        | 12/60 [1:07:45<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 4/5\n",
      "\r 20%|██        | 12/60 [1:07:45<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 20.784 Val loss 20.547\n",
      "\r 20%|██        | 12/60 [1:07:49<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.177 Val loss 7.669\n",
      "\r 20%|██        | 12/60 [1:08:17<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 90 best_val_loss 7.580\n",
      "\r 20%|██        | 12/60 [1:08:24<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rFold: 5/5\n",
      "\r 20%|██        | 12/60 [1:08:24<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 0 Train loss 20.711 Val loss 19.796\n",
      "\r 20%|██        | 12/60 [1:08:28<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEpoch 100 Train loss 4.216 Val loss 8.473\n",
      "\r 20%|██        | 12/60 [1:08:56<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 8.107\n",
      "\r 20%|██        | 12/60 [1:08:56<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r                                                                                     \rval MSE loss mean: 7.82310\n",
      "\n",
      "\r 20%|██        | 12/60 [1:08:56<4:57:14, 371.55s/trial, best loss: 7.915440486027644]\r 22%|██▏       | 13/60 [1:08:56<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.34911321589371486, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.22991059624275845, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.00035642188098698627, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.507143165273824}\n",
      "\r 22%|██▏       | 13/60 [1:08:56<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 22%|██▏       | 13/60 [1:08:56<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.475 Val loss 17.571\n",
      "\r 22%|██▏       | 13/60 [1:09:00<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.273 Val loss 8.752\n",
      "\r 22%|██▏       | 13/60 [1:09:30<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 112 best_val_loss 8.454\n",
      "\r 22%|██▏       | 13/60 [1:09:44<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 22%|██▏       | 13/60 [1:09:44<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.433 Val loss 17.122\n",
      "\r 22%|██▏       | 13/60 [1:09:47<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.997 Val loss 8.097\n",
      "\r 22%|██▏       | 13/60 [1:10:19<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rStopped at epoch 182 best_val_loss 7.875\n",
      "\r 22%|██▏       | 13/60 [1:10:48<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 22%|██▏       | 13/60 [1:10:48<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.808 Val loss 16.832\n",
      "\r 22%|██▏       | 13/60 [1:10:52<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.446 Val loss 8.401\n",
      "\r 22%|██▏       | 13/60 [1:11:21<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rStopped at epoch 174 best_val_loss 7.995\n",
      "\r 22%|██▏       | 13/60 [1:11:51<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 22%|██▏       | 13/60 [1:11:51<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.492 Val loss 17.074\n",
      "\r 22%|██▏       | 13/60 [1:11:54<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.018 Val loss 9.050\n",
      "\r 22%|██▏       | 13/60 [1:12:29<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rStopped at epoch 179 best_val_loss 8.670\n",
      "\r 22%|██▏       | 13/60 [1:13:02<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 22%|██▏       | 13/60 [1:13:02<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.524 Val loss 17.549\n",
      "\r 22%|██▏       | 13/60 [1:13:06<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.449 Val loss 8.772\n",
      "\r 22%|██▏       | 13/60 [1:13:37<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 132 best_val_loss 8.312\n",
      "\r 22%|██▏       | 13/60 [1:13:55<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.26121\n",
      "\n",
      "\r 22%|██▏       | 13/60 [1:13:55<4:06:01, 314.08s/trial, best loss: 7.823103904724121]\r 23%|██▎       | 14/60 [1:13:55<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.43435148448396343, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.20254546216708508, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0009734600742496138, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.3442840130641803}\n",
      "\r 23%|██▎       | 14/60 [1:13:55<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 23%|██▎       | 14/60 [1:13:55<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 18.688 Val loss 17.809\n",
      "\r 23%|██▎       | 14/60 [1:13:59<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 7.182 Val loss 9.691\n",
      "\r 23%|██▎       | 14/60 [1:14:30<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 91 best_val_loss 8.628\n",
      "\r 23%|██▎       | 14/60 [1:14:37<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 23%|██▎       | 14/60 [1:14:37<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 18.706 Val loss 17.172\n",
      "\r 23%|██▎       | 14/60 [1:14:41<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.178 Val loss 8.118\n",
      "\r 23%|██▎       | 14/60 [1:15:14<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 113 best_val_loss 7.533\n",
      "\r 23%|██▎       | 14/60 [1:15:27<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 23%|██▎       | 14/60 [1:15:27<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 18.889 Val loss 17.227\n",
      "\r 23%|██▎       | 14/60 [1:15:31<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.215 Val loss 8.734\n",
      "\r 23%|██▎       | 14/60 [1:16:02<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 8.552\n",
      "\r 23%|██▎       | 14/60 [1:16:03<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 23%|██▎       | 14/60 [1:16:03<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 18.925 Val loss 16.584\n",
      "\r 23%|██▎       | 14/60 [1:16:07<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.569 Val loss 8.895\n",
      "\r 23%|██▎       | 14/60 [1:16:38<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 90 best_val_loss 8.294\n",
      "\r 23%|██▎       | 14/60 [1:16:44<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 23%|██▎       | 14/60 [1:16:44<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 18.819 Val loss 16.522\n",
      "\r 23%|██▎       | 14/60 [1:16:48<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.725 Val loss 9.345\n",
      "\r 23%|██▎       | 14/60 [1:17:18<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 83 best_val_loss 8.601\n",
      "\r 23%|██▎       | 14/60 [1:17:22<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.32159\n",
      "\n",
      "\r 23%|██▎       | 14/60 [1:17:22<3:57:20, 309.57s/trial, best loss: 7.823103904724121]\r 25%|██▌       | 15/60 [1:17:22<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.07360689036739099, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.08160377929079748, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.0009689446741805537, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.4750162991470407}\n",
      "\r 25%|██▌       | 15/60 [1:17:22<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 25%|██▌       | 15/60 [1:17:22<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.972 Val loss 22.484\n",
      "\r 25%|██▌       | 15/60 [1:17:25<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 65 best_val_loss 8.184\n",
      "\r 25%|██▌       | 15/60 [1:17:54<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 25%|██▌       | 15/60 [1:17:54<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.549 Val loss 21.722\n",
      "\r 25%|██▌       | 15/60 [1:17:57<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.922 Val loss 8.055\n",
      "\r 25%|██▌       | 15/60 [1:18:27<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 110 best_val_loss 7.719\n",
      "\r 25%|██▌       | 15/60 [1:18:40<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 25%|██▌       | 15/60 [1:18:40<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.443 Val loss 21.641\n",
      "\r 25%|██▌       | 15/60 [1:18:43<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 52 best_val_loss 7.883\n",
      "\r 25%|██▌       | 15/60 [1:19:11<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 25%|██▌       | 15/60 [1:19:11<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.713 Val loss 21.416\n",
      "\r 25%|██▌       | 15/60 [1:19:15<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.881 Val loss 8.600\n",
      "\r 25%|██▌       | 15/60 [1:19:48<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 8.275\n",
      "\r 25%|██▌       | 15/60 [1:19:49<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 25%|██▌       | 15/60 [1:19:49<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.876 Val loss 21.222\n",
      "\r 25%|██▌       | 15/60 [1:19:52<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.125 Val loss 8.304\n",
      "\r 25%|██▌       | 15/60 [1:20:27<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 127 best_val_loss 7.959\n",
      "\r 25%|██▌       | 15/60 [1:20:46<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.00385\n",
      "\n",
      "\r 25%|██▌       | 15/60 [1:20:46<3:28:49, 278.44s/trial, best loss: 7.823103904724121]\r 27%|██▋       | 16/60 [1:20:46<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.03508741316157621, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.24075420865880987, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00017404763592899423, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.1785394248741693}\n",
      "\r 27%|██▋       | 16/60 [1:20:46<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 27%|██▋       | 16/60 [1:20:46<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 17.558 Val loss 15.891\n",
      "\r 27%|██▋       | 16/60 [1:20:50<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 51 best_val_loss 8.524\n",
      "\r 27%|██▋       | 16/60 [1:21:15<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 27%|██▋       | 16/60 [1:21:15<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 17.619 Val loss 15.345\n",
      "\r 27%|██▋       | 16/60 [1:21:19<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 43 best_val_loss 7.551\n",
      "\r 27%|██▋       | 16/60 [1:21:42<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 27%|██▋       | 16/60 [1:21:42<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 17.434 Val loss 15.615\n",
      "\r 27%|██▋       | 16/60 [1:21:45<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 54 best_val_loss 8.291\n",
      "\r 27%|██▋       | 16/60 [1:22:12<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 27%|██▋       | 16/60 [1:22:12<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 17.507 Val loss 14.392\n",
      "\r 27%|██▋       | 16/60 [1:22:16<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.428 Val loss 8.012\n",
      "\r 27%|██▋       | 16/60 [1:22:48<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 73 best_val_loss 7.832\n",
      "\r 27%|██▋       | 16/60 [1:22:50<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 27%|██▋       | 16/60 [1:22:50<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 17.476 Val loss 15.039\n",
      "\r 27%|██▋       | 16/60 [1:22:53<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 68 best_val_loss 8.536\n",
      "\r 27%|██▋       | 16/60 [1:23:23<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.14685\n",
      "\n",
      "\r 27%|██▋       | 16/60 [1:23:23<3:07:45, 256.04s/trial, best loss: 7.823103904724121]\r 28%|██▊       | 17/60 [1:23:23<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.4241772103427654, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.04701141427919037, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.00038502094885573847, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.39714119180963137}\n",
      "\r 28%|██▊       | 17/60 [1:23:23<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 28%|██▊       | 17/60 [1:23:23<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.777 Val loss 17.842\n",
      "\r 28%|██▊       | 17/60 [1:23:26<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.746 Val loss 9.849\n",
      "\r 28%|██▊       | 17/60 [1:23:56<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 97 best_val_loss 8.610\n",
      "\r 28%|██▊       | 17/60 [1:24:04<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 28%|██▊       | 17/60 [1:24:04<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.752 Val loss 17.273\n",
      "\r 28%|██▊       | 17/60 [1:24:08<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 58 best_val_loss 8.169\n",
      "\r 28%|██▊       | 17/60 [1:24:37<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 28%|██▊       | 17/60 [1:24:37<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.917 Val loss 17.468\n",
      "\r 28%|██▊       | 17/60 [1:24:42<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.241 Val loss 8.885\n",
      "\r 28%|██▊       | 17/60 [1:25:13<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 8.526\n",
      "\r 28%|██▊       | 17/60 [1:25:23<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 28%|██▊       | 17/60 [1:25:23<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.856 Val loss 16.681\n",
      "\r 28%|██▊       | 17/60 [1:25:27<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.437 Val loss 9.228\n",
      "\r 28%|██▊       | 17/60 [1:26:01<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 114 best_val_loss 8.764\n",
      "\r 28%|██▊       | 17/60 [1:26:15<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 28%|██▊       | 17/60 [1:26:15<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.728 Val loss 16.524\n",
      "\r 28%|██▊       | 17/60 [1:26:19<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.327 Val loss 10.307\n",
      "\r 28%|██▊       | 17/60 [1:26:51<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 135 best_val_loss 9.209\n",
      "\r 28%|██▊       | 17/60 [1:27:12<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.65551\n",
      "\n",
      "\r 28%|██▊       | 17/60 [1:27:12<2:42:10, 226.30s/trial, best loss: 7.823103904724121]\r 30%|███       | 18/60 [1:27:12<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.38958642452835024, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.01336732846638039, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.00024436125443789194, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.34645294468948107}\n",
      "\r 30%|███       | 18/60 [1:27:12<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 30%|███       | 18/60 [1:27:12<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.905 Val loss 22.915\n",
      "\r 30%|███       | 18/60 [1:27:16<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.835 Val loss 9.575\n",
      "\r 30%|███       | 18/60 [1:28:24<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 123 best_val_loss 8.933\n",
      "\r 30%|███       | 18/60 [1:29:03<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 30%|███       | 18/60 [1:29:03<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 21.175 Val loss 20.875\n",
      "\r 30%|███       | 18/60 [1:29:07<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.912 Val loss 8.836\n",
      "\r 30%|███       | 18/60 [1:30:19<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 200 Train loss 4.636 Val loss 8.411\n",
      "\r 30%|███       | 18/60 [1:31:26<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 191 best_val_loss 7.980\n",
      "\r 30%|███       | 18/60 [1:31:43<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 30%|███       | 18/60 [1:31:43<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 21.185 Val loss 21.710\n",
      "\r 30%|███       | 18/60 [1:31:47<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.845 Val loss 9.000\n",
      "\r 30%|███       | 18/60 [1:33:02<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 200 Train loss 4.799 Val loss 8.330\n",
      "\r 30%|███       | 18/60 [1:34:21<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 258 best_val_loss 8.061\n",
      "\r 30%|███       | 18/60 [1:35:25<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 30%|███       | 18/60 [1:35:25<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 21.318 Val loss 21.652\n",
      "\r 30%|███       | 18/60 [1:35:29<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 5.736 Val loss 10.153\n",
      "\r 30%|███       | 18/60 [1:36:46<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 200 Train loss 4.508 Val loss 9.212\n",
      "\r 30%|███       | 18/60 [1:37:51<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 217 best_val_loss 8.910\n",
      "\r 30%|███       | 18/60 [1:38:28<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 30%|███       | 18/60 [1:38:28<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 21.324 Val loss 19.173\n",
      "\r 30%|███       | 18/60 [1:38:32<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 6.286 Val loss 9.044\n",
      "\r 30%|███       | 18/60 [1:39:46<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 200 Train loss 4.908 Val loss 8.545\n",
      "\r 30%|███       | 18/60 [1:40:44<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 182 best_val_loss 8.444\n",
      "\r 30%|███       | 18/60 [1:40:54<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 8.46578\n",
      "\n",
      "\r 30%|███       | 18/60 [1:40:54<2:38:58, 227.10s/trial, best loss: 7.823103904724121]\r 32%|███▏      | 19/60 [1:40:54<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.13875771078376015, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.2909615051926761, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0002971196314435137, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 4, 'residual_coef': 0.6640363753544026}\n",
      "\r 32%|███▏      | 19/60 [1:40:54<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 32%|███▏      | 19/60 [1:40:54<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.596 Val loss 21.583\n",
      "\r 32%|███▏      | 19/60 [1:40:58<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.652 Val loss 8.318\n",
      "\r 32%|███▏      | 19/60 [1:41:34<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 74 best_val_loss 8.106\n",
      "\r 32%|███▏      | 19/60 [1:41:36<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 32%|███▏      | 19/60 [1:41:36<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.938 Val loss 20.348\n",
      "\r 32%|███▏      | 19/60 [1:41:40<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.714 Val loss 7.849\n",
      "\r 32%|███▏      | 19/60 [1:42:15<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 80 best_val_loss 7.718\n",
      "\r 32%|███▏      | 19/60 [1:42:18<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 32%|███▏      | 19/60 [1:42:18<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 19.740 Val loss 20.176\n",
      "\r 32%|███▏      | 19/60 [1:42:22<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.750 Val loss 8.092\n",
      "\r 32%|███▏      | 19/60 [1:42:58<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 90 best_val_loss 7.889\n",
      "\r 32%|███▏      | 19/60 [1:43:04<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 32%|███▏      | 19/60 [1:43:04<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.069 Val loss 19.347\n",
      "\r 32%|███▏      | 19/60 [1:43:08<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.833 Val loss 7.834\n",
      "\r 32%|███▏      | 19/60 [1:43:43<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 85 best_val_loss 7.799\n",
      "\r 32%|███▏      | 19/60 [1:43:47<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 32%|███▏      | 19/60 [1:43:47<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.261 Val loss 19.664\n",
      "\r 32%|███▏      | 19/60 [1:43:51<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 3.829 Val loss 8.387\n",
      "\r 32%|███▏      | 19/60 [1:44:20<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 163 best_val_loss 7.930\n",
      "\r 32%|███▏      | 19/60 [1:44:46<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 7.88842\n",
      "\n",
      "\r 32%|███▏      | 19/60 [1:44:46<4:37:17, 405.80s/trial, best loss: 7.823103904724121]\r 33%|███▎      | 20/60 [1:44:46<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.23700826528936805, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.49968044112732213, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00046834158603836795, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.9232041702671046}\n",
      "\r 33%|███▎      | 20/60 [1:44:46<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 33%|███▎      | 20/60 [1:44:46<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.213 Val loss 19.300\n",
      "\r 33%|███▎      | 20/60 [1:44:50<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.138 Val loss 8.258\n",
      "\r 33%|███▎      | 20/60 [1:45:17<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 104 best_val_loss 8.192\n",
      "\r 33%|███▎      | 20/60 [1:45:27<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 33%|███▎      | 20/60 [1:45:27<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.479 Val loss 18.449\n",
      "\r 33%|███▎      | 20/60 [1:45:30<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.159 Val loss 7.813\n",
      "\r 33%|███▎      | 20/60 [1:46:02<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 110 best_val_loss 7.615\n",
      "\r 33%|███▎      | 20/60 [1:46:14<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 33%|███▎      | 20/60 [1:46:14<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.312 Val loss 18.331\n",
      "\r 33%|███▎      | 20/60 [1:46:18<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 67 best_val_loss 7.924\n",
      "\r 33%|███▎      | 20/60 [1:46:49<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 33%|███▎      | 20/60 [1:46:49<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.484 Val loss 17.972\n",
      "\r 33%|███▎      | 20/60 [1:46:53<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.318 Val loss 8.221\n",
      "\r 33%|███▎      | 20/60 [1:47:26<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 125 best_val_loss 7.729\n",
      "\r 33%|███▎      | 20/60 [1:47:42<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 33%|███▎      | 20/60 [1:47:42<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.744 Val loss 17.622\n",
      "\r 33%|███▎      | 20/60 [1:47:46<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 62 best_val_loss 7.891\n",
      "\r 33%|███▎      | 20/60 [1:48:16<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 7.87006\n",
      "\n",
      "\r 33%|███▎      | 20/60 [1:48:16<3:55:42, 353.55s/trial, best loss: 7.823103904724121]\r 35%|███▌      | 21/60 [1:48:16<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.24095898753562642, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.4964132644494209, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00047172853884198317, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.9118445804396729}\n",
      "\r 35%|███▌      | 21/60 [1:48:16<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 1/5\n",
      "\r 35%|███▌      | 21/60 [1:48:16<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.305 Val loss 19.297\n",
      "\r 35%|███▌      | 21/60 [1:48:20<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.162 Val loss 8.305\n",
      "\r 35%|███▌      | 21/60 [1:48:52<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 87 best_val_loss 8.022\n",
      "\r 35%|███▌      | 21/60 [1:48:56<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 2/5\n",
      "\r 35%|███▌      | 21/60 [1:48:56<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.424 Val loss 18.542\n",
      "\r 35%|███▌      | 21/60 [1:49:00<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.230 Val loss 7.720\n",
      "\r 35%|███▌      | 21/60 [1:49:27<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 7.562\n",
      "\r 35%|███▌      | 21/60 [1:49:27<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 3/5\n",
      "\r 35%|███▌      | 21/60 [1:49:27<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.262 Val loss 18.444\n",
      "\r 35%|███▌      | 21/60 [1:49:30<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 59 best_val_loss 7.905\n",
      "\r 35%|███▌      | 21/60 [1:50:00<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 4/5\n",
      "\r 35%|███▌      | 21/60 [1:50:00<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.576 Val loss 17.914\n",
      "\r 35%|███▌      | 21/60 [1:50:04<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 100 Train loss 4.365 Val loss 8.187\n",
      "\r 35%|███▌      | 21/60 [1:50:29<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 200 Train loss 3.375 Val loss 7.750\n",
      "\r 35%|███▌      | 21/60 [1:50:57<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 173 best_val_loss 7.692\n",
      "\r 35%|███▌      | 21/60 [1:50:58<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rFold: 5/5\n",
      "\r 35%|███▌      | 21/60 [1:50:58<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEpoch 0 Train loss 20.764 Val loss 17.794\n",
      "\r 35%|███▌      | 21/60 [1:51:02<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rEarly stopped at epoch 62 best_val_loss 7.845\n",
      "\r 35%|███▌      | 21/60 [1:51:32<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r                                                                                     \rval MSE loss mean: 7.80514\n",
      "\n",
      "\r 35%|███▌      | 21/60 [1:51:32<3:21:51, 310.54s/trial, best loss: 7.823103904724121]\r 37%|███▋      | 22/60 [1:51:32<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.19763996859835462, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.16044144077671246, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0005383894714513061, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.9725140063545397}\n",
      "\r 37%|███▋      | 22/60 [1:51:32<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 37%|███▋      | 22/60 [1:51:32<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.214 Val loss 18.347\n",
      "\r 37%|███▋      | 22/60 [1:51:35<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.794 Val loss 8.372\n",
      "\r 37%|███▋      | 22/60 [1:52:08<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 82 best_val_loss 8.103\n",
      "\r 37%|███▋      | 22/60 [1:52:11<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 37%|███▋      | 22/60 [1:52:11<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.206 Val loss 16.903\n",
      "\r 37%|███▋      | 22/60 [1:52:15<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.842 Val loss 7.854\n",
      "\r 37%|███▋      | 22/60 [1:52:44<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 106 best_val_loss 7.585\n",
      "\r 37%|███▋      | 22/60 [1:52:56<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 37%|███▋      | 22/60 [1:52:56<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.054 Val loss 17.539\n",
      "\r 37%|███▋      | 22/60 [1:53:00<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 62 best_val_loss 7.844\n",
      "\r 37%|███▋      | 22/60 [1:53:28<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 37%|███▋      | 22/60 [1:53:28<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.106 Val loss 16.594\n",
      "\r 37%|███▋      | 22/60 [1:53:32<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.878 Val loss 7.967\n",
      "\r 37%|███▋      | 22/60 [1:54:05<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 124 best_val_loss 7.609\n",
      "\r 37%|███▋      | 22/60 [1:54:20<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 37%|███▋      | 22/60 [1:54:20<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.290 Val loss 16.201\n",
      "\r 37%|███▋      | 22/60 [1:54:25<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.865 Val loss 8.332\n",
      "\r 37%|███▋      | 22/60 [1:54:58<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 8.010\n",
      "\r 37%|███▋      | 22/60 [1:54:58<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.83026\n",
      "\n",
      "\r 37%|███▋      | 22/60 [1:54:58<2:54:49, 276.05s/trial, best loss: 7.805135127476284]\r 38%|███▊      | 23/60 [1:54:58<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.27809357983906086, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.15132924821570165, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0004662190281666685, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8350023179817144}\n",
      "\r 38%|███▊      | 23/60 [1:54:58<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 38%|███▊      | 23/60 [1:54:58<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.720 Val loss 19.213\n",
      "\r 38%|███▊      | 23/60 [1:55:02<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.161 Val loss 8.369\n",
      "\r 38%|███▊      | 23/60 [1:55:37<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 8.115\n",
      "\r 38%|███▊      | 23/60 [1:55:49<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 38%|███▊      | 23/60 [1:55:49<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.968 Val loss 18.363\n",
      "\r 38%|███▊      | 23/60 [1:55:53<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.201 Val loss 7.828\n",
      "\r 38%|███▊      | 23/60 [1:56:27<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 155 best_val_loss 7.513\n",
      "\r 38%|███▊      | 23/60 [1:56:55<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 38%|███▊      | 23/60 [1:56:55<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.736 Val loss 18.045\n",
      "\r 38%|███▊      | 23/60 [1:56:59<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.212 Val loss 8.095\n",
      "\r 38%|███▊      | 23/60 [1:57:31<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 81 best_val_loss 8.000\n",
      "\r 38%|███▊      | 23/60 [1:57:34<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 38%|███▊      | 23/60 [1:57:34<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.738 Val loss 18.074\n",
      "\r 38%|███▊      | 23/60 [1:57:38<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.300 Val loss 8.004\n",
      "\r 38%|███▊      | 23/60 [1:58:09<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 128 best_val_loss 7.824\n",
      "\r 38%|███▊      | 23/60 [1:58:28<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 38%|███▊      | 23/60 [1:58:28<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.020 Val loss 17.400\n",
      "\r 38%|███▊      | 23/60 [1:58:32<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 62 best_val_loss 8.025\n",
      "\r 38%|███▊      | 23/60 [1:59:01<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.89516\n",
      "\n",
      "\r 38%|███▊      | 23/60 [1:59:01<2:37:19, 255.13s/trial, best loss: 7.805135127476284]\r 40%|████      | 24/60 [1:59:01<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.2517474281551901, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.3451776873617905, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0006457904429701912, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8311279820975443}\n",
      "\r 40%|████      | 24/60 [1:59:01<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 40%|████      | 24/60 [1:59:01<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.058 Val loss 21.021\n",
      "\r 40%|████      | 24/60 [1:59:05<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.183 Val loss 8.200\n",
      "\r 40%|████      | 24/60 [1:59:32<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 78 best_val_loss 7.939\n",
      "\r 40%|████      | 24/60 [1:59:34<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 40%|████      | 24/60 [1:59:34<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.326 Val loss 19.515\n",
      "\r 40%|████      | 24/60 [1:59:38<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.187 Val loss 7.537\n",
      "\r 40%|████      | 24/60 [2:00:03<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 123 best_val_loss 7.291\n",
      "\r 40%|████      | 24/60 [2:00:17<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 40%|████      | 24/60 [2:00:17<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.178 Val loss 19.863\n",
      "\r 40%|████      | 24/60 [2:00:21<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 67 best_val_loss 8.127\n",
      "\r 40%|████      | 24/60 [2:00:45<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 40%|████      | 24/60 [2:00:46<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.446 Val loss 18.733\n",
      "\r 40%|████      | 24/60 [2:00:49<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.165 Val loss 7.698\n",
      "\r 40%|████      | 24/60 [2:01:17<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 114 best_val_loss 7.538\n",
      "\r 40%|████      | 24/60 [2:01:28<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 40%|████      | 24/60 [2:01:28<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.523 Val loss 18.331\n",
      "\r 40%|████      | 24/60 [2:01:32<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 41 best_val_loss 8.210\n",
      "\r 40%|████      | 24/60 [2:01:53<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.82095\n",
      "\n",
      "\r 40%|████      | 24/60 [2:01:53<2:30:59, 251.64s/trial, best loss: 7.805135127476284]\r 42%|████▏     | 25/60 [2:01:53<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.2704788906585906, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.4906635578506098, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0005679256275600176, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8901655307307348}\n",
      "\r 42%|████▏     | 25/60 [2:01:53<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 42%|████▏     | 25/60 [2:01:53<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.515 Val loss 19.753\n",
      "\r 42%|████▏     | 25/60 [2:01:56<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.123 Val loss 8.183\n",
      "\r 42%|████▏     | 25/60 [2:02:29<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 149 best_val_loss 8.046\n",
      "\r 42%|████▏     | 25/60 [2:02:52<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 42%|████▏     | 25/60 [2:02:52<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.480 Val loss 18.519\n",
      "\r 42%|████▏     | 25/60 [2:02:56<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 37 best_val_loss 7.626\n",
      "\r 42%|████▏     | 25/60 [2:03:17<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 42%|████▏     | 25/60 [2:03:17<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.520 Val loss 18.750\n",
      "\r 42%|████▏     | 25/60 [2:03:21<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.244 Val loss 8.102\n",
      "\r 42%|████▏     | 25/60 [2:03:54<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 69 best_val_loss 7.926\n",
      "\r 42%|████▏     | 25/60 [2:03:54<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 42%|████▏     | 25/60 [2:03:54<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.680 Val loss 18.023\n",
      "\r 42%|████▏     | 25/60 [2:03:58<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.305 Val loss 8.106\n",
      "\r 42%|████▏     | 25/60 [2:04:28<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 136 best_val_loss 7.744\n",
      "\r 42%|████▏     | 25/60 [2:04:48<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 42%|████▏     | 25/60 [2:04:48<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.923 Val loss 17.485\n",
      "\r 42%|████▏     | 25/60 [2:04:52<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 65 best_val_loss 8.013\n",
      "\r 42%|████▏     | 25/60 [2:05:23<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.87083\n",
      "\n",
      "\r 42%|████▏     | 25/60 [2:05:23<2:12:45, 227.58s/trial, best loss: 7.805135127476284]\r 43%|████▎     | 26/60 [2:05:23<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.1787970032064795, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.35335381456624315, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0004797685295151692, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.9858585128426587}\n",
      "\r 43%|████▎     | 26/60 [2:05:23<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 43%|████▎     | 26/60 [2:05:23<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.634 Val loss 20.716\n",
      "\r 43%|████▎     | 26/60 [2:05:27<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.941 Val loss 8.260\n",
      "\r 43%|████▎     | 26/60 [2:05:52<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 82 best_val_loss 8.086\n",
      "\r 43%|████▎     | 26/60 [2:05:56<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 43%|████▎     | 26/60 [2:05:56<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.826 Val loss 19.110\n",
      "\r 43%|████▎     | 26/60 [2:05:59<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.959 Val loss 7.746\n",
      "\r 43%|████▎     | 26/60 [2:06:25<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 7.482\n",
      "\r 43%|████▎     | 26/60 [2:06:26<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 43%|████▎     | 26/60 [2:06:26<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.757 Val loss 19.437\n",
      "\r 43%|████▎     | 26/60 [2:06:29<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.097 Val loss 8.420\n",
      "\r 43%|████▎     | 26/60 [2:06:54<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 95 best_val_loss 8.258\n",
      "\r 43%|████▎     | 26/60 [2:07:01<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 43%|████▎     | 26/60 [2:07:01<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.031 Val loss 18.327\n",
      "\r 43%|████▎     | 26/60 [2:07:05<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 48 best_val_loss 7.701\n",
      "\r 43%|████▎     | 26/60 [2:07:26<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 43%|████▎     | 26/60 [2:07:26<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.006 Val loss 18.332\n",
      "\r 43%|████▎     | 26/60 [2:07:30<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 41 best_val_loss 8.285\n",
      "\r 43%|████▎     | 26/60 [2:07:48<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.96223\n",
      "\n",
      "\r 43%|████▎     | 26/60 [2:07:48<2:06:02, 222.44s/trial, best loss: 7.805135127476284]\r 45%|████▌     | 27/60 [2:07:48<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.3182544929357469, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.4444777133364833, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.00011218222193173488, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7716917495397368}\n",
      "\r 45%|████▌     | 27/60 [2:07:48<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 45%|████▌     | 27/60 [2:07:48<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 22.051 Val loss 21.787\n",
      "\r 45%|████▌     | 27/60 [2:07:52<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 7.692 Val loss 9.042\n",
      "\r 45%|████▌     | 27/60 [2:08:20<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 156 best_val_loss 8.502\n",
      "\r 45%|████▌     | 27/60 [2:08:44<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 45%|████▌     | 27/60 [2:08:44<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 22.243 Val loss 20.478\n",
      "\r 45%|████▌     | 27/60 [2:08:48<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 7.914 Val loss 8.740\n",
      "\r 45%|████▌     | 27/60 [2:09:15<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 194 best_val_loss 8.005\n",
      "\r 45%|████▌     | 27/60 [2:09:40<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 45%|████▌     | 27/60 [2:09:40<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.971 Val loss 20.632\n",
      "\r 45%|████▌     | 27/60 [2:09:44<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 7.913 Val loss 9.216\n",
      "\r 45%|████▌     | 27/60 [2:10:11<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 190 best_val_loss 8.684\n",
      "\r 45%|████▌     | 27/60 [2:10:37<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 45%|████▌     | 27/60 [2:10:37<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 22.280 Val loss 19.441\n",
      "\r 45%|████▌     | 27/60 [2:10:41<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 7.926 Val loss 8.859\n",
      "\r 45%|████▌     | 27/60 [2:11:10<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 175 best_val_loss 8.283\n",
      "\r 45%|████▌     | 27/60 [2:11:38<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 45%|████▌     | 27/60 [2:11:38<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 22.430 Val loss 19.312\n",
      "\r 45%|████▌     | 27/60 [2:11:41<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 7.891 Val loss 8.985\n",
      "\r 45%|████▌     | 27/60 [2:12:09<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 170 best_val_loss 8.519\n",
      "\r 45%|████▌     | 27/60 [2:12:35<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 8.39880\n",
      "\n",
      "\r 45%|████▌     | 27/60 [2:12:35<1:49:33, 199.19s/trial, best loss: 7.805135127476284]\r 47%|████▋     | 28/60 [2:12:35<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.1372220433588992, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.388885119890081, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.00039341861665285083, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8949592869655503}\n",
      "\r 47%|████▋     | 28/60 [2:12:35<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 47%|████▋     | 28/60 [2:12:35<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.293 Val loss 18.916\n",
      "\r 47%|████▋     | 28/60 [2:12:39<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.668 Val loss 8.306\n",
      "\r 47%|████▋     | 28/60 [2:13:10<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 87 best_val_loss 8.244\n",
      "\r 47%|████▋     | 28/60 [2:13:16<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 47%|████▋     | 28/60 [2:13:16<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.472 Val loss 17.702\n",
      "\r 47%|████▋     | 28/60 [2:13:20<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.667 Val loss 7.666\n",
      "\r 47%|████▋     | 28/60 [2:13:51<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 89 best_val_loss 7.538\n",
      "\r 47%|████▋     | 28/60 [2:13:58<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 47%|████▋     | 28/60 [2:13:58<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.219 Val loss 17.770\n",
      "\r 47%|████▋     | 28/60 [2:14:01<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 56 best_val_loss 7.885\n",
      "\r 47%|████▋     | 28/60 [2:14:29<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 47%|████▋     | 28/60 [2:14:29<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.231 Val loss 17.241\n",
      "\r 47%|████▋     | 28/60 [2:14:33<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.757 Val loss 8.001\n",
      "\r 47%|████▋     | 28/60 [2:15:05<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 128 best_val_loss 7.691\n",
      "\r 47%|████▋     | 28/60 [2:15:23<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 47%|████▋     | 28/60 [2:15:23<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.608 Val loss 17.295\n",
      "\r 47%|████▋     | 28/60 [2:15:27<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 62 best_val_loss 7.988\n",
      "\r 47%|████▋     | 28/60 [2:15:57<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.86903\n",
      "\n",
      "\r 47%|████▋     | 28/60 [2:15:57<2:00:18, 225.58s/trial, best loss: 7.805135127476284]\r 48%|████▊     | 29/60 [2:15:57<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.25700351613643896, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.3347785776715375, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0008610046061324659, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.9830457276734665}\n",
      "\r 48%|████▊     | 29/60 [2:15:57<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 48%|████▊     | 29/60 [2:15:57<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.124 Val loss 18.198\n",
      "\r 48%|████▊     | 29/60 [2:16:01<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.861 Val loss 9.277\n",
      "\r 48%|████▊     | 29/60 [2:16:28<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 74 best_val_loss 9.081\n",
      "\r 48%|████▊     | 29/60 [2:16:29<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 48%|████▊     | 29/60 [2:16:29<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.311 Val loss 16.595\n",
      "\r 48%|████▊     | 29/60 [2:16:33<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 52 best_val_loss 8.316\n",
      "\r 48%|████▊     | 29/60 [2:16:54<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 48%|████▊     | 29/60 [2:16:55<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.141 Val loss 16.674\n",
      "\r 48%|████▊     | 29/60 [2:16:58<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 63 best_val_loss 8.996\n",
      "\r 48%|████▊     | 29/60 [2:17:23<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 48%|████▊     | 29/60 [2:17:23<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.220 Val loss 16.231\n",
      "\r 48%|████▊     | 29/60 [2:17:26<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.853 Val loss 9.163\n",
      "\r 48%|████▊     | 29/60 [2:17:54<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 78 best_val_loss 8.642\n",
      "\r 48%|████▊     | 29/60 [2:17:57<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 48%|████▊     | 29/60 [2:17:57<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 19.425 Val loss 15.602\n",
      "\r 48%|████▊     | 29/60 [2:18:00<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 37 best_val_loss 9.408\n",
      "\r 48%|████▊     | 29/60 [2:18:19<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 8.88867\n",
      "\n",
      "\r 48%|████▊     | 29/60 [2:18:19<1:52:51, 218.44s/trial, best loss: 7.805135127476284]\r 50%|█████     | 30/60 [2:18:19<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.005880912238658498, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.4744330661854928, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0005248957966273308, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.8178243276867547}\n",
      "\r 50%|█████     | 30/60 [2:18:19<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 50%|█████     | 30/60 [2:18:19<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 18.526 Val loss 18.408\n",
      "\r 50%|█████     | 30/60 [2:18:22<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.010 Val loss 8.192\n",
      "\r 50%|█████     | 30/60 [2:18:54<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 82 best_val_loss 8.070\n",
      "\r 50%|█████     | 30/60 [2:18:58<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 50%|█████     | 30/60 [2:18:58<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 18.994 Val loss 16.866\n",
      "\r 50%|█████     | 30/60 [2:19:01<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.021 Val loss 7.646\n",
      "\r 50%|█████     | 30/60 [2:19:35<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 88 best_val_loss 7.451\n",
      "\r 50%|█████     | 30/60 [2:19:41<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 50%|█████     | 30/60 [2:19:41<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 18.690 Val loss 17.188\n",
      "\r 50%|█████     | 30/60 [2:19:45<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 39 best_val_loss 8.014\n",
      "\r 50%|█████     | 30/60 [2:20:06<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 50%|█████     | 30/60 [2:20:06<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 18.682 Val loss 16.745\n",
      "\r 50%|█████     | 30/60 [2:20:10<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 3.044 Val loss 7.843\n",
      "\r 50%|█████     | 30/60 [2:20:41<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 7.688\n",
      "\r 50%|█████     | 30/60 [2:20:42<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 50%|█████     | 30/60 [2:20:42<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 18.976 Val loss 16.841\n",
      "\r 50%|█████     | 30/60 [2:20:46<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 60 best_val_loss 7.893\n",
      "\r 50%|█████     | 30/60 [2:21:13<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.82310\n",
      "\n",
      "\r 50%|█████     | 30/60 [2:21:13<1:37:39, 195.32s/trial, best loss: 7.805135127476284]\r 52%|█████▏    | 31/60 [2:21:13<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.3430044874773345, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.40113001513709, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0006203704073657864, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6064153783247896}\n",
      "\r 52%|█████▏    | 31/60 [2:21:13<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 52%|█████▏    | 31/60 [2:21:13<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.204 Val loss 22.018\n",
      "\r 52%|█████▏    | 31/60 [2:21:16<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.759 Val loss 8.086\n",
      "\r 52%|█████▏    | 31/60 [2:21:45<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 160 best_val_loss 7.914\n",
      "\r 52%|█████▏    | 31/60 [2:22:09<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 52%|█████▏    | 31/60 [2:22:09<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.442 Val loss 20.893\n",
      "\r 52%|█████▏    | 31/60 [2:22:13<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.743 Val loss 7.812\n",
      "\r 52%|█████▏    | 31/60 [2:22:38<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 194 best_val_loss 7.329\n",
      "\r 52%|█████▏    | 31/60 [2:23:05<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 52%|█████▏    | 31/60 [2:23:05<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.258 Val loss 21.187\n",
      "\r 52%|█████▏    | 31/60 [2:23:08<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.959 Val loss 8.391\n",
      "\r 52%|█████▏    | 31/60 [2:23:37<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 124 best_val_loss 8.076\n",
      "\r 52%|█████▏    | 31/60 [2:23:52<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 52%|█████▏    | 31/60 [2:23:52<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.514 Val loss 19.891\n",
      "\r 52%|█████▏    | 31/60 [2:23:55<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.771 Val loss 7.840\n",
      "\r 52%|█████▏    | 31/60 [2:24:23<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 118 best_val_loss 7.606\n",
      "\r 52%|█████▏    | 31/60 [2:24:35<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 52%|█████▏    | 31/60 [2:24:35<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.534 Val loss 19.893\n",
      "\r 52%|█████▏    | 31/60 [2:24:39<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.879 Val loss 8.229\n",
      "\r 52%|█████▏    | 31/60 [2:25:06<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 127 best_val_loss 8.113\n",
      "\r 52%|█████▏    | 31/60 [2:25:21<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.80765\n",
      "\n",
      "\r 52%|█████▏    | 31/60 [2:25:21<1:31:20, 188.99s/trial, best loss: 7.805135127476284]\r 53%|█████▎    | 32/60 [2:25:21<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.485161968303912, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.40888692804650945, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (2048, 256), 'lr': 0.0007323040358104406, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.4377451687041545}\n",
      "\r 53%|█████▎    | 32/60 [2:25:21<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 53%|█████▎    | 32/60 [2:25:21<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.457 Val loss 23.302\n",
      "\r 53%|█████▎    | 32/60 [2:25:25<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.598 Val loss 8.538\n",
      "\r 53%|█████▎    | 32/60 [2:26:02<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 168 best_val_loss 8.160\n",
      "\r 53%|█████▎    | 32/60 [2:26:44<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 53%|█████▎    | 32/60 [2:26:44<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.624 Val loss 22.438\n",
      "\r 53%|█████▎    | 32/60 [2:26:48<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.726 Val loss 7.983\n",
      "\r 53%|█████▎    | 32/60 [2:27:24<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 132 best_val_loss 7.513\n",
      "\r 53%|█████▎    | 32/60 [2:27:50<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 53%|█████▎    | 32/60 [2:27:50<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.729 Val loss 22.814\n",
      "\r 53%|█████▎    | 32/60 [2:27:54<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.613 Val loss 8.425\n",
      "\r 53%|█████▎    | 32/60 [2:28:29<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 166 best_val_loss 7.927\n",
      "\r 53%|█████▎    | 32/60 [2:29:06<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 53%|█████▎    | 32/60 [2:29:06<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.815 Val loss 21.827\n",
      "\r 53%|█████▎    | 32/60 [2:29:10<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.452 Val loss 8.156\n",
      "\r 53%|█████▎    | 32/60 [2:29:51<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 177 best_val_loss 7.914\n",
      "\r 53%|█████▎    | 32/60 [2:30:30<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 53%|█████▎    | 32/60 [2:30:30<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.786 Val loss 21.554\n",
      "\r 53%|█████▎    | 32/60 [2:30:33<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.664 Val loss 8.169\n",
      "\r 53%|█████▎    | 32/60 [2:31:17<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rStopped at epoch 189 best_val_loss 7.899\n",
      "\r 53%|█████▎    | 32/60 [2:31:59<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.88274\n",
      "\n",
      "\r 53%|█████▎    | 32/60 [2:31:59<1:36:31, 206.83s/trial, best loss: 7.805135127476284]\r 55%|█████▌    | 33/60 [2:31:59<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.3363092269957189, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.4623686568938341, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000601945136161426, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6017580218911323}\n",
      "\r 55%|█████▌    | 33/60 [2:31:59<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 55%|█████▌    | 33/60 [2:31:59<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.010 Val loss 23.666\n",
      "\r 55%|█████▌    | 33/60 [2:32:02<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.567 Val loss 11.419\n",
      "\r 55%|█████▌    | 33/60 [2:32:32<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 107 best_val_loss 10.576\n",
      "\r 55%|█████▌    | 33/60 [2:32:44<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 55%|█████▌    | 33/60 [2:32:44<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.266 Val loss 19.801\n",
      "\r 55%|█████▌    | 33/60 [2:32:48<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.641 Val loss 10.633\n",
      "\r 55%|█████▌    | 33/60 [2:33:22<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 93 best_val_loss 9.971\n",
      "\r 55%|█████▌    | 33/60 [2:33:29<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 55%|█████▌    | 33/60 [2:33:29<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.333 Val loss 23.793\n",
      "\r 55%|█████▌    | 33/60 [2:33:33<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.584 Val loss 11.429\n",
      "\r 55%|█████▌    | 33/60 [2:34:06<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 129 best_val_loss 10.867\n",
      "\r 55%|█████▌    | 33/60 [2:34:24<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 55%|█████▌    | 33/60 [2:34:24<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.265 Val loss 19.363\n",
      "\r 55%|█████▌    | 33/60 [2:34:28<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.529 Val loss 11.315\n",
      "\r 55%|█████▌    | 33/60 [2:35:00<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 10.948\n",
      "\r 55%|█████▌    | 33/60 [2:35:12<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 55%|█████▌    | 33/60 [2:35:12<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.203 Val loss 20.797\n",
      "\r 55%|█████▌    | 33/60 [2:35:16<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.848 Val loss 11.500\n",
      "\r 55%|█████▌    | 33/60 [2:35:47<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 75 best_val_loss 11.184\n",
      "\r 55%|█████▌    | 33/60 [2:35:49<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 10.70903\n",
      "\n",
      "\r 55%|█████▌    | 33/60 [2:35:49<1:58:50, 264.08s/trial, best loss: 7.805135127476284]\r 57%|█████▋    | 34/60 [2:35:49<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.3056726732718394, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.31659575804402923, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0006795261076224608, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.27682313803708647}\n",
      "\r 57%|█████▋    | 34/60 [2:35:49<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 57%|█████▋    | 34/60 [2:35:49<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.117 Val loss 19.930\n",
      "\r 57%|█████▋    | 34/60 [2:35:53<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.439 Val loss 8.302\n",
      "\r 57%|█████▋    | 34/60 [2:36:42<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 8.127\n",
      "\r 57%|█████▋    | 34/60 [2:37:03<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 57%|█████▋    | 34/60 [2:37:03<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.306 Val loss 18.159\n",
      "\r 57%|█████▋    | 34/60 [2:37:07<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.477 Val loss 7.722\n",
      "\r 57%|█████▋    | 34/60 [2:37:54<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 7.672\n",
      "\r 57%|█████▋    | 34/60 [2:37:55<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 57%|█████▋    | 34/60 [2:37:55<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.198 Val loss 18.224\n",
      "\r 57%|█████▋    | 34/60 [2:37:59<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.607 Val loss 7.974\n",
      "\r 57%|█████▋    | 34/60 [2:38:55<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 200 Train loss 3.769 Val loss 7.744\n",
      "\r 57%|█████▋    | 34/60 [2:39:40<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 203 best_val_loss 7.674\n",
      "\r 57%|█████▋    | 34/60 [2:39:54<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 57%|█████▋    | 34/60 [2:39:54<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.458 Val loss 17.816\n",
      "\r 57%|█████▋    | 34/60 [2:39:58<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.428 Val loss 8.004\n",
      "\r 57%|█████▋    | 34/60 [2:40:45<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 116 best_val_loss 7.874\n",
      "\r 57%|█████▋    | 34/60 [2:41:13<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 57%|█████▋    | 34/60 [2:41:13<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.224 Val loss 17.749\n",
      "\r 57%|█████▋    | 34/60 [2:41:17<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 5.053 Val loss 7.923\n",
      "\r 57%|█████▋    | 34/60 [2:42:09<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 87 best_val_loss 7.841\n",
      "\r 57%|█████▋    | 34/60 [2:42:17<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.83751\n",
      "\n",
      "\r 57%|█████▋    | 34/60 [2:42:17<1:50:03, 254.00s/trial, best loss: 7.805135127476284]\r 58%|█████▊    | 35/60 [2:42:17<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.3575768798250808, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.37760589870521244, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 200, 'hidden_dim_list': (1024, 256), 'lr': 0.00042413419467257434, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7226261617689059}\n",
      "\r 58%|█████▊    | 35/60 [2:42:17<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 58%|█████▊    | 35/60 [2:42:17<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.666 Val loss 16.999\n",
      "\r 58%|█████▊    | 35/60 [2:42:21<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.524 Val loss 11.155\n",
      "\r 58%|█████▊    | 35/60 [2:43:00<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 99 best_val_loss 10.708\n",
      "\r 58%|█████▊    | 35/60 [2:43:12<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 58%|█████▊    | 35/60 [2:43:12<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.034 Val loss 17.548\n",
      "\r 58%|█████▊    | 35/60 [2:43:16<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.653 Val loss 9.572\n",
      "\r 58%|█████▊    | 35/60 [2:43:59<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 148 best_val_loss 9.178\n",
      "\r 58%|█████▊    | 35/60 [2:44:35<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 58%|█████▊    | 35/60 [2:44:35<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.937 Val loss 16.777\n",
      "\r 58%|█████▊    | 35/60 [2:44:39<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.629 Val loss 10.110\n",
      "\r 58%|█████▊    | 35/60 [2:45:22<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 124 best_val_loss 9.903\n",
      "\r 58%|█████▊    | 35/60 [2:45:45<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 58%|█████▊    | 35/60 [2:45:45<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.003 Val loss 16.148\n",
      "\r 58%|█████▊    | 35/60 [2:45:48<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.562 Val loss 10.930\n",
      "\r 58%|█████▊    | 35/60 [2:46:33<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 113 best_val_loss 10.325\n",
      "\r 58%|█████▊    | 35/60 [2:46:54<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 58%|█████▊    | 35/60 [2:46:54<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.152 Val loss 16.514\n",
      "\r 58%|█████▊    | 35/60 [2:46:57<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.598 Val loss 10.579\n",
      "\r 58%|█████▊    | 35/60 [2:47:45<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 10.405\n",
      "\r 58%|█████▊    | 35/60 [2:47:47<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 10.10386\n",
      "\n",
      "\r 58%|█████▊    | 35/60 [2:47:47<2:02:31, 294.07s/trial, best loss: 7.805135127476284]\r 60%|██████    | 36/60 [2:47:47<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.20745985902210828, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.49946379793495405, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0008319540008563523, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6121588961417437}\n",
      "\r 60%|██████    | 36/60 [2:47:47<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 1/5\n",
      "\r 60%|██████    | 36/60 [2:47:47<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.577 Val loss 21.093\n",
      "\r 60%|██████    | 36/60 [2:47:50<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.116 Val loss 8.372\n",
      "\r 60%|██████    | 36/60 [2:48:16<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 107 best_val_loss 8.035\n",
      "\r 60%|██████    | 36/60 [2:48:26<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 2/5\n",
      "\r 60%|██████    | 36/60 [2:48:26<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.618 Val loss 20.065\n",
      "\r 60%|██████    | 36/60 [2:48:30<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.190 Val loss 7.476\n",
      "\r 60%|██████    | 36/60 [2:48:57<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 7.241\n",
      "\r 60%|██████    | 36/60 [2:48:57<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 3/5\n",
      "\r 60%|██████    | 36/60 [2:48:57<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.573 Val loss 20.230\n",
      "\r 60%|██████    | 36/60 [2:49:01<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 50 best_val_loss 8.206\n",
      "\r 60%|██████    | 36/60 [2:49:24<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 4/5\n",
      "\r 60%|██████    | 36/60 [2:49:24<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 21.110 Val loss 19.336\n",
      "\r 60%|██████    | 36/60 [2:49:28<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.208 Val loss 7.773\n",
      "\r 60%|██████    | 36/60 [2:49:57<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 111 best_val_loss 7.409\n",
      "\r 60%|██████    | 36/60 [2:50:07<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rFold: 5/5\n",
      "\r 60%|██████    | 36/60 [2:50:07<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 0 Train loss 20.830 Val loss 18.436\n",
      "\r 60%|██████    | 36/60 [2:50:11<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEpoch 100 Train loss 4.245 Val loss 8.452\n",
      "\r 60%|██████    | 36/60 [2:50:37<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rEarly stopped at epoch 87 best_val_loss 8.072\n",
      "\r 60%|██████    | 36/60 [2:50:42<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r                                                                                     \rval MSE loss mean: 7.79265\n",
      "\n",
      "\r 60%|██████    | 36/60 [2:50:42<2:01:54, 304.75s/trial, best loss: 7.805135127476284]\r 62%|██████▏   | 37/60 [2:50:42<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.11917459543535805, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.493975609734064, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0008896391190650855, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.0513834967667654}\n",
      "\r 62%|██████▏   | 37/60 [2:50:42<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 62%|██████▏   | 37/60 [2:50:42<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.347 Val loss 22.446\n",
      "\r 62%|██████▏   | 37/60 [2:50:46<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.521 Val loss 8.173\n",
      "\r 62%|██████▏   | 37/60 [2:51:17<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 88 best_val_loss 7.998\n",
      "\r 62%|██████▏   | 37/60 [2:51:24<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 62%|██████▏   | 37/60 [2:51:24<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.548 Val loss 21.672\n",
      "\r 62%|██████▏   | 37/60 [2:51:28<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.656 Val loss 8.175\n",
      "\r 62%|██████▏   | 37/60 [2:51:59<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 136 best_val_loss 7.676\n",
      "\r 62%|██████▏   | 37/60 [2:52:21<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 62%|██████▏   | 37/60 [2:52:21<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.706 Val loss 21.684\n",
      "\r 62%|██████▏   | 37/60 [2:52:24<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.547 Val loss 7.947\n",
      "\r 62%|██████▏   | 37/60 [2:52:55<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 132 best_val_loss 7.679\n",
      "\r 62%|██████▏   | 37/60 [2:53:14<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 62%|██████▏   | 37/60 [2:53:14<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.980 Val loss 21.481\n",
      "\r 62%|██████▏   | 37/60 [2:53:17<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.618 Val loss 8.543\n",
      "\r 62%|██████▏   | 37/60 [2:53:50<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 200 Train loss 3.752 Val loss 8.288\n",
      "\r 62%|██████▏   | 37/60 [2:54:22<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 181 best_val_loss 8.102\n",
      "\r 62%|██████▏   | 37/60 [2:54:26<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 62%|██████▏   | 37/60 [2:54:26<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.850 Val loss 21.150\n",
      "\r 62%|██████▏   | 37/60 [2:54:29<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.684 Val loss 8.156\n",
      "\r 62%|██████▏   | 37/60 [2:54:59<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 159 best_val_loss 7.822\n",
      "\r 62%|██████▏   | 37/60 [2:55:27<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 7.85544\n",
      "\n",
      "\r 62%|██████▏   | 37/60 [2:55:27<1:41:53, 265.82s/trial, best loss: 7.792647361755371]\r 63%|██████▎   | 38/60 [2:55:27<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.2038002462163927, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.2681483229153676, 'encoder_norm': 'layer_norm', 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0008099819922443543, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7444903133615622}\n",
      "\r 63%|██████▎   | 38/60 [2:55:27<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 63%|██████▎   | 38/60 [2:55:27<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.908 Val loss 14.927\n",
      "\r 63%|██████▎   | 38/60 [2:55:31<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 67 best_val_loss 9.245\n",
      "\r 63%|██████▎   | 38/60 [2:56:41<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 63%|██████▎   | 38/60 [2:56:41<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.183 Val loss 13.975\n",
      "\r 63%|██████▎   | 38/60 [2:56:45<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 44 best_val_loss 8.602\n",
      "\r 63%|██████▎   | 38/60 [2:57:40<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 63%|██████▎   | 38/60 [2:57:40<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.060 Val loss 16.110\n",
      "\r 63%|██████▎   | 38/60 [2:57:44<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 39 best_val_loss 8.828\n",
      "\r 63%|██████▎   | 38/60 [2:58:32<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 63%|██████▎   | 38/60 [2:58:32<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.596 Val loss 16.014\n",
      "\r 63%|██████▎   | 38/60 [2:58:36<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 58 best_val_loss 9.093\n",
      "\r 63%|██████▎   | 38/60 [2:59:37<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 63%|██████▎   | 38/60 [2:59:38<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.151 Val loss 13.810\n",
      "\r 63%|██████▎   | 38/60 [2:59:42<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 48 best_val_loss 9.027\n",
      "\r 63%|██████▎   | 38/60 [3:00:43<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 8.95881\n",
      "\n",
      "\r 63%|██████▎   | 38/60 [3:00:43<1:39:37, 271.71s/trial, best loss: 7.792647361755371]\r 65%|██████▌   | 39/60 [3:00:43<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.16235328332334686, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.46536683617723834, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.0007251374048226266, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.6544357393663699}\n",
      "\r 65%|██████▌   | 39/60 [3:00:43<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 65%|██████▌   | 39/60 [3:00:43<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.595 Val loss 19.135\n",
      "\r 65%|██████▌   | 39/60 [3:00:46<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.818 Val loss 8.211\n",
      "\r 65%|██████▌   | 39/60 [3:01:14<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 87 best_val_loss 7.975\n",
      "\r 65%|██████▌   | 39/60 [3:01:20<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 65%|██████▌   | 39/60 [3:01:20<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.858 Val loss 17.569\n",
      "\r 65%|██████▌   | 39/60 [3:01:23<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 41 best_val_loss 7.736\n",
      "\r 65%|██████▌   | 39/60 [3:01:45<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 65%|██████▌   | 39/60 [3:01:45<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.731 Val loss 18.102\n",
      "\r 65%|██████▌   | 39/60 [3:01:49<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.849 Val loss 8.016\n",
      "\r 65%|██████▌   | 39/60 [3:02:19<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 69 best_val_loss 7.753\n",
      "\r 65%|██████▌   | 39/60 [3:02:19<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 65%|██████▌   | 39/60 [3:02:19<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.997 Val loss 17.917\n",
      "\r 65%|██████▌   | 39/60 [3:02:23<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.873 Val loss 7.828\n",
      "\r 65%|██████▌   | 39/60 [3:02:54<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 7.766\n",
      "\r 65%|██████▌   | 39/60 [3:02:55<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 65%|██████▌   | 39/60 [3:02:55<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 20.194 Val loss 17.086\n",
      "\r 65%|██████▌   | 39/60 [3:02:59<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.880 Val loss 8.313\n",
      "\r 65%|██████▌   | 39/60 [3:03:28<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 7.942\n",
      "\r 65%|██████▌   | 39/60 [3:03:29<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 7.83430\n",
      "\n",
      "\r 65%|██████▌   | 39/60 [3:03:29<1:39:44, 284.95s/trial, best loss: 7.792647361755371]\r 67%|██████▋   | 40/60 [3:03:29<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 1024, 'drop_ratio': 0.28764982835453157, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.42805000885623934, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.00021114324868589865, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.26599785429435535}\n",
      "\r 67%|██████▋   | 40/60 [3:03:29<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 67%|██████▋   | 40/60 [3:03:29<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.964 Val loss 22.692\n",
      "\r 67%|██████▋   | 40/60 [3:03:33<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.728 Val loss 8.630\n",
      "\r 67%|██████▋   | 40/60 [3:03:58<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 200 Train loss 4.585 Val loss 8.108\n",
      "\r 67%|██████▋   | 40/60 [3:04:25<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 204 best_val_loss 8.054\n",
      "\r 67%|██████▋   | 40/60 [3:04:34<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 67%|██████▋   | 40/60 [3:04:34<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 22.132 Val loss 21.197\n",
      "\r 67%|██████▋   | 40/60 [3:04:37<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.862 Val loss 8.149\n",
      "\r 67%|██████▋   | 40/60 [3:05:05<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 158 best_val_loss 7.479\n",
      "\r 67%|██████▋   | 40/60 [3:05:28<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 67%|██████▋   | 40/60 [3:05:28<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 21.860 Val loss 21.452\n",
      "\r 67%|██████▋   | 40/60 [3:05:32<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.930 Val loss 8.565\n",
      "\r 67%|██████▋   | 40/60 [3:05:58<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 83 best_val_loss 8.321\n",
      "\r 67%|██████▋   | 40/60 [3:06:02<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 67%|██████▋   | 40/60 [3:06:02<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 22.132 Val loss 20.224\n",
      "\r 67%|██████▋   | 40/60 [3:06:06<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.779 Val loss 8.145\n",
      "\r 67%|██████▋   | 40/60 [3:06:31<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 200 Train loss 4.730 Val loss 7.831\n",
      "\r 67%|██████▋   | 40/60 [3:06:59<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 195 best_val_loss 7.707\n",
      "\r 67%|██████▋   | 40/60 [3:07:05<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 67%|██████▋   | 40/60 [3:07:05<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 22.240 Val loss 20.076\n",
      "\r 67%|██████▋   | 40/60 [3:07:09<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.829 Val loss 8.454\n",
      "\r 67%|██████▋   | 40/60 [3:07:36<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 200 Train loss 4.789 Val loss 8.228\n",
      "\r 67%|██████▋   | 40/60 [3:08:03<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 179 best_val_loss 8.146\n",
      "\r 67%|██████▋   | 40/60 [3:08:05<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 7.94129\n",
      "\n",
      "\r 67%|██████▋   | 40/60 [3:08:05<1:23:03, 249.19s/trial, best loss: 7.792647361755371]\r 68%|██████▊   | 41/60 [3:08:05<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.0927948208286934, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.36851597359782656, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0008341087560098162, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.7780606175102693}\n",
      "\r 68%|██████▊   | 41/60 [3:08:05<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 68%|██████▊   | 41/60 [3:08:05<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.115 Val loss 18.600\n",
      "\r 68%|██████▊   | 41/60 [3:08:09<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.773 Val loss 8.427\n",
      "\r 68%|██████▊   | 41/60 [3:09:18<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 94 best_val_loss 8.135\n",
      "\r 68%|██████▊   | 41/60 [3:09:36<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 68%|██████▊   | 41/60 [3:09:36<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.430 Val loss 17.742\n",
      "\r 68%|██████▊   | 41/60 [3:09:40<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.858 Val loss 7.734\n",
      "\r 68%|██████▊   | 41/60 [3:10:54<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 134 best_val_loss 7.593\n",
      "\r 68%|██████▊   | 41/60 [3:11:33<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 68%|██████▊   | 41/60 [3:11:33<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.067 Val loss 18.119\n",
      "\r 68%|██████▊   | 41/60 [3:11:37<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 37 best_val_loss 7.898\n",
      "\r 68%|██████▊   | 41/60 [3:12:24<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 68%|██████▊   | 41/60 [3:12:24<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.052 Val loss 17.041\n",
      "\r 68%|██████▊   | 41/60 [3:12:28<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.863 Val loss 8.390\n",
      "\r 68%|██████▊   | 41/60 [3:13:42<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 88 best_val_loss 7.878\n",
      "\r 68%|██████▊   | 41/60 [3:13:53<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 68%|██████▊   | 41/60 [3:13:53<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.052 Val loss 16.210\n",
      "\r 68%|██████▊   | 41/60 [3:13:57<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 66 best_val_loss 7.861\n",
      "\r 68%|██████▊   | 41/60 [3:15:05<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 7.87295\n",
      "\n",
      "\r 68%|██████▊   | 41/60 [3:15:05<1:21:31, 257.44s/trial, best loss: 7.792647361755371]\r 70%|███████   | 42/60 [3:15:05<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.21619653421432172, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.31627500315666224, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000767674934666746, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.5693232108079871}\n",
      "\r 70%|███████   | 42/60 [3:15:05<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 70%|███████   | 42/60 [3:15:05<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.459 Val loss 19.271\n",
      "\r 70%|███████   | 42/60 [3:15:09<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 41 best_val_loss 9.491\n",
      "\r 70%|███████   | 42/60 [3:15:32<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 70%|███████   | 42/60 [3:15:32<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.583 Val loss 19.263\n",
      "\r 70%|███████   | 42/60 [3:15:36<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 60 best_val_loss 9.297\n",
      "\r 70%|███████   | 42/60 [3:16:03<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 70%|███████   | 42/60 [3:16:03<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.882 Val loss 18.437\n",
      "\r 70%|███████   | 42/60 [3:16:07<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 54 best_val_loss 9.162\n",
      "\r 70%|███████   | 42/60 [3:16:32<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 70%|███████   | 42/60 [3:16:32<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.735 Val loss 19.456\n",
      "\r 70%|███████   | 42/60 [3:16:36<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 66 best_val_loss 10.176\n",
      "\r 70%|███████   | 42/60 [3:17:07<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 70%|███████   | 42/60 [3:17:07<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.092 Val loss 19.644\n",
      "\r 70%|███████   | 42/60 [3:17:10<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 5.570 Val loss 10.204\n",
      "\r 70%|███████   | 42/60 [3:17:40<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 90 best_val_loss 9.912\n",
      "\r 70%|███████   | 42/60 [3:17:46<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 9.60762\n",
      "\n",
      "\r 70%|███████   | 42/60 [3:17:46<1:31:51, 306.19s/trial, best loss: 7.792647361755371]\r 72%|███████▏  | 43/60 [3:17:46<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.04286289490104503, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.41210461401562304, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0009307299781228574, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.9423496946460528}\n",
      "\r 72%|███████▏  | 43/60 [3:17:46<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 72%|███████▏  | 43/60 [3:17:46<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.675 Val loss 18.873\n",
      "\r 72%|███████▏  | 43/60 [3:17:49<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 27 best_val_loss 8.329\n",
      "\r 72%|███████▏  | 43/60 [3:18:17<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 72%|███████▏  | 43/60 [3:18:17<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.947 Val loss 17.580\n",
      "\r 72%|███████▏  | 43/60 [3:18:20<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.204 Val loss 8.321\n",
      "\r 72%|███████▏  | 43/60 [3:19:03<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 86 best_val_loss 7.687\n",
      "\r 72%|███████▏  | 43/60 [3:19:10<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 72%|███████▏  | 43/60 [3:19:10<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.853 Val loss 18.166\n",
      "\r 72%|███████▏  | 43/60 [3:19:14<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 57 best_val_loss 8.085\n",
      "\r 72%|███████▏  | 43/60 [3:19:47<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 72%|███████▏  | 43/60 [3:19:47<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.912 Val loss 17.548\n",
      "\r 72%|███████▏  | 43/60 [3:19:51<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.189 Val loss 7.907\n",
      "\r 72%|███████▏  | 43/60 [3:20:38<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 104 best_val_loss 7.676\n",
      "\r 72%|███████▏  | 43/60 [3:20:53<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 72%|███████▏  | 43/60 [3:20:53<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 19.131 Val loss 16.235\n",
      "\r 72%|███████▏  | 43/60 [3:20:57<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 57 best_val_loss 8.048\n",
      "\r 72%|███████▏  | 43/60 [3:21:40<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 7.96491\n",
      "\n",
      "\r 72%|███████▏  | 43/60 [3:21:40<1:14:22, 262.49s/trial, best loss: 7.792647361755371]\r 73%|███████▎  | 44/60 [3:21:40<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.18377012110763277, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.19794988160761878, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (2048, 256), 'lr': 0.000999726377495053, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.007566848813591764}\n",
      "\r 73%|███████▎  | 44/60 [3:21:40<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 73%|███████▎  | 44/60 [3:21:40<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.349 Val loss 15.525\n",
      "\r 73%|███████▎  | 44/60 [3:21:44<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 3.967 Val loss 8.587\n",
      "\r 73%|███████▎  | 44/60 [3:22:11<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 82 best_val_loss 8.142\n",
      "\r 73%|███████▎  | 44/60 [3:22:14<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 73%|███████▎  | 44/60 [3:22:14<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.420 Val loss 15.045\n",
      "\r 73%|███████▎  | 44/60 [3:22:18<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 35 best_val_loss 7.740\n",
      "\r 73%|███████▎  | 44/60 [3:22:35<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 73%|███████▎  | 44/60 [3:22:35<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.323 Val loss 15.084\n",
      "\r 73%|███████▎  | 44/60 [3:22:38<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 25 best_val_loss 8.374\n",
      "\r 73%|███████▎  | 44/60 [3:22:53<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 73%|███████▎  | 44/60 [3:22:53<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.193 Val loss 14.123\n",
      "\r 73%|███████▎  | 44/60 [3:22:57<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.097 Val loss 8.370\n",
      "\r 73%|███████▎  | 44/60 [3:23:26<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 118 best_val_loss 7.968\n",
      "\r 73%|███████▎  | 44/60 [3:23:39<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 73%|███████▎  | 44/60 [3:23:39<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 17.228 Val loss 15.260\n",
      "\r 73%|███████▎  | 44/60 [3:23:43<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.093 Val loss 8.552\n",
      "\r 73%|███████▎  | 44/60 [3:24:08<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 85 best_val_loss 8.320\n",
      "\r 73%|███████▎  | 44/60 [3:24:12<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 8.10885\n",
      "\n",
      "\r 73%|███████▎  | 44/60 [3:24:12<1:07:43, 253.97s/trial, best loss: 7.792647361755371]\r 75%|███████▌  | 45/60 [3:24:12<55:52, 223.49s/trial, best loss: 7.792647361755371]  \r                                                                                   \r{'act_fun': 'gelu', 'batch_size': 2048, 'drop_ratio': 0.15844468048274143, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.48023863716553095, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.000318974913644539, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.4670826144907074}\n",
      "\r 75%|███████▌  | 45/60 [3:24:12<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 1/5\n",
      "\r 75%|███████▌  | 45/60 [3:24:12<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.660 Val loss 22.077\n",
      "\r 75%|███████▌  | 45/60 [3:24:16<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 6.370 Val loss 8.782\n",
      "\r 75%|███████▌  | 45/60 [3:24:48<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 200 Train loss 5.136 Val loss 8.115\n",
      "\r 75%|███████▌  | 45/60 [3:25:19<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 267 best_val_loss 8.092\n",
      "\r 75%|███████▌  | 45/60 [3:25:49<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 2/5\n",
      "\r 75%|███████▌  | 45/60 [3:25:49<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.693 Val loss 21.437\n",
      "\r 75%|███████▌  | 45/60 [3:25:53<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 6.702 Val loss 8.211\n",
      "\r 75%|███████▌  | 45/60 [3:26:24<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 200 Train loss 5.401 Val loss 7.795\n",
      "\r 75%|███████▌  | 45/60 [3:26:56<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 180 best_val_loss 7.761\n",
      "\r 75%|███████▌  | 45/60 [3:26:58<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 3/5\n",
      "\r 75%|███████▌  | 45/60 [3:26:58<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 22.158 Val loss 21.394\n",
      "\r 75%|███████▌  | 45/60 [3:27:02<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 6.737 Val loss 8.255\n",
      "\r 75%|███████▌  | 45/60 [3:27:32<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 200 Train loss 5.220 Val loss 7.895\n",
      "\r 75%|███████▌  | 45/60 [3:28:02<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 261 best_val_loss 7.684\n",
      "\r 75%|███████▌  | 45/60 [3:28:30<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 4/5\n",
      "\r 75%|███████▌  | 45/60 [3:28:30<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.969 Val loss 21.147\n",
      "\r 75%|███████▌  | 45/60 [3:28:34<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 6.684 Val loss 8.991\n",
      "\r 75%|███████▌  | 45/60 [3:29:09<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 200 Train loss 5.447 Val loss 8.335\n",
      "\r 75%|███████▌  | 45/60 [3:29:42<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 217 best_val_loss 8.206\n",
      "\r 75%|███████▌  | 45/60 [3:29:57<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 5/5\n",
      "\r 75%|███████▌  | 45/60 [3:29:57<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 22.170 Val loss 20.930\n",
      "\r 75%|███████▌  | 45/60 [3:30:01<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 6.772 Val loss 8.563\n",
      "\r 75%|███████▌  | 45/60 [3:30:36<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 167 best_val_loss 8.090\n",
      "\r 75%|███████▌  | 45/60 [3:31:09<55:52, 223.49s/trial, best loss: 7.792647361755371]\r                                                                                   \rval MSE loss mean: 7.96670\n",
      "\n",
      "\r 75%|███████▌  | 45/60 [3:31:09<55:52, 223.49s/trial, best loss: 7.792647361755371]\r 77%|███████▋  | 46/60 [3:31:09<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.10046765815159356, 'encoder_dim_list': ((8, 32), (1, 64)), 'encoder_drop_ratio': 0.4464681139074377, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.00011837695881713035, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 1, 'residual_coef': 0.861775798981142}\n",
      "\r 77%|███████▋  | 46/60 [3:31:09<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 1/5\n",
      "\r 77%|███████▋  | 46/60 [3:31:09<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.543 Val loss 17.795\n",
      "\r 77%|███████▋  | 46/60 [3:31:13<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.480 Val loss 12.349\n",
      "\r 77%|███████▋  | 46/60 [3:31:41<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 77 best_val_loss 10.954\n",
      "\r 77%|███████▋  | 46/60 [3:31:43<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 2/5\n",
      "\r 77%|███████▋  | 46/60 [3:31:43<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.606 Val loss 17.759\n",
      "\r 77%|███████▋  | 46/60 [3:31:47<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.650 Val loss 11.101\n",
      "\r 77%|███████▋  | 46/60 [3:32:14<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 72 best_val_loss 9.791\n",
      "\r 77%|███████▋  | 46/60 [3:32:15<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 3/5\n",
      "\r 77%|███████▋  | 46/60 [3:32:15<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.738 Val loss 17.685\n",
      "\r 77%|███████▋  | 46/60 [3:32:19<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 51 best_val_loss 10.978\n",
      "\r 77%|███████▋  | 46/60 [3:32:41<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 4/5\n",
      "\r 77%|███████▋  | 46/60 [3:32:41<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.789 Val loss 17.302\n",
      "\r 77%|███████▋  | 46/60 [3:32:45<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 36 best_val_loss 11.171\n",
      "\r 77%|███████▋  | 46/60 [3:33:03<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rFold: 5/5\n",
      "\r 77%|███████▋  | 46/60 [3:33:03<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 0 Train loss 18.675 Val loss 17.033\n",
      "\r 77%|███████▋  | 46/60 [3:33:06<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEpoch 100 Train loss 4.599 Val loss 12.586\n",
      "\r 77%|███████▋  | 46/60 [3:33:36<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rEarly stopped at epoch 70 best_val_loss 11.559\n",
      "\r 77%|███████▋  | 46/60 [3:33:36<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r                                                                                     \rval MSE loss mean: 10.89063\n",
      "\n",
      "\r 77%|███████▋  | 46/60 [3:33:36<1:05:40, 281.47s/trial, best loss: 7.792647361755371]\r 78%|███████▊  | 47/60 [3:33:36<52:14, 241.12s/trial, best loss: 7.792647361755371]  \r                                                                                   \r{'act_fun': 'gelu', 'batch_size': 256, 'drop_ratio': 0.22507255630634332, 'encoder_dim_list': ((4, 64), (2, 128), (1, 64)), 'encoder_drop_ratio': 0.2676656717092088, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 300, 'hidden_dim_list': (2048, 1024, 256), 'lr': 0.0005040901827205068, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 1, 'residual_coef': 0.7002979745683163}\n",
      "\r 78%|███████▊  | 47/60 [3:33:36<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 1/5\n",
      "\r 78%|███████▊  | 47/60 [3:33:36<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 19.514 Val loss 20.045\n",
      "\r 78%|███████▊  | 47/60 [3:33:41<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.143 Val loss 8.485\n",
      "\r 78%|███████▊  | 47/60 [3:34:50<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 72 best_val_loss 8.171\n",
      "\r 78%|███████▊  | 47/60 [3:34:53<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 2/5\n",
      "\r 78%|███████▊  | 47/60 [3:34:53<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 20.043 Val loss 19.435\n",
      "\r 78%|███████▊  | 47/60 [3:34:57<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 58 best_val_loss 7.756\n",
      "\r 78%|███████▊  | 47/60 [3:35:51<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 3/5\n",
      "\r 78%|███████▊  | 47/60 [3:35:51<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 19.674 Val loss 19.538\n",
      "\r 78%|███████▊  | 47/60 [3:35:55<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.209 Val loss 8.064\n",
      "\r 78%|███████▊  | 47/60 [3:37:09<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 82 best_val_loss 7.800\n",
      "\r 78%|███████▊  | 47/60 [3:37:20<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 4/5\n",
      "\r 78%|███████▊  | 47/60 [3:37:20<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 19.825 Val loss 18.465\n",
      "\r 78%|███████▊  | 47/60 [3:37:24<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 3.981 Val loss 8.192\n",
      "\r 78%|███████▊  | 47/60 [3:38:35<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 104 best_val_loss 7.982\n",
      "\r 78%|███████▊  | 47/60 [3:39:01<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 5/5\n",
      "\r 78%|███████▊  | 47/60 [3:39:01<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 19.838 Val loss 18.260\n",
      "\r 78%|███████▊  | 47/60 [3:39:05<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 63 best_val_loss 7.976\n",
      "\r 78%|███████▊  | 47/60 [3:40:18<52:14, 241.12s/trial, best loss: 7.792647361755371]\r                                                                                   \rval MSE loss mean: 7.93683\n",
      "\n",
      "\r 78%|███████▊  | 47/60 [3:40:18<52:14, 241.12s/trial, best loss: 7.792647361755371]\r 80%|████████  | 48/60 [3:40:18<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \r{'act_fun': 'gelu', 'batch_size': 512, 'drop_ratio': 0.4124418905454339, 'encoder_dim_list': ((4, 64), (2, 128), (1, 128)), 'encoder_drop_ratio': 0.1132872422106029, 'encoder_norm': None, 'encoder_with_res': True, 'epochs': 400, 'hidden_dim_list': (2048, 256), 'lr': 0.0005908004617849263, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 4, 'residual_coef': 0.39997263966232055}\n",
      "\r 80%|████████  | 48/60 [3:40:18<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 1/5\n",
      "\r 80%|████████  | 48/60 [3:40:18<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 17.307 Val loss 17.178\n",
      "\r 80%|████████  | 48/60 [3:40:21<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 5.286 Val loss 8.801\n",
      "\r 80%|████████  | 48/60 [3:41:04<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 77 best_val_loss 8.686\n",
      "\r 80%|████████  | 48/60 [3:41:07<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 2/5\n",
      "\r 80%|████████  | 48/60 [3:41:07<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 17.689 Val loss 15.984\n",
      "\r 80%|████████  | 48/60 [3:41:11<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 60 best_val_loss 8.032\n",
      "\r 80%|████████  | 48/60 [3:41:41<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 3/5\n",
      "\r 80%|████████  | 48/60 [3:41:41<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 17.798 Val loss 16.552\n",
      "\r 80%|████████  | 48/60 [3:41:45<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 5.681 Val loss 8.881\n",
      "\r 80%|████████  | 48/60 [3:42:22<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 129 best_val_loss 8.079\n",
      "\r 80%|████████  | 48/60 [3:42:48<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 4/5\n",
      "\r 80%|████████  | 48/60 [3:42:48<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 17.758 Val loss 16.017\n",
      "\r 80%|████████  | 48/60 [3:42:52<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.896 Val loss 8.635\n",
      "\r 80%|████████  | 48/60 [3:43:34<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 97 best_val_loss 8.330\n",
      "\r 80%|████████  | 48/60 [3:43:46<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 5/5\n",
      "\r 80%|████████  | 48/60 [3:43:46<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 17.587 Val loss 17.033\n",
      "\r 80%|████████  | 48/60 [3:43:50<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 5.165 Val loss 8.475\n",
      "\r 80%|████████  | 48/60 [3:44:23<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 144 best_val_loss 8.235\n",
      "\r 80%|████████  | 48/60 [3:44:51<57:51, 289.29s/trial, best loss: 7.792647361755371]\r                                                                                   \rval MSE loss mean: 8.27246\n",
      "\n",
      "\r 80%|████████  | 48/60 [3:44:51<57:51, 289.29s/trial, best loss: 7.792647361755371]\r 82%|████████▏ | 49/60 [3:44:51<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.11907599046615094, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.4260890640610687, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0004307257660367826, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.5496262094308765}\n",
      "\r 82%|████████▏ | 49/60 [3:44:51<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 1/5\n",
      "\r 82%|████████▏ | 49/60 [3:44:51<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.352 Val loss 23.132\n",
      "\r 82%|████████▏ | 49/60 [3:44:54<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.775 Val loss 8.522\n",
      "\r 82%|████████▏ | 49/60 [3:45:23<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 136 best_val_loss 8.126\n",
      "\r 82%|████████▏ | 49/60 [3:45:41<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 2/5\n",
      "\r 82%|████████▏ | 49/60 [3:45:41<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.640 Val loss 21.637\n",
      "\r 82%|████████▏ | 49/60 [3:45:44<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.719 Val loss 7.477\n",
      "\r 82%|████████▏ | 49/60 [3:46:12<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 160 best_val_loss 7.077\n",
      "\r 82%|████████▏ | 49/60 [3:46:38<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 3/5\n",
      "\r 82%|████████▏ | 49/60 [3:46:38<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.804 Val loss 21.903\n",
      "\r 82%|████████▏ | 49/60 [3:46:41<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.797 Val loss 8.407\n",
      "\r 82%|████████▏ | 49/60 [3:47:09<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 82 best_val_loss 8.172\n",
      "\r 82%|████████▏ | 49/60 [3:47:12<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 4/5\n",
      "\r 82%|████████▏ | 49/60 [3:47:12<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.720 Val loss 20.495\n",
      "\r 82%|████████▏ | 49/60 [3:47:16<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 100 Train loss 4.723 Val loss 7.906\n",
      "\r 82%|████████▏ | 49/60 [3:47:44<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 115 best_val_loss 7.539\n",
      "\r 82%|████████▏ | 49/60 [3:47:58<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rFold: 5/5\n",
      "\r 82%|████████▏ | 49/60 [3:47:58<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEpoch 0 Train loss 21.778 Val loss 20.447\n",
      "\r 82%|████████▏ | 49/60 [3:48:01<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rEarly stopped at epoch 65 best_val_loss 8.008\n",
      "\r 82%|████████▏ | 49/60 [3:48:29<52:08, 284.44s/trial, best loss: 7.792647361755371]\r                                                                                   \rval MSE loss mean: 7.78447\n",
      "\n",
      "\r 82%|████████▏ | 49/60 [3:48:29<52:08, 284.44s/trial, best loss: 7.792647361755371]\r 83%|████████▎ | 50/60 [3:48:29<44:07, 264.70s/trial, best loss: 7.78447380065918] \r                                                                                  \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.004207169899641511, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.31409662316452464, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00015412914035086377, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.5257908138010365}\n",
      "\r 83%|████████▎ | 50/60 [3:48:29<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 1/5\n",
      "\r 83%|████████▎ | 50/60 [3:48:29<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 20.806 Val loss 20.582\n",
      "\r 83%|████████▎ | 50/60 [3:48:33<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 53 best_val_loss 10.540\n",
      "\r 83%|████████▎ | 50/60 [3:49:00<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 2/5\n",
      "\r 83%|████████▎ | 50/60 [3:49:00<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 20.951 Val loss 19.240\n",
      "\r 83%|████████▎ | 50/60 [3:49:04<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 30 best_val_loss 10.359\n",
      "\r 83%|████████▎ | 50/60 [3:49:25<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 3/5\n",
      "\r 83%|████████▎ | 50/60 [3:49:25<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.039 Val loss 20.057\n",
      "\r 83%|████████▎ | 50/60 [3:49:29<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 39 best_val_loss 11.520\n",
      "\r 83%|████████▎ | 50/60 [3:49:52<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 4/5\n",
      "\r 83%|████████▎ | 50/60 [3:49:52<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.035 Val loss 19.007\n",
      "\r 83%|████████▎ | 50/60 [3:49:56<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 49 best_val_loss 11.015\n",
      "\r 83%|████████▎ | 50/60 [3:50:20<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 5/5\n",
      "\r 83%|████████▎ | 50/60 [3:50:20<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.088 Val loss 18.294\n",
      "\r 83%|████████▎ | 50/60 [3:50:24<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 37 best_val_loss 11.467\n",
      "\r 83%|████████▎ | 50/60 [3:50:45<44:07, 264.70s/trial, best loss: 7.78447380065918]\r                                                                                  \rval MSE loss mean: 10.98019\n",
      "\n",
      "\r 83%|████████▎ | 50/60 [3:50:45<44:07, 264.70s/trial, best loss: 7.78447380065918]\r 85%|████████▌ | 51/60 [3:50:45<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.0577643865220924, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.2147806070546695, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.0004316214104984198, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.5612878027927032}\n",
      "\r 85%|████████▌ | 51/60 [3:50:45<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 1/5\n",
      "\r 85%|████████▌ | 51/60 [3:50:45<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 17.508 Val loss 16.176\n",
      "\r 85%|████████▌ | 51/60 [3:50:48<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 50 best_val_loss 8.253\n",
      "\r 85%|████████▌ | 51/60 [3:51:12<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 2/5\n",
      "\r 85%|████████▌ | 51/60 [3:51:12<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 18.075 Val loss 16.676\n",
      "\r 85%|████████▌ | 51/60 [3:51:15<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 54 best_val_loss 7.665\n",
      "\r 85%|████████▌ | 51/60 [3:51:40<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 3/5\n",
      "\r 85%|████████▌ | 51/60 [3:51:40<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 17.777 Val loss 15.965\n",
      "\r 85%|████████▌ | 51/60 [3:51:44<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 26 best_val_loss 8.248\n",
      "\r 85%|████████▌ | 51/60 [3:52:00<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 4/5\n",
      "\r 85%|████████▌ | 51/60 [3:52:00<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 17.785 Val loss 14.684\n",
      "\r 85%|████████▌ | 51/60 [3:52:03<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 3.708 Val loss 8.149\n",
      "\r 85%|████████▌ | 51/60 [3:52:33<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 152 best_val_loss 7.521\n",
      "\r 85%|████████▌ | 51/60 [3:52:56<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 5/5\n",
      "\r 85%|████████▌ | 51/60 [3:52:56<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 17.912 Val loss 15.680\n",
      "\r 85%|████████▌ | 51/60 [3:53:00<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 44 best_val_loss 8.281\n",
      "\r 85%|████████▌ | 51/60 [3:53:21<33:53, 225.93s/trial, best loss: 7.78447380065918]\r                                                                                  \rval MSE loss mean: 7.99352\n",
      "\n",
      "\r 85%|████████▌ | 51/60 [3:53:21<33:53, 225.93s/trial, best loss: 7.78447380065918]\r 87%|████████▋ | 52/60 [3:53:21<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.025688225059374584, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.42578546341422574, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00034942983792930006, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.12941742479138152}\n",
      "\r 87%|████████▋ | 52/60 [3:53:21<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 1/5\n",
      "\r 87%|████████▋ | 52/60 [3:53:21<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.053 Val loss 22.961\n",
      "\r 87%|████████▋ | 52/60 [3:53:24<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 65 best_val_loss 8.235\n",
      "\r 87%|████████▋ | 52/60 [3:53:51<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 2/5\n",
      "\r 87%|████████▋ | 52/60 [3:53:51<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.484 Val loss 21.665\n",
      "\r 87%|████████▋ | 52/60 [3:53:55<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 3.908 Val loss 7.477\n",
      "\r 87%|████████▋ | 52/60 [3:54:22<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 121 best_val_loss 7.198\n",
      "\r 87%|████████▋ | 52/60 [3:54:37<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 3/5\n",
      "\r 87%|████████▋ | 52/60 [3:54:37<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.687 Val loss 21.695\n",
      "\r 87%|████████▋ | 52/60 [3:54:40<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 37 best_val_loss 8.286\n",
      "\r 87%|████████▋ | 52/60 [3:54:59<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 4/5\n",
      "\r 87%|████████▋ | 52/60 [3:54:59<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.609 Val loss 20.425\n",
      "\r 87%|████████▋ | 52/60 [3:55:03<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 3.947 Val loss 7.873\n",
      "\r 87%|████████▋ | 52/60 [3:55:32<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 132 best_val_loss 7.397\n",
      "\r 87%|████████▋ | 52/60 [3:55:49<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 5/5\n",
      "\r 87%|████████▋ | 52/60 [3:55:50<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.669 Val loss 20.346\n",
      "\r 87%|████████▋ | 52/60 [3:55:53<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 4.070 Val loss 8.482\n",
      "\r 87%|████████▋ | 52/60 [3:56:21<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 71 best_val_loss 8.133\n",
      "\r 87%|████████▋ | 52/60 [3:56:22<27:19, 204.99s/trial, best loss: 7.78447380065918]\r                                                                                  \rval MSE loss mean: 7.84963\n",
      "\n",
      "\r 87%|████████▋ | 52/60 [3:56:22<27:19, 204.99s/trial, best loss: 7.78447380065918]\r 88%|████████▊ | 53/60 [3:56:22<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.11447536743795209, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.36416457905902305, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00025570375363264823, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.4082888662824572}\n",
      "\r 88%|████████▊ | 53/60 [3:56:22<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 1/5\n",
      "\r 88%|████████▊ | 53/60 [3:56:22<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.570 Val loss 22.957\n",
      "\r 88%|████████▊ | 53/60 [3:56:25<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 4.983 Val loss 8.430\n",
      "\r 88%|████████▊ | 53/60 [3:56:54<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 136 best_val_loss 7.968\n",
      "\r 88%|████████▊ | 53/60 [3:57:13<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 2/5\n",
      "\r 88%|████████▊ | 53/60 [3:57:13<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.520 Val loss 21.483\n",
      "\r 88%|████████▊ | 53/60 [3:57:17<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 4.912 Val loss 7.659\n",
      "\r 88%|████████▊ | 53/60 [3:57:45<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 200 Train loss 4.006 Val loss 7.236\n",
      "\r 88%|████████▊ | 53/60 [3:58:13<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 177 best_val_loss 7.121\n",
      "\r 88%|████████▊ | 53/60 [3:58:16<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 3/5\n",
      "\r 88%|████████▊ | 53/60 [3:58:16<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.783 Val loss 21.721\n",
      "\r 88%|████████▊ | 53/60 [3:58:19<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 4.986 Val loss 8.325\n",
      "\r 88%|████████▊ | 53/60 [3:58:47<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 75 best_val_loss 8.142\n",
      "\r 88%|████████▊ | 53/60 [3:58:49<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 4/5\n",
      "\r 88%|████████▊ | 53/60 [3:58:49<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.832 Val loss 20.432\n",
      "\r 88%|████████▊ | 53/60 [3:58:52<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 4.852 Val loss 7.770\n",
      "\r 88%|████████▊ | 53/60 [3:59:24<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 164 best_val_loss 7.401\n",
      "\r 88%|████████▊ | 53/60 [3:59:50<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rFold: 5/5\n",
      "\r 88%|████████▊ | 53/60 [3:59:50<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 0 Train loss 21.886 Val loss 20.245\n",
      "\r 88%|████████▊ | 53/60 [3:59:54<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEpoch 100 Train loss 5.078 Val loss 8.352\n",
      "\r 88%|████████▊ | 53/60 [4:00:22<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rEarly stopped at epoch 84 best_val_loss 8.050\n",
      "\r 88%|████████▊ | 53/60 [4:00:26<23:04, 197.73s/trial, best loss: 7.78447380065918]\r                                                                                  \rval MSE loss mean: 7.73619\n",
      "\n",
      "\r 88%|████████▊ | 53/60 [4:00:26<23:04, 197.73s/trial, best loss: 7.78447380065918]\r 90%|█████████ | 54/60 [4:00:26<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.11842643164632163, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.2524323679574555, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.0002703063051345681, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.29047978713536066}\n",
      "\r 90%|█████████ | 54/60 [4:00:26<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 90%|█████████ | 54/60 [4:00:26<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.190 Val loss 23.040\n",
      "\r 90%|█████████ | 54/60 [4:00:31<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.670 Val loss 8.357\n",
      "\r 90%|█████████ | 54/60 [4:01:01<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 99 best_val_loss 8.094\n",
      "\r 90%|█████████ | 54/60 [4:01:10<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 90%|█████████ | 54/60 [4:01:10<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.419 Val loss 21.566\n",
      "\r 90%|█████████ | 54/60 [4:01:14<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.680 Val loss 7.554\n",
      "\r 90%|█████████ | 54/60 [4:01:44<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 79 best_val_loss 7.386\n",
      "\r 90%|█████████ | 54/60 [4:01:47<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 90%|█████████ | 54/60 [4:01:47<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.536 Val loss 21.636\n",
      "\r 90%|█████████ | 54/60 [4:01:51<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.804 Val loss 8.243\n",
      "\r 90%|█████████ | 54/60 [4:02:21<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 99 best_val_loss 8.103\n",
      "\r 90%|█████████ | 54/60 [4:02:30<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 90%|█████████ | 54/60 [4:02:30<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.698 Val loss 20.421\n",
      "\r 90%|█████████ | 54/60 [4:02:33<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.790 Val loss 7.835\n",
      "\r 90%|█████████ | 54/60 [4:03:06<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 117 best_val_loss 7.518\n",
      "\r 90%|█████████ | 54/60 [4:03:20<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 90%|█████████ | 54/60 [4:03:20<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.655 Val loss 20.193\n",
      "\r 90%|█████████ | 54/60 [4:03:24<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.777 Val loss 8.642\n",
      "\r 90%|█████████ | 54/60 [4:03:54<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 93 best_val_loss 8.285\n",
      "\r 90%|█████████ | 54/60 [4:04:01<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 7.87708\n",
      "\n",
      "\r 90%|█████████ | 54/60 [4:04:01<21:10, 211.80s/trial, best loss: 7.7361856460571286]\r 92%|█████████▏| 55/60 [4:04:01<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.060503401061356515, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.36037030296441247, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.00022308236313445988, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.40792816474903937}\n",
      "\r 92%|█████████▏| 55/60 [4:04:01<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 92%|█████████▏| 55/60 [4:04:01<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.891 Val loss 17.880\n",
      "\r 92%|█████████▏| 55/60 [4:04:04<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 40 best_val_loss 9.638\n",
      "\r 92%|█████████▏| 55/60 [4:04:26<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 92%|█████████▏| 55/60 [4:04:26<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 19.059 Val loss 17.459\n",
      "\r 92%|█████████▏| 55/60 [4:04:30<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 54 best_val_loss 8.745\n",
      "\r 92%|█████████▏| 55/60 [4:04:57<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 92%|█████████▏| 55/60 [4:04:57<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 19.175 Val loss 17.508\n",
      "\r 92%|█████████▏| 55/60 [4:05:00<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 44 best_val_loss 9.706\n",
      "\r 92%|█████████▏| 55/60 [4:05:23<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 92%|█████████▏| 55/60 [4:05:23<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 19.154 Val loss 17.052\n",
      "\r 92%|█████████▏| 55/60 [4:05:27<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 61 best_val_loss 9.526\n",
      "\r 92%|█████████▏| 55/60 [4:05:55<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 92%|█████████▏| 55/60 [4:05:55<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 19.094 Val loss 16.844\n",
      "\r 92%|█████████▏| 55/60 [4:05:59<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 44 best_val_loss 10.455\n",
      "\r 92%|█████████▏| 55/60 [4:06:22<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 9.61399\n",
      "\n",
      "\r 92%|█████████▏| 55/60 [4:06:22<17:42, 212.58s/trial, best loss: 7.7361856460571286]\r 93%|█████████▎| 56/60 [4:06:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 2048, 'drop_ratio': 0.14537727779209866, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.29191194523149006, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00015841229846683374, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.14389307225293768}\n",
      "\r 93%|█████████▎| 56/60 [4:06:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 93%|█████████▎| 56/60 [4:06:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.583 Val loss 22.048\n",
      "\r 93%|█████████▎| 56/60 [4:06:26<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 6.701 Val loss 8.980\n",
      "\r 93%|█████████▎| 56/60 [4:06:56<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 200 Train loss 5.308 Val loss 8.202\n",
      "\r 93%|█████████▎| 56/60 [4:07:26<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 246 best_val_loss 8.087\n",
      "\r 93%|█████████▎| 56/60 [4:07:50<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 93%|█████████▎| 56/60 [4:07:50<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.686 Val loss 21.429\n",
      "\r 93%|█████████▎| 56/60 [4:07:53<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 6.804 Val loss 8.408\n",
      "\r 93%|█████████▎| 56/60 [4:08:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 200 Train loss 5.532 Val loss 7.856\n",
      "\r 93%|█████████▎| 56/60 [4:08:53<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 259 best_val_loss 7.694\n",
      "\r 93%|█████████▎| 56/60 [4:09:19<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 93%|█████████▎| 56/60 [4:09:19<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 22.099 Val loss 21.365\n",
      "\r 93%|█████████▎| 56/60 [4:09:23<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 7.370 Val loss 8.454\n",
      "\r 93%|█████████▎| 56/60 [4:09:52<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 200 Train loss 5.348 Val loss 7.765\n",
      "\r 93%|█████████▎| 56/60 [4:10:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 192 best_val_loss 7.677\n",
      "\r 93%|█████████▎| 56/60 [4:10:28<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 93%|█████████▎| 56/60 [4:10:28<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.824 Val loss 21.133\n",
      "\r 93%|█████████▎| 56/60 [4:10:32<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 6.811 Val loss 9.036\n",
      "\r 93%|█████████▎| 56/60 [4:11:02<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 200 Train loss 5.405 Val loss 8.251\n",
      "\r 93%|█████████▎| 56/60 [4:11:32<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 223 best_val_loss 8.132\n",
      "\r 93%|█████████▎| 56/60 [4:11:48<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 93%|█████████▎| 56/60 [4:11:48<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 22.102 Val loss 20.905\n",
      "\r 93%|█████████▎| 56/60 [4:11:52<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 7.333 Val loss 8.459\n",
      "\r 93%|█████████▎| 56/60 [4:12:22<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 200 Train loss 5.852 Val loss 7.985\n",
      "\r 93%|█████████▎| 56/60 [4:12:51<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 236 best_val_loss 7.901\n",
      "\r 93%|█████████▎| 56/60 [4:13:10<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 7.89829\n",
      "\n",
      "\r 93%|█████████▎| 56/60 [4:13:10<12:45, 191.26s/trial, best loss: 7.7361856460571286]\r 95%|█████████▌| 57/60 [4:13:10<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.0761831061178245, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.3839150317962268, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00019520293476244747, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.22523965550630426}\n",
      "\r 95%|█████████▌| 57/60 [4:13:10<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 95%|█████████▌| 57/60 [4:13:10<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.382 Val loss 22.810\n",
      "\r 95%|█████████▌| 57/60 [4:13:14<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.899 Val loss 8.326\n",
      "\r 95%|█████████▌| 57/60 [4:13:41<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 101 best_val_loss 8.055\n",
      "\r 95%|█████████▌| 57/60 [4:13:49<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 95%|█████████▌| 57/60 [4:13:49<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.556 Val loss 21.307\n",
      "\r 95%|█████████▌| 57/60 [4:13:53<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.748 Val loss 7.557\n",
      "\r 95%|█████████▌| 57/60 [4:14:20<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 99 best_val_loss 7.526\n",
      "\r 95%|█████████▌| 57/60 [4:14:28<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 95%|█████████▌| 57/60 [4:14:28<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.735 Val loss 21.584\n",
      "\r 95%|█████████▌| 57/60 [4:14:32<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.723 Val loss 8.583\n",
      "\r 95%|█████████▌| 57/60 [4:14:59<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 82 best_val_loss 8.206\n",
      "\r 95%|█████████▌| 57/60 [4:15:02<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 95%|█████████▌| 57/60 [4:15:02<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.813 Val loss 20.326\n",
      "\r 95%|█████████▌| 57/60 [4:15:06<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.665 Val loss 7.718\n",
      "\r 95%|█████████▌| 57/60 [4:15:38<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 80 best_val_loss 7.590\n",
      "\r 95%|█████████▌| 57/60 [4:15:41<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 95%|█████████▌| 57/60 [4:15:41<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 21.814 Val loss 20.143\n",
      "\r 95%|█████████▌| 57/60 [4:15:44<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.788 Val loss 8.204\n",
      "\r 95%|█████████▌| 57/60 [4:16:13<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 131 best_val_loss 7.746\n",
      "\r 95%|█████████▌| 57/60 [4:16:31<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 7.82471\n",
      "\n",
      "\r 95%|█████████▌| 57/60 [4:16:31<12:48, 256.22s/trial, best loss: 7.7361856460571286]\r 97%|█████████▋| 58/60 [4:16:31<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.09958005789652805, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.3308293211355622, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 400, 'hidden_dim_list': (1024, 256), 'lr': 0.00035315458570953876, 'lrf': 0.01, 'norm_fun': 'layer_norm', 'num_heads': 2, 'residual_coef': 0.47497661758662046}\n",
      "\r 97%|█████████▋| 58/60 [4:16:31<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 97%|█████████▋| 58/60 [4:16:31<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.327 Val loss 17.783\n",
      "\r 97%|█████████▋| 58/60 [4:16:35<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 67 best_val_loss 8.444\n",
      "\r 97%|█████████▋| 58/60 [4:17:03<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 97%|█████████▋| 58/60 [4:17:03<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.587 Val loss 17.827\n",
      "\r 97%|█████████▋| 58/60 [4:17:06<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.372 Val loss 8.935\n",
      "\r 97%|█████████▋| 58/60 [4:17:35<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 77 best_val_loss 7.600\n",
      "\r 97%|█████████▋| 58/60 [4:17:37<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 97%|█████████▋| 58/60 [4:17:37<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.498 Val loss 17.747\n",
      "\r 97%|█████████▋| 58/60 [4:17:41<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 55 best_val_loss 8.226\n",
      "\r 97%|█████████▋| 58/60 [4:18:04<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 97%|█████████▋| 58/60 [4:18:04<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.700 Val loss 17.426\n",
      "\r 97%|█████████▋| 58/60 [4:18:08<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.764 Val loss 8.712\n",
      "\r 97%|█████████▋| 58/60 [4:18:39<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 80 best_val_loss 8.088\n",
      "\r 97%|█████████▋| 58/60 [4:18:42<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 97%|█████████▋| 58/60 [4:18:42<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 18.468 Val loss 17.329\n",
      "\r 97%|█████████▋| 58/60 [4:18:46<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 100 Train loss 4.349 Val loss 8.814\n",
      "\r 97%|█████████▋| 58/60 [4:19:13<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 98 best_val_loss 8.247\n",
      "\r 97%|█████████▋| 58/60 [4:19:21<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 8.12098\n",
      "\n",
      "\r 97%|█████████▋| 58/60 [4:19:21<07:59, 239.63s/trial, best loss: 7.7361856460571286]\r 98%|█████████▊| 59/60 [4:19:21<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \r{'act_fun': 'relu', 'batch_size': 256, 'drop_ratio': 0.029059117351472444, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.39765650997572544, 'encoder_norm': 'layer_norm', 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00028098935091287703, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.08477507048430716}\n",
      "\r 98%|█████████▊| 59/60 [4:19:21<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 1/5\n",
      "\r 98%|█████████▊| 59/60 [4:19:21<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 20.289 Val loss 18.663\n",
      "\r 98%|█████████▊| 59/60 [4:19:25<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 24 best_val_loss 12.345\n",
      "\r 98%|█████████▊| 59/60 [4:20:04<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 2/5\n",
      "\r 98%|█████████▊| 59/60 [4:20:04<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 20.846 Val loss 18.842\n",
      "\r 98%|█████████▊| 59/60 [4:20:08<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 40 best_val_loss 11.837\n",
      "\r 98%|█████████▊| 59/60 [4:20:50<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 3/5\n",
      "\r 98%|█████████▊| 59/60 [4:20:50<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 20.559 Val loss 18.052\n",
      "\r 98%|█████████▊| 59/60 [4:20:55<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 57 best_val_loss 12.161\n",
      "\r 98%|█████████▊| 59/60 [4:22:02<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 4/5\n",
      "\r 98%|█████████▊| 59/60 [4:22:02<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 20.688 Val loss 17.941\n",
      "\r 98%|█████████▊| 59/60 [4:22:06<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 50 best_val_loss 12.625\n",
      "\r 98%|█████████▊| 59/60 [4:22:53<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rFold: 5/5\n",
      "\r 98%|█████████▊| 59/60 [4:22:53<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEpoch 0 Train loss 20.747 Val loss 17.368\n",
      "\r 98%|█████████▊| 59/60 [4:22:57<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rEarly stopped at epoch 27 best_val_loss 12.138\n",
      "\r 98%|█████████▊| 59/60 [4:23:33<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r                                                                                    \rval MSE loss mean: 12.22106\n",
      "\n",
      "\r 98%|█████████▊| 59/60 [4:23:33<03:38, 218.71s/trial, best loss: 7.7361856460571286]\r100%|██████████| 60/60 [4:23:33<00:00, 228.84s/trial, best loss: 7.7361856460571286]\r100%|██████████| 60/60 [4:23:33<00:00, 263.56s/trial, best loss: 7.7361856460571286]\n",
      "Best params:{'act_fun': 'relu', 'batch_size': 1024, 'drop_ratio': 0.11447536743795209, 'encoder_dim_list': ((8, 32), (2, 64), (1, 64)), 'encoder_drop_ratio': 0.36416457905902305, 'encoder_norm': None, 'encoder_with_res': False, 'epochs': 300, 'hidden_dim_list': (1024, 256), 'lr': 0.00025570375363264823, 'lrf': 0.01, 'norm_fun': 'batch_norm', 'num_heads': 2, 'residual_coef': 0.4082888662824572}\n",
      "\n",
      "Fold: 1/5\n",
      "[Epoch 0 fold 1 logkcatkm] Train loss 21.570 Val loss 22.957\n",
      "[Epoch 50 fold 1 logkcatkm] Train loss 6.192 Val loss 8.835\n",
      "[Epoch 100 fold 1 logkcatkm] Train loss 4.983 Val loss 8.430\n",
      "[Epoch 150 fold 1 logkcatkm] Train loss 4.350 Val loss 8.177\n",
      "Early stopped at epoch 136 best_val_loss 7.968\n",
      "Fold: 2/5\n",
      "[Epoch 0 fold 2 logkcatkm] Train loss 21.520 Val loss 21.483\n",
      "[Epoch 50 fold 2 logkcatkm] Train loss 6.636 Val loss 8.469\n",
      "[Epoch 100 fold 2 logkcatkm] Train loss 4.912 Val loss 7.659\n",
      "[Epoch 150 fold 2 logkcatkm] Train loss 4.307 Val loss 7.347\n",
      "[Epoch 200 fold 2 logkcatkm] Train loss 4.006 Val loss 7.236\n",
      "Early stopped at epoch 177 best_val_loss 7.121\n",
      "Fold: 3/5\n",
      "[Epoch 0 fold 3 logkcatkm] Train loss 21.783 Val loss 21.721\n",
      "[Epoch 50 fold 3 logkcatkm] Train loss 6.331 Val loss 8.431\n",
      "[Epoch 100 fold 3 logkcatkm] Train loss 4.986 Val loss 8.325\n",
      "Early stopped at epoch 75 best_val_loss 8.142\n",
      "Fold: 4/5\n",
      "[Epoch 0 fold 4 logkcatkm] Train loss 21.832 Val loss 20.432\n",
      "[Epoch 50 fold 4 logkcatkm] Train loss 6.244 Val loss 8.314\n",
      "[Epoch 100 fold 4 logkcatkm] Train loss 4.852 Val loss 7.770\n",
      "[Epoch 150 fold 4 logkcatkm] Train loss 4.339 Val loss 7.800\n",
      "Early stopped at epoch 164 best_val_loss 7.401\n",
      "Fold: 5/5\n",
      "[Epoch 0 fold 5 logkcatkm] Train loss 21.886 Val loss 20.245\n",
      "[Epoch 50 fold 5 logkcatkm] Train loss 6.405 Val loss 8.763\n",
      "[Epoch 100 fold 5 logkcatkm] Train loss 5.078 Val loss 8.352\n",
      "Early stopped at epoch 84 best_val_loss 8.050\n",
      "Dimension of x: 1328\n",
      "[Val_mean] rmse 2.7970 mae 2.0360 r2 0.5468 pcc 0.7436 [Test_mean] rmse 2.8613 mae 2.0638 r2 0.5192 pcc 0.7255\n",
      "\n",
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval  # 超参数搜索\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    y_true = np.array(y_true).ravel()\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "\n",
    "def return_data_loader(x, y, batch_size, shuffle=True, seed=66):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    x = torch.FloatTensor(x)\n",
    "    y = torch.FloatTensor(y)\n",
    "    label_loader = Data.DataLoader(Data.TensorDataset(x, y), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return label_loader\n",
    "\n",
    "def return_x_y(df_filtered):\n",
    "    y = df_filtered[label_name].values\n",
    "    mask = ~np.isnan(y)\n",
    "\n",
    "    # factors\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_filtered['ph'].values.reshape(-1, 1)\n",
    "        t = df_filtered['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_filtered['mw'].values.reshape(-1, 1)\n",
    "        logp = df_filtered['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_filtered[protein_column].tolist())\n",
    "    substrate_data = np.array(df_filtered[substrate_column].tolist())\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    accu_loss_train = torch.zeros(1).to(device)  # 累计损失\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, data in enumerate(train_loader):\n",
    "        data, label_value = data[0].to(device), data[1].to(device)\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = loss_function(pred.float().squeeze(), label_value.float())\n",
    "        loss.backward()\n",
    "        accu_loss_train += loss.detach()\n",
    "\n",
    "        # 在更新权重之前，对梯度进行裁剪，使其不超过clip_value\n",
    "        torch.nn.utils.clip_grad_value_([p for p in model.parameters() if p.requires_grad], clip_value=clip_value)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return accu_loss_train.item() / (step + 1), model\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, mode='search'):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_function = torch.nn.MSELoss()\n",
    "        accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "\n",
    "        for step, data in enumerate(data_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_function(outputs.float().squeeze(), labels.float())\n",
    "            accu_loss += loss.detach()\n",
    "\n",
    "            if mode != 'search':\n",
    "                all_pred.extend(outputs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    torch.cuda.empty_cache()  # 清理未使用的缓存\n",
    "\n",
    "    if mode == 'search':\n",
    "        return accu_loss.item() / len(data_loader)  # 返回平均损失\n",
    "\n",
    "    else:\n",
    "        return all_pred, all_labels\n",
    "\n",
    "def search_model(params, train_x, train_y, val_x, val_y):\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = TransformerKP(\n",
    "                input_dim=len(train_x[0]),\n",
    "                hidden_dim_list=params['hidden_dim_list'],\n",
    "                encoder_dim_list=params['encoder_dim_list'],\n",
    "                drop_ratio=params['drop_ratio'],\n",
    "                norm_fun=params['norm_fun'],\n",
    "                act_fun=params['act_fun'],\n",
    "                encoder_with_res=params['encoder_with_res'],\n",
    "                encoder_norm=params['encoder_norm'],\n",
    "                encoder_drop_ratio=params['encoder_drop_ratio'],\n",
    "                num_heads=params['num_heads'],\n",
    "                residual_coef=params['residual_coef']\n",
    "            ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums = 0, 0\n",
    "\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        # train\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "        if epoch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch_idx} Train loss {train_loss:.3f} Val loss {val_loss:.3f}')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            break\n",
    "\n",
    "    # print Log\n",
    "    if patience_nums > patience:\n",
    "        print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "    else:\n",
    "        print(f'Stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "\n",
    "    return best_loss\n",
    "\n",
    "\n",
    "def _search_params(params):\n",
    "    print(params)\n",
    "    val_loss_list = []\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "        print(f\"Fold: {fold_idx}/5\")\n",
    "        df_train = df_train_val.iloc[train_index]\n",
    "        df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "        train_x, train_y = return_x_y(df_train)\n",
    "        val_x, val_y = return_x_y(df_val)\n",
    "\n",
    "        val_loss = search_model(params, train_x, train_y, val_x, val_y)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    val_loss_mean = np.mean(val_loss_list, axis=0)\n",
    "    print(f\"val MSE loss mean: {val_loss_mean:.5f}\\n\")\n",
    "\n",
    "    return val_loss_mean\n",
    "\n",
    "\n",
    "def search_best_param(max_evals):\n",
    "    space = {\n",
    "        \"lr\": hp.uniform(\"lr\", 1e-4, 1e-3),\n",
    "        'lrf': hp.choice('lrf', [0.01]),\n",
    "        \"drop_ratio\": hp.uniform(\"drop_ratio\", 0, 0.5),\n",
    "        'hidden_dim_list': hp.choice('hidden_dim_list', [\n",
    "            (2048, 1024, 256),\n",
    "            (1024, 256),\n",
    "            (2048, 256)\n",
    "        ]),\n",
    "        'encoder_dim_list': hp.choice('encoder_dim_list', [\n",
    "            [(8, 32), (1, 64)],\n",
    "            [(8, 32), (2, 64), (1, 64)],\n",
    "            [(4, 64), (2, 128), (1, 128)],\n",
    "            [(4, 64), (2, 128), (1, 64)]\n",
    "        ]),\n",
    "        'norm_fun': hp.choice('norm_fun', ['batch_norm', 'layer_norm']),\n",
    "        'act_fun': hp.choice('act_fun', ['gelu', 'relu']),\n",
    "        'encoder_with_res': hp.choice('encoder_with_res', [False, True]),\n",
    "        'encoder_norm': hp.choice('encoder_norm', ['layer_norm', None]),\n",
    "        \"encoder_drop_ratio\": hp.uniform(\"encoder_drop_ratio\", 0, 0.5),\n",
    "        'num_heads': hp.choice('num_heads', [1, 2, 4]),\n",
    "        'residual_coef': hp.uniform('residual_coef', 0, 1.0),\n",
    "        'batch_size': hp.choice('batch_size', [256, 512, 1024, 2048]),\n",
    "        'epochs': hp.choice('epochs', [200, 300, 400]),\n",
    "    }\n",
    "\n",
    "    trials = Trials()\n",
    "    print(f'[Info] Starting parameter search with MSE_Loss...')\n",
    "    best_params = fmin(fn=_search_params, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "    best_params = space_eval(space, best_params)\n",
    "\n",
    "    # Save the best params to JSON\n",
    "    with open(params_json_path, 'w') as json_file:\n",
    "        json.dump(best_params, json_file)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "search_max_evals = 60\n",
    "patience = 30\n",
    "clip_value = 0.8\n",
    "\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'transformer_standard'\n",
    "label_name = 'logkcatkm'\n",
    "\n",
    "df_standardized = pd.read_pickle(f'{current_dir}/../../data_process/dataset/df_standardized.pkl')\n",
    "df_train_val, df_test = train_test_split(df_standardized, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "params_json_path = f'./model_dict/{input_model}_params.json'\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path) as json_file:\n",
    "        params = json.load(json_file)\n",
    "else:\n",
    "    params = search_best_param(search_max_evals)\n",
    "\n",
    "print(f'Best params:{params}\\n')\n",
    "\n",
    "# Train\n",
    "val_scores_list, test_scores_list = [], []\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(df_train_val), start=1):\n",
    "    print(f\"Fold: {fold_idx}/5\")\n",
    "    df_train = df_train_val.iloc[train_index]\n",
    "    df_val = df_train_val.iloc[val_index]\n",
    "\n",
    "    train_x, train_y = return_x_y(df_train)\n",
    "    val_x, val_y = return_x_y(df_val)\n",
    "    test_x, test_y = return_x_y(df_test)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = return_data_loader(train_x, train_y, batch_size=params['batch_size'], shuffle=True, seed=random_state)\n",
    "    val_loader = return_data_loader(val_x, val_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "    test_loader = return_data_loader(test_x, test_y, batch_size=params['batch_size'], shuffle=False, seed=random_state)\n",
    "\n",
    "    model = TransformerKP(\n",
    "                input_dim=len(train_x[0]),\n",
    "                hidden_dim_list=params['hidden_dim_list'],\n",
    "                encoder_dim_list=params['encoder_dim_list'],\n",
    "                drop_ratio=params['drop_ratio'],\n",
    "                norm_fun=params['norm_fun'],\n",
    "                act_fun=params['act_fun'],\n",
    "                encoder_with_res=params['encoder_with_res'],\n",
    "                encoder_norm=params['encoder_norm'],\n",
    "                encoder_drop_ratio=params['encoder_drop_ratio'],\n",
    "                num_heads=params['num_heads'],\n",
    "                residual_coef=params['residual_coef']\n",
    "            ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(pg, lr=params['lr'], weight_decay=5E-5)  # optimizer\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / params['epochs'])) / 2) * (1 - params['lrf']) + params['lrf']  # cosine\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    best_epoch, patience_nums, best_model = 0, 0, None\n",
    "\n",
    "    # train\n",
    "    for epoch_idx in range(params['epochs']):\n",
    "        train_loss, model = train_one_epoch(model, optimizer, train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = evaluate_model(model, val_loader, mode='search')\n",
    "\n",
    "        # compare\n",
    "        if val_loss <= best_loss:\n",
    "            best_model = model\n",
    "            best_epoch = epoch_idx\n",
    "            best_loss = val_loss\n",
    "            patience_nums = 0\n",
    "\n",
    "        else:\n",
    "            patience_nums += 1\n",
    "\n",
    "        if patience_nums > patience:\n",
    "            print(f'Early stopped at epoch {best_epoch} best_val_loss {best_loss:.3f}')\n",
    "            break\n",
    "        if epoch_idx % 50 == 0:\n",
    "            print(f\"[Epoch {epoch_idx} fold {fold_idx} {label_name}] Train loss {train_loss:.3f} Val loss {val_loss:.3f}\")\n",
    "\n",
    "    val_pred, val_labels = evaluate_model(best_model, val_loader, mode='val')\n",
    "    test_pred, test_labels = evaluate_model(best_model, test_loader, mode='test')\n",
    "\n",
    "    # scores\n",
    "    val_scores = return_scores(val_labels, val_pred)\n",
    "    test_scores = return_scores(test_labels, test_pred)\n",
    "    val_scores_list.append(val_scores)\n",
    "    test_scores_list.append(test_scores)\n",
    "\n",
    "    # fold\n",
    "    fold_results.append([\n",
    "        fold_idx,\n",
    "        val_scores[0], val_scores[1], val_scores[2], val_scores[3],\n",
    "        test_scores[0], test_scores[1], test_scores[2], test_scores[3]\n",
    "    ])\n",
    "\n",
    "# mean\n",
    "val_scores_mean = np.mean(val_scores_list, axis=0)\n",
    "test_scores_mean = np.mean(test_scores_list, axis=0)\n",
    "\n",
    "print(f\"Dimension of x: {train_x.shape[1]}\")\n",
    "print(f\"[Val_mean] rmse {val_scores_mean[0]:.4f} mae {val_scores_mean[1]:.4f} r2 {val_scores_mean[2]:.4f} pcc {val_scores_mean[3]:.4f} \"\n",
    "      f\"[Test_mean] rmse {test_scores_mean[0]:.4f} mae {test_scores_mean[1]:.4f} r2 {test_scores_mean[2]:.4f} pcc {test_scores_mean[3]:.4f}\\n\")\n",
    "\n",
    "# save cvs\n",
    "df_cv_results = pd.DataFrame(fold_results, columns=[\n",
    "    \"Fold\",\n",
    "    \"Val_RMSE\", \"Val_MAE\", \"Val_R2\", \"Val_PCC\",\n",
    "    \"Test_RMSE\", \"Test_MAE\", \"Test_R2\", \"Test_PCC\"])\n",
    "df_cv_results.to_excel(f\"./results/{input_model}_cv_results.xlsx\", index=False)\n",
    "print(\"Results saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynoMTGBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db0e6cebfd42dbe7de32cf1b0daf517db5c30eda4a99fad3eb7c5d8b4a7bde0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
