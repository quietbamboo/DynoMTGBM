{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1f96913c6945c4",
   "metadata": {},
   "source": [
    "# MTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3036b6e8114f7cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda/envs/km_predict/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cuda:0\n",
      "Reading data...Finished.\n",
      "best_params: {'bagging_fraction': 0.729611058732434, 'feature_fraction': 0.6643005188332146, 'lambda_l1': 0.346846951564011, 'lambda_l2': 0.7149783548509333, 'learning_rate': 0.07838547411322133, 'max_bin': 95, 'max_depth': 9, 'min_data_in_leaf': 21, 'num_iterations': 3273, 'num_leaves': 2350}\n",
      "using -km kcat kcatkm resample\n",
      "Fold: 1/5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.85301\n",
      "Early stopping, best iteration is:\n",
      "[608]\tvalid_0's rmse_kcatkm: 3.84848\n",
      "valid_records min_index 607\n",
      "inner_predict 27918\n",
      "Val  {'logkm': (2.3628156373896076, 1.8614934156904146, 0.35296247621129784, 0.5957523127292299), 'logkcat': (3.2227939543542306, 2.4515167608390187, 0.10003374724750336, 0.3346397316478254), 'logkcatkm': (3.8484839341384656, 3.052279655546175, 0.10506309607644726, 0.33030360081623283)}\n",
      "\n",
      "Fold: 2/5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's rmse_kcatkm: 4.04393\n",
      "valid_records min_index 248\n",
      "inner_predict 27918\n",
      "Val  {'logkm': (2.491059455939739, 1.94162979894874, 0.334643957210505, 0.5797984046892093), 'logkcat': (3.2807467006363766, 2.5407786704266258, 0.13574865980686002, 0.393475746154968), 'logkcatkm': (4.043933959717752, 3.0916273373161087, 0.09151204158062376, 0.30289759347335277)}\n",
      "\n",
      "Fold: 3/5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.80597\n",
      "Early stopping, best iteration is:\n",
      "[1010]\tvalid_0's rmse_kcatkm: 3.80527\n",
      "valid_records min_index 1009\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.80597\n",
      "inner_predict 27918\n",
      "Val  {'logkm': (2.3246121525700096, 1.78995155178954, 0.3526896095666, 0.5941565574322143), 'logkcat': (3.311274430018575, 2.5324758845683744, 0.11250666322259417, 0.3433569726876937), 'logkcatkm': (3.8052721711576387, 3.0368130697276317, 0.12497141272018919, 0.35458081953493914)}\n",
      "\n",
      "Fold: 4/5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.85023\n",
      "Early stopping, best iteration is:\n",
      "[1053]\tvalid_0's rmse_kcatkm: 3.84849\n",
      "valid_records min_index 1052\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.85023\n",
      "inner_predict 27918\n",
      "Val  {'logkm': (2.4027670430787276, 1.8734072655384595, 0.39208074091082146, 0.6300691495414454), 'logkcat': (3.2094457421211593, 2.490866370690905, 0.1636964614860017, 0.40749929020463743), 'logkcatkm': (3.848489230661226, 2.953320734731034, 0.10943796597127131, 0.3350314081649107)}\n",
      "\n",
      "Fold: 5/5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.99367\n",
      "Early stopping, best iteration is:\n",
      "[1208]\tvalid_0's rmse_kcatkm: 3.99287\n",
      "valid_records min_index 1207\n",
      "[1000]\tvalid_0's rmse_kcatkm: 3.99367\n",
      "inner_predict 27918\n",
      "Val  {'logkm': (2.5452663958894477, 1.9314292927344874, 0.25297767427278484, 0.5101918307072975), 'logkcat': (3.3725021781536872, 2.62333895005177, 0.12116982162950263, 0.35834421548364415), 'logkcatkm': (3.9928713243546192, 3.145940919543887, 0.12929538014260156, 0.36371023784018186)}\n",
      "\n",
      "logkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.4253\t 1.8796\t 0.3371\t 0.5820\t\n",
      "\n",
      "logkcat\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  3.2794\t 2.5278\t 0.1266\t 0.3675\t\n",
      "\n",
      "logkcatkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  3.9078\t 3.0560\t 0.1121\t 0.3373\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import lightgbmmt as lgb\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "def return_mtgbm_x_y(df_data, tasks):\n",
    "    y = np.array(df_data[tasks].values)\n",
    "\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_data['ph'].values.reshape(-1, 1)\n",
    "        t = df_data['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_data['mw'].values.reshape(-1, 1)\n",
    "        logp = df_data['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_data[protein_column].tolist())\n",
    "    substrate_data = np.array(df_data[substrate_column].tolist())\n",
    "\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "    return x, y\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "def print_scores(task_scores_dict):\n",
    "    for task_name in task_names:\n",
    "        print(f\"{task_name}\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "\n",
    "        task_val_scores = task_scores_dict[task_name]['val']\n",
    "        val_metrics = [f\"{np.mean(task_val_scores[metric_name]):.4f}\\t\" for metric_name in score_names]\n",
    "        print(\"Val  \" + \" \".join(val_metrics))\n",
    "        print()\n",
    "\n",
    "def self_kcatkm_rmse(preds, train_data):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "\n",
    "    # extract kcatkm values\n",
    "    labels = labels.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "    preds = preds.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    valid_labels = labels[valid_mask]\n",
    "    valid_preds = preds[valid_mask]\n",
    "\n",
    "    kcatkm_rmse = torch.sqrt(torch.mean((valid_labels - valid_preds) ** 2))\n",
    "\n",
    "    return 'rmse_kcatkm', kcatkm_rmse.item(), False\n",
    "\n",
    "\n",
    "def cal_grad(preds, train_data, ep=0):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "    labels = labels.view(num_tasks, -1).T\n",
    "    preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    grad = torch.zeros_like(preds)\n",
    "    grad[valid_mask] = preds[valid_mask] - labels[valid_mask]\n",
    "\n",
    "    # sum\n",
    "    grad_final = grad.mean(dim=1)\n",
    "\n",
    "    # Hessian\n",
    "    grad_flattened = grad.T.flatten()\n",
    "    hess = torch.ones_like(grad_final)\n",
    "    hess2 = torch.ones_like(grad_flattened)\n",
    "\n",
    "    return grad_final.cpu().numpy(), hess.cpu().numpy(), grad_flattened.cpu().numpy(), hess2.cpu().numpy()\n",
    "\n",
    "\n",
    "# TODO Train model\n",
    "def train_mtgbm(params):\n",
    "    temp_params = deepcopy(params)\n",
    "    temp_params.update({\"verbosity\": -1, \"objective\": \"custom\", \"num_labels\": num_tasks, \"tree_learner\": 'serial2', \"num_threads\": num_threads})\n",
    "    num_iterations = temp_params.pop(\"num_iterations\")\n",
    "\n",
    "    task_scores_dict = {task_name: {'val': {name: [] for name in score_names}} for task_name in task_names}\n",
    "\n",
    "    for fold_idx, (fold_train_idx, fold_val_idx) in enumerate(df_fold_index.values.tolist(), start=1):\n",
    "        print(f\"Fold: {fold_idx}/5\")\n",
    "        train_x, train_y = return_mtgbm_x_y(df_input.loc[fold_train_idx], task_names)\n",
    "        val_x, val_y = return_mtgbm_x_y(df_input.loc[fold_val_idx], task_names)\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # get the best epoch number\n",
    "        evals_result_mt = {}\n",
    "        lgb.train(temp_params, train_data, num_iterations, valid_sets=[val_data],\n",
    "                  fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000, evals_result=evals_result_mt,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500)])\n",
    "        valid_records = evals_result_mt['valid_0']['rmse_kcatkm']\n",
    "        min_index = np.argmin(np.array(valid_records))\n",
    "        print(f\"valid_records min_index {min_index}\")\n",
    "\n",
    "        # train model for all scores of validation\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "        evals_result_mt = {}\n",
    "        model = lgb.train(temp_params, train_data, min_index + 1, valid_sets=[val_data],\n",
    "                          fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000,\n",
    "                          evals_result=evals_result_mt)\n",
    "        model.set_num_labels(num_tasks)\n",
    "\n",
    "        # validation predict\n",
    "        val_predicted = model.predict(val_x)\n",
    "        val_scores = {task_name: return_scores(val_y[:, idx], val_predicted[:, idx]) for idx, task_name in\n",
    "                      enumerate(task_names)}\n",
    "\n",
    "        # record\n",
    "        for task_name in task_names:\n",
    "            for score_idx, score_name in enumerate(score_names):\n",
    "                task_scores_dict[task_name]['val'][score_name].append(val_scores[task_name][score_idx])\n",
    "        print(f\"Val  {val_scores}\\n\")\n",
    "\n",
    "    print_scores(task_scores_dict)\n",
    "\n",
    "\n",
    "# init seed\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "# config\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'mtgbm_km_kcat_kcatkm'\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "num_threads = 32\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is {device}\")\n",
    "\n",
    "# input\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "task_names = ['logkm', 'logkcat', 'logkcatkm']\n",
    "num_tasks = len(task_names)\n",
    "print('Reading data...', end='')\n",
    "df_input = pd.read_pickle(current_dir + f'/../../data_process/dataset/df_all_log_transformed.pkl')\n",
    "df_input['logkm'] = -df_input['logkm']\n",
    "fill_nan_value = -100\n",
    "df_input = df_input.fillna(fill_nan_value)\n",
    "\n",
    "df_fold_index = pd.read_pickle(current_dir + f'/../../data_process/dataset/cdhit/cdhit_fold_index.pkl')\n",
    "print('Finished.')\n",
    "\n",
    "with open(f'{current_dir}/../../kcatkm_mtgbm_ablation/{input_model}_params.json', 'r') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "\n",
    "print('best_params:', best_params)\n",
    "print('using -km kcat kcatkm resample')\n",
    "train_mtgbm(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "391ae7a9a517ea640120dfb04776679e361e6af223196de029c77b4062e2a450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
