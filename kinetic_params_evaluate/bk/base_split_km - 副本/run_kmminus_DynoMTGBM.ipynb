{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1f96913c6945c4",
   "metadata": {},
   "source": "# DynoMTGBM (-logkm logkcat logkcatkm)"
  },
  {
   "cell_type": "code",
   "id": "3036b6e8114f7cbd",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from decorator import append\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import lightgbmmt as lgb\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "def return_mtgbm_x_y(df_data, tasks):\n",
    "    y = np.array(df_data[tasks].values)\n",
    "\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_data['ph'].values.reshape(-1, 1)\n",
    "        t = df_data['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_data['mw'].values.reshape(-1, 1)\n",
    "        logp = df_data['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_data[protein_column].tolist())\n",
    "    substrate_data = np.array(df_data[substrate_column].tolist())\n",
    "\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "    return x, y\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "def print_scores(task_scores_dict):\n",
    "    for task_name in task_names:\n",
    "        print(f\"{task_name}\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "\n",
    "        task_val_scores = task_scores_dict[task_name]['val']\n",
    "        task_test_scores = task_scores_dict[task_name]['test']\n",
    "\n",
    "        val_metrics = [f\"{np.mean(task_val_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                       score_names]\n",
    "        print(\"Val  \" + \" \".join(val_metrics))\n",
    "\n",
    "        test_metrics = [f\"{np.mean(task_test_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                        score_names]\n",
    "        print(\"Test \" + \" \".join(test_metrics))\n",
    "        print()\n",
    "\n",
    "\n",
    "def cal_grad(preds, train_data, ep=0):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "    labels = labels.view(num_tasks, -1).T\n",
    "    preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    grad = torch.zeros_like(preds)\n",
    "    grad[valid_mask] = preds[valid_mask] - labels[valid_mask]\n",
    "\n",
    "    # sum\n",
    "    grad_final = grad.mean(dim=1)\n",
    "\n",
    "    # Hessian\n",
    "    grad_flattened = grad.T.flatten()\n",
    "    hess = torch.ones_like(grad_final)\n",
    "    hess2 = torch.ones_like(grad_flattened)\n",
    "\n",
    "    return grad_final.cpu().numpy(), hess.cpu().numpy(), grad_flattened.cpu().numpy(), hess2.cpu().numpy()\n",
    "\n",
    "# TODO Train model\n",
    "def train_mtgbm(params):\n",
    "    def self_km_rmse(preds, train_data):\n",
    "        labels = torch.tensor(train_data.get_label(), device=device)\n",
    "        preds = torch.tensor(preds, device=device)\n",
    "        labels = labels.view(num_tasks, -1).T\n",
    "        preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "        # all task rmse\n",
    "        task_rmse = []\n",
    "        for task_idx in range(num_tasks):\n",
    "            valid_mask = labels[:, task_idx] != fill_nan_value\n",
    "            rmse_value = torch.sqrt(torch.mean((labels[:, task_idx][valid_mask] - preds[:, task_idx][valid_mask]) ** 2))\n",
    "            task_rmse.append(rmse_value.item())\n",
    "\n",
    "        if record:\n",
    "            if labels.shape[0] < 10000:\n",
    "                log_folds_records['valid'][-1].append(task_rmse)\n",
    "            else:\n",
    "                log_folds_records['train'][-1].append(task_rmse)\n",
    "\n",
    "        return 'rmse_km', task_rmse[0], False\n",
    "\n",
    "    temp_params = deepcopy(params)\n",
    "    temp_params.update({\"verbosity\": -1, \"objective\": \"custom\", \"num_labels\": num_tasks, \"tree_learner\": 'serial2', \"num_threads\": num_threads})\n",
    "    num_iterations = temp_params.pop(\"num_iterations\")\n",
    "    task_scores_dict = {task_name: {'val': {name: [] for name in score_names}, 'test': {name: [] for name in score_names}} for task_name in task_names}\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_x), start=1):\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        # split dataset\n",
    "        train_x, val_x = train_val_x[train_index], train_val_x[val_index]\n",
    "        train_y, val_y = train_val_y[train_index], train_val_y[val_index]\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # get the best epoch number\n",
    "        evals_result_mt = {}\n",
    "        record = True\n",
    "        log_folds_records['train'].append([])\n",
    "        log_folds_records['valid'].append([])\n",
    "        lgb.train(temp_params, train_data, num_iterations, valid_sets=[train_data, val_data],\n",
    "                  fobj=cal_grad, feval=self_km_rmse, verbose_eval=300, evals_result=evals_result_mt,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500)])\n",
    "\n",
    "        # train_records = evals_result_mt['training']['rmse_km']\n",
    "        valid_records = evals_result_mt['valid_1']['rmse_km']\n",
    "        min_index = np.argmin(np.array(valid_records))\n",
    "        print(f\"valid_records min_index {min_index}\")\n",
    "\n",
    "        # train model for all scores of validation and test\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "        evals_result_mt = {}\n",
    "        record = False\n",
    "        model = lgb.train(temp_params, train_data, min_index + 1, valid_sets=[val_data],\n",
    "                          fobj=cal_grad, feval=self_km_rmse, verbose_eval=1000,\n",
    "                          evals_result=evals_result_mt)\n",
    "        model.set_num_labels(num_tasks)\n",
    "\n",
    "        # validation predict\n",
    "        val_predicted = model.predict(val_x)\n",
    "        val_scores = {task_name: return_scores(val_y[:, idx], val_predicted[:, idx]) for idx, task_name in\n",
    "                      enumerate(task_names)}\n",
    "\n",
    "        # test predict\n",
    "        test_predicted = model.predict(test_x)\n",
    "        test_pred_list.append(test_predicted)\n",
    "        test_scores = {task_name: return_scores(test_y[:, idx], test_predicted[:, idx]) for idx, task_name in\n",
    "                       enumerate(task_names)}\n",
    "\n",
    "        # record\n",
    "        for task_name in task_names:\n",
    "            for score_idx, score_name in enumerate(score_names):\n",
    "                task_scores_dict[task_name]['val'][score_name].append(val_scores[task_name][score_idx])\n",
    "                task_scores_dict[task_name]['test'][score_name].append(test_scores[task_name][score_idx])\n",
    "        print(f\"Val  {val_scores} \\n Test {test_scores}\\n\")\n",
    "\n",
    "    print_scores(task_scores_dict)\n",
    "\n",
    "\n",
    "# init seed\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "# config\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'mtgbm_km_kcat_kcatkm'\n",
    "dataset_path = f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl'\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "num_threads = 32\n",
    "search_max_evals = 60\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is {device}\")\n",
    "\n",
    "# input\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "task_names = ['logkm', 'logkcat', 'logkcatkm']\n",
    "num_tasks = len(task_names)\n",
    "df_input = pd.read_pickle(dataset_path)\n",
    "df_input['logkm'] = -df_input['logkm']\n",
    "fill_nan_value = -100\n",
    "df_input = df_input.fillna(fill_nan_value)\n",
    "\n",
    "# split dataset\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "train_val_x, train_val_y = return_mtgbm_x_y(df_train_val, task_names)\n",
    "test_x, test_y = return_mtgbm_x_y(df_test, task_names)\n",
    "\n",
    "with open(f'{current_dir}/../../kcatkm_mtgbm_ablation/{input_model}_params.json', 'r') as json_file:\n",
    "    best_params = json.load(json_file)\n",
    "\n",
    "print('best_params:', best_params)\n",
    "print('using -km kcat kcatkm resample')\n",
    "test_pred_list = []\n",
    "log_folds_records = {'train':[], 'valid':[]}\n",
    "record = True\n",
    "train_mtgbm(best_params)\n",
    "np.save(f'{current_dir}/results/dynomtgbm_test_pred.npy', np.array(test_pred_list))\n",
    "np.save(f'{current_dir}/results/dynomtgbm_test_y.npy', np.array(test_y))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(log_folds_records).to_pickle(f'./results/{input_model}_log_folds_records.pkl')",
   "id": "5b2b290754fe6070",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test = pd.read_pickle(f'./results/{input_model}_log_folds_records.pkl')\n",
    "test.head()"
   ],
   "id": "9dcf6e53a0f2407a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.array(test['train'][0]).shape\n",
    "np.array(test['valid'][0])[-1, -1]"
   ],
   "id": "35664daa9fab8764",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot Loss",
   "id": "d352b74995414f5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc(\"font\", weight=\"bold\")\n",
    "\n",
    "train_losses, val_losses = log_folds_records['train'], log_folds_records['valid']\n",
    "for fold_idx in range(5):\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    epochs = range(1, len(train_losses[fold_idx]) + 1)\n",
    "    train_loss = np.array(train_losses[fold_idx])\n",
    "    val_loss = np.array(val_losses[fold_idx])\n",
    "    for name_idx, name in enumerate(['-logKm', 'logkcat', 'log(kcat/Km)']):\n",
    "        plt.plot(epochs, train_loss[:, name_idx], label=f'Train {name} Loss')\n",
    "        plt.plot(epochs, val_loss[:, name_idx], label=f'Val {name} Loss', linestyle='--')\n",
    "\n",
    "    plt.xlabel('$Epoch$', fontsize=12)\n",
    "    plt.ylabel('$Loss$', fontsize=12)\n",
    "    # plt.title(f'Training and Validation Loss per Epoch Cross Validation {fold_idx}')\n",
    "    plt.legend()\n",
    "    plt.savefig(current_dir + f'/results/{input_model}_loss_plot_cv{fold_idx}.png')  # 保存图表为图片文件\n",
    "    plt.show()"
   ],
   "id": "27e7088933c4eab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate the mean value of predicted log(kcat) of 5 folds on test dataset",
   "id": "820d8ddc4345a2d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "fill_nan_value = -100\n",
    "test_pred_list = np.load(f'{current_dir}/results/dynomtgbm_test_pred.npy')\n",
    "test_pred_npy = np.array([np.array(_) for _ in test_pred_list])\n",
    "logkm_pred_mean = test_pred_npy[:, :, 0].mean(axis=0)\n",
    "\n",
    "test_label_list = np.load(f'{current_dir}/results/dynomtgbm_test_y.npy')\n",
    "logkm_test_y = test_label_list[:, 0]\n",
    "\n",
    "# get real logkm\n",
    "logkm_test_y = -logkm_test_y\n",
    "logkm_pred_mean = -logkm_pred_mean\n",
    "\n",
    "logkm_scores = return_scores(logkm_test_y, logkm_pred_mean)\n",
    "logkm_scores"
   ],
   "id": "e46ee55adc80b2f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, gaussian_kde\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "matplotlib.rc(\"font\", weight=\"bold\")\n",
    "\n",
    "# 过滤掉填充值\n",
    "mask = logkm_test_y != fill_nan_value\n",
    "logkm_test_y = logkm_test_y[mask]\n",
    "logkm_pred_mean = logkm_pred_mean[mask]\n",
    "n = len(logkm_test_y)\n",
    "\n",
    "# 计算密度\n",
    "xy = np.vstack([logkm_test_y, logkm_pred_mean])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sc = ax.scatter(\n",
    "    logkm_test_y,\n",
    "    logkm_pred_mean,\n",
    "    c=z,\n",
    "    s=20,\n",
    "    cmap='viridis',\n",
    "    linewidths=0\n",
    ")\n",
    "\n",
    "# 在图内底部居中插入一个横向 colorbar\n",
    "cax = inset_axes(\n",
    "    ax,\n",
    "    width=\"60%\",        # 控制宽度百分比\n",
    "    height=\"4%\",        # 控制高度\n",
    "    loc='lower center', # 放在图的内部底部中间\n",
    "    bbox_to_anchor=(0.5, 0.02, 0.5, 1),  # 精细控制位置偏移（可选）\n",
    "    bbox_transform=ax.transAxes,\n",
    "    borderpad=2\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, cax=cax, orientation='horizontal')\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.set_label('Density', fontsize=11, labelpad=6)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "\n",
    "ax.set_xlabel(r'$log_{10}(K_m)$ $experimental$ $value$', fontsize=18)\n",
    "ax.set_ylabel(r'$log_{10}(K_m)$ $predicted$ $value$', fontsize=18)\n",
    "ax.text(\n",
    "    0.05, 0.95,\n",
    "    f'DynoMTGBM\\n\\nPCC = {logkm_scores[-1]:.2f}\\n$R^2$ = {logkm_scores[-2]:.2f}\\nN = {n}',\n",
    "    transform=ax.transAxes,\n",
    "    bbox=dict(facecolor='white', edgecolor='lightgray', alpha=0.9),\n",
    "    fontsize=16,\n",
    "    verticalalignment='top'\n",
    ")\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{current_dir}/results/dynomtgbm_scatter.png')\n",
    "plt.show()"
   ],
   "id": "9aeb780169f4cecd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "391ae7a9a517ea640120dfb04776679e361e6af223196de029c77b4062e2a450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
