{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UniKP (logkcat)",
   "id": "2d315f2f1a3d0dfa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"Refer and revise from UniKP https://github.com/Luo-SynBioLab/UniKP with gpl-3.0\"\"\"\n",
    "import os, math\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "current_dir = os.getcwd()\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def return_scores(y_test, y_pred):\n",
    "    # 移除 NaN 值\n",
    "    mask = ~np.isnan(y_test)\n",
    "    y_test_filtered = y_test[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    # scores\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_filtered, y_pred_filtered))\n",
    "    mae = mean_absolute_error(y_test_filtered, y_pred_filtered)\n",
    "    r2 = r2_score(y_test_filtered, y_pred_filtered)\n",
    "    pcc = pearsonr(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "    return rmse, mae, r2, pcc[0]\n",
    "\n",
    "\n",
    "def return_x_y(df_filtered):\n",
    "    y = df_filtered[label_name].values\n",
    "    mask = ~np.isnan(y)\n",
    "\n",
    "    # factors\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_filtered['ph'].values.reshape(-1, 1)\n",
    "        t = df_filtered['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_filtered['mw'].values.reshape(-1, 1)\n",
    "        logp = df_filtered['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_filtered[protein_column].tolist())\n",
    "    substrate_data = np.array(df_filtered[substrate_column].tolist())\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def Smooth_Label(Label_new):\n",
    "    labels = Label_new\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = labels[i] - min(labels)\n",
    "    bin_index_per_label = [int(label*10) for label in labels]\n",
    "    # print(bin_index_per_label)\n",
    "    Nb = max(bin_index_per_label) + 1\n",
    "    print(Nb)\n",
    "    num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
    "    print(num_samples_of_bins)\n",
    "    emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
    "    print(emp_label_dist, len(emp_label_dist))\n",
    "    eff_label_dist = []\n",
    "    beta = 0.9\n",
    "    for i in range(len(emp_label_dist)):\n",
    "        eff_label_dist.append((1-math.pow(beta, emp_label_dist[i])) / (1-beta))\n",
    "    print(eff_label_dist)\n",
    "    eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
    "    weights = [np.float32(1 / x) for x in eff_num_per_label]\n",
    "    weights = np.array(weights)\n",
    "    print(weights)\n",
    "    print(len(weights))\n",
    "    return weights\n",
    "\n",
    "\n",
    "print('Reading data...', end='')\n",
    "df_input = pd.read_pickle(f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl')\n",
    "print('Finished.')\n",
    "\n",
    "# TODO Split dataset\n",
    "label_name = 'logkcat'\n",
    "use_t_ph_embedding, use_mw_logp = True, True\n",
    "protein_column, substrate_column = 'prott5', 'molebert'\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "\n",
    "train_val_idx, test_idx = train_test_split(df_input.index, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "test_x, test_y = return_x_y(df_input.loc[test_idx])\n",
    "\n",
    "val_scores_list = []\n",
    "test_scores_list = []\n",
    "test_pred_list = []\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_idx), start=1):\n",
    "    print(f\"Fold: {fold_idx}/5\")\n",
    "    fold_train_idx, fold_val_idx = train_val_idx[train_index], train_val_idx[val_index]\n",
    "    train_x, train_y = return_x_y(df_input.loc[fold_train_idx])\n",
    "    val_x, val_y = return_x_y(df_input.loc[fold_val_idx])\n",
    "\n",
    "    model = ExtraTreesRegressor(n_jobs=-1)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    val_pred = model.predict(val_x)\n",
    "    val_scores = return_scores(val_y, val_pred)\n",
    "    test_pred = model.predict(test_x)\n",
    "    test_pred_list.append(test_pred)\n",
    "    test_scores = return_scores(test_y, test_pred)\n",
    "\n",
    "    val_scores_list.append(val_scores)\n",
    "    test_scores_list.append(test_scores)\n",
    "    print(f'Val  fold{fold_idx} ', val_scores)\n",
    "    print(f'Test fold{fold_idx} ', test_scores)\n",
    "\n",
    "val_scores_mean = np.mean(val_scores_list, axis=0)\n",
    "test_scores_mean = np.mean(test_scores_list, axis=0)\n",
    "\n",
    "np.save(f'{current_dir}/results/unikp_test_pred.npy', np.array(test_pred_list))\n",
    "np.save(f'{current_dir}/results/unikp_test_y.npy', np.array(test_y))\n",
    "\n",
    "print(f\"UniKP with CBW\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "print(f\"Val_mean \\t {val_scores_mean[0]:.4f} \\t {val_scores_mean[1]:.4f} \\t {val_scores_mean[2]:.4f} \\t {val_scores_mean[3]:.4f}\\n\"\n",
    "      f\"Test_mean \\t {test_scores_mean[0]:.4f} \\t {test_scores_mean[1]:.4f} \\t {test_scores_mean[2]:.4f} \\t {test_scores_mean[3]:.4f}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate the mean value of predicted logkcat of 5 folds on test dataset",
   "id": "a63e492d6faed588"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def return_scores(y_test, y_pred):\n",
    "    # 移除 NaN 值\n",
    "    mask = ~np.isnan(y_test)\n",
    "    y_test_filtered = y_test[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    # scores\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_filtered, y_pred_filtered))\n",
    "    mae = mean_absolute_error(y_test_filtered, y_pred_filtered)\n",
    "    r2 = r2_score(y_test_filtered, y_pred_filtered)\n",
    "    pcc = pearsonr(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "    return rmse, mae, r2, pcc[0]\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "test_pred_list = np.load(f'{current_dir}/results/unikp_test_pred.npy')\n",
    "test_pred_npy = np.array([np.array(_) for _ in test_pred_list])\n",
    "logkcat_pred_mean = test_pred_npy.mean(axis=0)\n",
    "\n",
    "logkcat_test_y = np.load(f'{current_dir}/results/unikp_test_y.npy')\n",
    "logkcat_scores = return_scores(logkcat_test_y, logkcat_pred_mean)\n",
    "logkcat_scores"
   ],
   "id": "57489b3890256bd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, gaussian_kde\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "matplotlib.rc(\"font\", weight=\"bold\")\n",
    "\n",
    "# 过滤掉填充值\n",
    "mask = ~np.isnan(logkcat_test_y)\n",
    "logkcat_test_y = logkcat_test_y[mask]\n",
    "logkcat_pred_mean = logkcat_pred_mean[mask]\n",
    "n = len(logkcat_test_y)\n",
    "\n",
    "# 计算密度\n",
    "xy = np.vstack([logkcat_test_y, logkcat_pred_mean])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sc = ax.scatter(\n",
    "    logkcat_test_y,\n",
    "    logkcat_pred_mean,\n",
    "    c=z,\n",
    "    s=20,\n",
    "    cmap='viridis',\n",
    "    linewidths=0\n",
    ")\n",
    "\n",
    "# 在图内底部居中插入一个横向 colorbar\n",
    "cax = inset_axes(\n",
    "    ax,\n",
    "    width=\"60%\",        # 控制宽度百分比\n",
    "    height=\"4%\",        # 控制高度\n",
    "    loc='lower center', # 放在图的内部底部中间\n",
    "    bbox_to_anchor=(0.5, 0.02, 0.5, 1),  # 精细控制位置偏移（可选）\n",
    "    bbox_transform=ax.transAxes,\n",
    "    borderpad=2\n",
    ")\n",
    "\n",
    "cb = plt.colorbar(sc, cax=cax, orientation='horizontal')\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "cb.set_label('Density', fontsize=11, labelpad=6)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "\n",
    "ax.set_xlabel(r'$log_{10}(k_{cat})$ $experimental$ $value$', fontsize=18)\n",
    "ax.set_ylabel(r'$log_{10}(k_{cat})$ $predicted$ $value$', fontsize=18)\n",
    "ax.text(\n",
    "    0.05, 0.95,\n",
    "    f'UniKP\\n\\nPCC = {logkcat_scores[-1]:.2f}\\n$R^2$ = {logkcat_scores[-2]:.2f}\\nN = {n}',\n",
    "    transform=ax.transAxes,\n",
    "    bbox=dict(facecolor='white', edgecolor='lightgray', alpha=0.9),\n",
    "    fontsize=16,\n",
    "    verticalalignment='top'\n",
    ")\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{current_dir}/results/unikp_scatter.png')\n",
    "plt.show()"
   ],
   "id": "d73f1a508b130184",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check the data in folds",
   "id": "c00946c4a4884d1f"
  },
  {
   "cell_type": "code",
   "id": "d422f8f00b2d0ba7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import numpy as np\n",
    "random_state = 66\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "df_input = pd.read_pickle(f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl')\n",
    "train_val_idx, test_idx = train_test_split(df_input.index, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_idx), start=1):\n",
    "    print(f\"Fold: {fold_idx}/5\")\n",
    "    fold_train_idx, fold_val_idx = train_val_idx[train_index], train_val_idx[val_index]\n",
    "    break\n",
    "\n",
    "df_input.loc[fold_train_idx].head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8812310eac0ea415",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "391ae7a9a517ea640120dfb04776679e361e6af223196de029c77b4062e2a450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
