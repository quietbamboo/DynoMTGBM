{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1f96913c6945c4",
   "metadata": {},
   "source": [
    "# MTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/miniconda/envs/DynoMTGBM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cuda:0\n",
      "best_params: {'bagging_fraction': 0.729611058732434, 'feature_fraction': 0.6643005188332146, 'lambda_l1': 0.346846951564011, 'lambda_l2': 0.7149783548509333, 'learning_rate': 0.07838547411322133, 'max_bin': 95, 'max_depth': 9, 'min_data_in_leaf': 21, 'num_iterations': 3273, 'num_leaves': 2350}\n",
      "using km kcat kcatkm resample\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.77608\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.72049\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.7113\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3067]\tvalid_0's rmse_kcatkm: 2.71085\n",
      "valid_records min_index 3066\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.77608\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.72049\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.7113\n",
      "inner_predict 22338\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.960829596974407, 1.333386586353164, 0.5623167167157751, 0.7647984103844179), 'logkcat': (2.120953741138861, 1.4409126728824737, 0.630103365200489, 0.7943291451174239), 'logkcatkm': (2.7108466750438085, 1.9320707801968813, 0.5874934647888155, 0.766893351435967)} \n",
      " Test {'logkm': (1.9705444717666463, 1.3380112136510722, 0.5678173650646879, 0.7679542161652702), 'logkcat': (2.202207107168449, 1.4939251249769312, 0.6242038358006796, 0.7905195089632784), 'logkcatkm': (2.7169284656064483, 1.9470466364429384, 0.5665341602598961, 0.753505531351328)}\n",
      "\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.6673\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.62452\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.61994\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2930]\tvalid_0's rmse_kcatkm: 2.61963\n",
      "valid_records min_index 2929\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.6673\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.62452\n",
      "inner_predict 22338\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.9826513943138198, 1.3442523839588305, 0.5727557925576265, 0.7691901387371907), 'logkcat': (2.0672898482963924, 1.4147258769519544, 0.6449699191233804, 0.8039905629269902), 'logkcatkm': (2.619630224979079, 1.88803561442266, 0.6036895545910181, 0.7781893698655349)} \n",
      " Test {'logkm': (1.9443963166532199, 1.3399183316330092, 0.5792109680531901, 0.7735514108119672), 'logkcat': (2.1953372911229354, 1.4932648594034432, 0.6265447816297219, 0.792083163500381), 'logkcatkm': (2.71001506833619, 1.9388306543507141, 0.5687373164466039, 0.7549991430311371)}\n",
      "\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.64288\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.58557\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.57493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3227]\tvalid_0's rmse_kcatkm: 2.57446\n",
      "valid_records min_index 3226\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.64288\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.58557\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.57493\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.9525613538358502, 1.3435464517954145, 0.5647208019330419, 0.7645396360991479), 'logkcat': (2.1449818312741087, 1.468137821356425, 0.627588121757706, 0.7934366113847888), 'logkcatkm': (2.574458960180937, 1.8397205011949613, 0.6076340232213546, 0.7800161095024507)} \n",
      " Test {'logkm': (1.9864405462244992, 1.3506806802205071, 0.5608165416057582, 0.7637643687588338), 'logkcat': (2.164133805227753, 1.4792873411647904, 0.637085566252555, 0.7986210452979683), 'logkcatkm': (2.680503631735103, 1.9127914679462599, 0.5780788758076867, 0.761145581734141)}\n",
      "\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.72947\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.68155\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.66635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3159]\tvalid_0's rmse_kcatkm: 2.66531\n",
      "valid_records min_index 3158\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.72947\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.68155\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.66635\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.8724608732255388, 1.3091713051470186, 0.6057033821699824, 0.7856239227074779), 'logkcat': (2.021941736371484, 1.4119074425671883, 0.6542917333698479, 0.8097104324169533), 'logkcatkm': (2.665308153797887, 1.9330820538499491, 0.5797510275568538, 0.7617933451307874)} \n",
      " Test {'logkm': (1.9554510505234404, 1.3357951965814585, 0.5744126311942535, 0.7719058630901416), 'logkcat': (2.176516897483859, 1.4920091885417224, 0.632920518637547, 0.7960355969892808), 'logkcatkm': (2.7088930363475607, 1.9350309869292595, 0.5690943553126286, 0.7554748211480518)}\n",
      "\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.7055\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.65761\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.64954\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3091]\tvalid_0's rmse_kcatkm: 2.64909\n",
      "valid_records min_index 3090\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.7055\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.65761\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.64954\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.95369896969073, 1.349010935082262, 0.5644039304428798, 0.7679640305462323), 'logkcat': (2.101790980373198, 1.439217700344545, 0.6524600150602727, 0.8088379219793888), 'logkcatkm': (2.649094470213429, 1.8815401905727067, 0.5968621432431322, 0.7738026550363996)} \n",
      " Test {'logkm': (1.9328417218658829, 1.3394468225847176, 0.5841971947113687, 0.7764172475812399), 'logkcat': (2.182376598033365, 1.4791686486071582, 0.6309413276557376, 0.7946647760683184), 'logkcatkm': (2.6781643649153555, 1.9248702821048298, 0.5788149728641626, 0.7612359998373189)}\n",
      "\n",
      "logkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  1.9444\t 1.3359\t 0.5740\t 0.7704\t\n",
      "Test 1.9579\t 1.3408\t 0.5733\t 0.7707\t\n",
      "logkcat\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.0914\t 1.4350\t 0.6419\t 0.8021\t\n",
      "Test 2.1841\t 1.4875\t 0.6303\t 0.7944\t\n",
      "logkcatkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.6439\t 1.8949\t 0.5951\t 0.7721\t\n",
      "Test 2.6989\t 1.9317\t 0.5723\t 0.7573\t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import lightgbmmt as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "def return_mtgbm_x_y(df_data, tasks):\n",
    "    y = np.array(df_data[tasks].values)\n",
    "\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_data['ph'].values.reshape(-1, 1)\n",
    "        t = df_data['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_data['mw'].values.reshape(-1, 1)\n",
    "        logp = df_data['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_data[protein_column].tolist())\n",
    "    substrate_data = np.array(df_data[substrate_column].tolist())\n",
    "\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "    return x, y\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "def print_scores(task_scores_dict):\n",
    "    for task_name in task_names:\n",
    "        print(f\"{task_name}\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "\n",
    "        task_val_scores = task_scores_dict[task_name]['val']\n",
    "        task_test_scores = task_scores_dict[task_name]['test']\n",
    "\n",
    "        val_metrics = [f\"{np.mean(task_val_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                       score_names]\n",
    "        print(\"Val  \" + \" \".join(val_metrics))\n",
    "\n",
    "        test_metrics = [f\"{np.mean(task_test_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                        score_names]\n",
    "        print(\"Test \" + \" \".join(test_metrics))\n",
    "\n",
    "def pcgrad(gradients):\n",
    "    adjusted_gradients = gradients.clone()\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        g_i = adjusted_gradients[:, i]\n",
    "        for j in range(num_tasks):\n",
    "            if i != j:  # 跳过与自身的比较\n",
    "                g_j = adjusted_gradients[:, j]\n",
    "\n",
    "                # 计算点积并检测冲突\n",
    "                dot_product = torch.dot(g_i, g_j)\n",
    "                if dot_product < 0:  # 仅在点积为负时调整\n",
    "                    projection = (dot_product / (torch.norm(g_j) ** 2 + 1e-8)) * g_j\n",
    "                    g_i -= projection  # 对 g_i 进行投影调整\n",
    "\n",
    "        # 更新调整后的梯度\n",
    "        adjusted_gradients[:, i] = g_i\n",
    "\n",
    "    # final_gradient = adjusted_gradients.mean(dim=1)  # 对任务维度求平均\n",
    "    return adjusted_gradients\n",
    "\n",
    "def self_kcatkm_rmse(preds, train_data):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "\n",
    "    # extract kcatkm values\n",
    "    labels = labels.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "    preds = preds.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    valid_labels = labels[valid_mask]\n",
    "    valid_preds = preds[valid_mask]\n",
    "\n",
    "    kcatkm_rmse = torch.sqrt(torch.mean((valid_labels - valid_preds) ** 2))\n",
    "\n",
    "    return 'rmse_kcatkm', kcatkm_rmse.item(), False\n",
    "\n",
    "def cal_grad(preds, train_data, ep=0):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "    labels = labels.view(num_tasks, -1).T\n",
    "    preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    grad = torch.zeros_like(preds)\n",
    "    grad[valid_mask] = preds[valid_mask] - labels[valid_mask]\n",
    "\n",
    "    # project\n",
    "    grad = pcgrad(grad)\n",
    "\n",
    "    # sum\n",
    "    grad_final = grad.mean(dim=1)\n",
    "\n",
    "    # Hessian\n",
    "    grad_flattened = grad.T.flatten()\n",
    "    hess = torch.ones_like(grad_final)\n",
    "    hess2 = torch.ones_like(grad_flattened)\n",
    "\n",
    "    return grad_final.cpu().numpy(), hess.cpu().numpy(), grad_flattened.cpu().numpy(), hess2.cpu().numpy()\n",
    "\n",
    "# TODO Train model\n",
    "def train_mtgbm(params):\n",
    "    temp_params = deepcopy(params)\n",
    "    temp_params.update({\"verbosity\": -1, \"objective\": \"custom\", \"num_labels\": num_tasks, \"tree_learner\": 'serial2', \"num_threads\": num_threads})\n",
    "    num_iterations = temp_params.pop(\"num_iterations\")\n",
    "\n",
    "    task_scores_dict = {task_name: {'val': {name: [] for name in score_names}, 'test': {name: [] for name in score_names}} for task_name in task_names}\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_x), start=1):\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        # split dataset\n",
    "        train_x, val_x = train_val_x[train_index], train_val_x[val_index]\n",
    "        train_y, val_y = train_val_y[train_index], train_val_y[val_index]\n",
    "\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # get the best epoch number\n",
    "        evals_result_mt = {}\n",
    "        lgb.train(temp_params, train_data, num_iterations, valid_sets=[val_data],\n",
    "                  fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000, evals_result=evals_result_mt,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500)])\n",
    "        valid_records = evals_result_mt['valid_0']['rmse_kcatkm']\n",
    "        min_index = np.argmin(np.array(valid_records))\n",
    "        print(f\"valid_records min_index {min_index}\")\n",
    "\n",
    "        # train model for all scores of validation and test\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "        evals_result_mt = {}\n",
    "        model = lgb.train(temp_params, train_data, min_index + 1, valid_sets=[val_data],\n",
    "                          fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000,\n",
    "                          evals_result=evals_result_mt)\n",
    "        model.set_num_labels(num_tasks)\n",
    "\n",
    "        # validation predict\n",
    "        val_predicted = model.predict(val_x)\n",
    "        val_scores = {task_name: return_scores(val_y[:, idx], val_predicted[:, idx]) for idx, task_name in\n",
    "                      enumerate(task_names)}\n",
    "\n",
    "        # test predict\n",
    "        test_predicted = model.predict(test_x)\n",
    "        test_scores = {task_name: return_scores(test_y[:, idx], test_predicted[:, idx]) for idx, task_name in\n",
    "                       enumerate(task_names)}\n",
    "\n",
    "        # record\n",
    "        for task_name in task_names:\n",
    "            for score_idx, score_name in enumerate(score_names):\n",
    "                task_scores_dict[task_name]['val'][score_name].append(val_scores[task_name][score_idx])\n",
    "                task_scores_dict[task_name]['test'][score_name].append(test_scores[task_name][score_idx])\n",
    "        print(f\"Val  {val_scores} \\n Test {test_scores}\\n\")\n",
    "\n",
    "    print_scores(task_scores_dict)\n",
    "\n",
    "\n",
    "# init seed\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "# config\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'mtgbm_km_kcat_kcatkm'\n",
    "dataset_path = f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl'\n",
    "params_json_path = f'{current_dir}/../{input_model}_params.json'\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "num_threads = 32\n",
    "search_max_evals = 60\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is {device}\")\n",
    "\n",
    "# input\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "task_names = ['logkm', 'logkcat', 'logkcatkm']\n",
    "num_tasks = len(task_names)\n",
    "df_input = pd.read_pickle(dataset_path)\n",
    "fill_nan_value = -100\n",
    "df_input = df_input.fillna(fill_nan_value)\n",
    "\n",
    "# split dataset\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "train_val_x, train_val_y = return_mtgbm_x_y(df_train_val, task_names)\n",
    "test_x, test_y = return_mtgbm_x_y(df_test, task_names)\n",
    "\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path, 'r') as json_file:\n",
    "        best_params = json.load(json_file)\n",
    "\n",
    "    print('best_params:', best_params)\n",
    "    print('using km kcat kcatkm resample')\n",
    "    train_mtgbm(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynoMTGBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db0e6cebfd42dbe7de32cf1b0daf517db5c30eda4a99fad3eb7c5d8b4a7bde0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
