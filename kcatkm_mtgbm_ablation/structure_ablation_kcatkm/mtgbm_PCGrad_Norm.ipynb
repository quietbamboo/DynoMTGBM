{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T09:19:09.054129Z",
     "start_time": "2025-03-28T08:43:41.507647Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import lightgbmmt as lgb\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "def return_mtgbm_x_y(df_data, tasks):\n",
    "    y = np.array(df_data[tasks].values)\n",
    "\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_data['ph'].values.reshape(-1, 1)\n",
    "        t = df_data['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_data['mw'].values.reshape(-1, 1)\n",
    "        logp = df_data['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_data[protein_column].tolist())\n",
    "    substrate_data = np.array(df_data[substrate_column].tolist())\n",
    "\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "    return x, y\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "def print_scores(task_scores_dict):\n",
    "    for task_name in task_names:\n",
    "        print(f\"{task_name}\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "\n",
    "        task_val_scores = task_scores_dict[task_name]['val']\n",
    "        task_test_scores = task_scores_dict[task_name]['test']\n",
    "\n",
    "        val_metrics = [f\"{np.mean(task_val_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                       score_names]\n",
    "        print(\"Val  \" + \" \".join(val_metrics))\n",
    "\n",
    "        test_metrics = [f\"{np.mean(task_test_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                        score_names]\n",
    "        print(\"Test \" + \" \".join(test_metrics))\n",
    "\n",
    "def self_kcatkm_rmse(preds, train_data):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "\n",
    "    # extract kcatkm values\n",
    "    labels = labels.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "    preds = preds.view(num_tasks, -1).T[:, num_tasks - 1]\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    valid_labels = labels[valid_mask]\n",
    "    valid_preds = preds[valid_mask]\n",
    "\n",
    "    kcatkm_rmse = torch.sqrt(torch.mean((valid_labels - valid_preds) ** 2))\n",
    "\n",
    "    return 'rmse_kcatkm', kcatkm_rmse.item(), False\n",
    "\n",
    "def pcgrad(gradients):\n",
    "    adjusted_gradients = gradients.clone()\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        g_i = adjusted_gradients[:, i]\n",
    "        for j in range(num_tasks):\n",
    "            if i != j:  # 跳过与自身的比较\n",
    "                g_j = adjusted_gradients[:, j]\n",
    "\n",
    "                # 计算点积并检测冲突\n",
    "                dot_product = torch.dot(g_i, g_j)\n",
    "                if dot_product < 0:  # 仅在点积为负时调整\n",
    "                    projection = (dot_product / (torch.norm(g_j) ** 2 + 1e-8)) * g_j\n",
    "                    g_i -= projection  # 对 g_i 进行投影调整\n",
    "\n",
    "        # 更新调整后的梯度\n",
    "        adjusted_gradients[:, i] = g_i\n",
    "\n",
    "    return adjusted_gradients\n",
    "\n",
    "def cal_grad(preds, train_data, ep=0):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "    labels = labels.view(num_tasks, -1).T\n",
    "    preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    grad = torch.zeros_like(preds)\n",
    "    grad[valid_mask] = preds[valid_mask] - labels[valid_mask]\n",
    "\n",
    "    # project\n",
    "    grad = pcgrad(grad)\n",
    "\n",
    "    # grad norm\n",
    "    grad_norms = torch.norm(grad, dim=0)\n",
    "    avg_grad_norm = grad_norms.mean()\n",
    "    grad_ratio = grad_norms / avg_grad_norm\n",
    "    grad_by_ratio = grad * grad_ratio\n",
    "    grad_final = grad_by_ratio.sum(dim=1)\n",
    "\n",
    "    # Hessian\n",
    "    grad_flattened = grad.T.flatten()\n",
    "    hess = torch.ones_like(grad_final)\n",
    "    hess2 = torch.ones_like(grad_flattened)\n",
    "\n",
    "    return grad_final.cpu().numpy(), hess.cpu().numpy(), grad_flattened.cpu().numpy(), hess2.cpu().numpy()\n",
    "\n",
    "# TODO Train model\n",
    "def train_mtgbm(params):\n",
    "    temp_params = deepcopy(params)\n",
    "    temp_params.update({\"verbosity\": -1, \"objective\": \"custom\", \"num_labels\": num_tasks, \"tree_learner\": 'serial2', \"num_threads\": num_threads})\n",
    "    num_iterations = temp_params.pop(\"num_iterations\")\n",
    "\n",
    "    task_scores_dict = {task_name: {'val': {name: [] for name in score_names}, 'test': {name: [] for name in score_names}} for task_name in task_names}\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_x), start=1):\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        # split dataset\n",
    "        train_x, val_x = train_val_x[train_index], train_val_x[val_index]\n",
    "        train_y, val_y = train_val_y[train_index], train_val_y[val_index]\n",
    "\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # get the best epoch number\n",
    "        evals_result_mt = {}\n",
    "        lgb.train(temp_params, train_data, num_iterations, valid_sets=[val_data],\n",
    "                  fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000, evals_result=evals_result_mt,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500)])\n",
    "        valid_records = evals_result_mt['valid_0']['rmse_kcatkm']\n",
    "        min_index = np.argmin(np.array(valid_records))\n",
    "        print(f\"valid_records min_index {min_index}\")\n",
    "\n",
    "        # train model for all scores of validation and test\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "        evals_result_mt = {}\n",
    "        model = lgb.train(temp_params, train_data, min_index + 1, valid_sets=[val_data],\n",
    "                          fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000,\n",
    "                          evals_result=evals_result_mt)\n",
    "        model.set_num_labels(num_tasks)\n",
    "\n",
    "        # validation predict\n",
    "        val_predicted = model.predict(val_x)\n",
    "        val_scores = {task_name: return_scores(val_y[:, idx], val_predicted[:, idx]) for idx, task_name in\n",
    "                      enumerate(task_names)}\n",
    "\n",
    "        # test predict\n",
    "        test_predicted = model.predict(test_x)\n",
    "        test_scores = {task_name: return_scores(test_y[:, idx], test_predicted[:, idx]) for idx, task_name in\n",
    "                       enumerate(task_names)}\n",
    "\n",
    "        # record\n",
    "        for task_name in task_names:\n",
    "            for score_idx, score_name in enumerate(score_names):\n",
    "                task_scores_dict[task_name]['val'][score_name].append(val_scores[task_name][score_idx])\n",
    "                task_scores_dict[task_name]['test'][score_name].append(test_scores[task_name][score_idx])\n",
    "        print(f\"Val  {val_scores} \\n Test {test_scores}\\n\")\n",
    "\n",
    "    print_scores(task_scores_dict)\n",
    "\n",
    "\n",
    "# init seed\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "# config\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'mtgbm_km_kcat_kcatkm'\n",
    "dataset_path = f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl'\n",
    "params_json_path = f'{current_dir}/../{input_model}_params.json'\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "num_threads = 32\n",
    "search_max_evals = 60\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is {device}\")\n",
    "\n",
    "# input\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "task_names = ['logkm', 'logkcat', 'logkcatkm']\n",
    "num_tasks = len(task_names)\n",
    "df_input = pd.read_pickle(dataset_path)\n",
    "fill_nan_value = -100\n",
    "df_input = df_input.fillna(fill_nan_value)\n",
    "\n",
    "# split dataset\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "train_val_x, train_val_y = return_mtgbm_x_y(df_train_val, task_names)\n",
    "test_x, test_y = return_mtgbm_x_y(df_test, task_names)\n",
    "\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path, 'r') as json_file:\n",
    "        best_params = json.load(json_file)\n",
    "\n",
    "    print('best_params:', best_params)\n",
    "    print('using km kcat kcatkm resample')\n",
    "    train_mtgbm(best_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cuda:0\n",
      "best_params: {'bagging_fraction': 0.729611058732434, 'feature_fraction': 0.6643005188332146, 'lambda_l1': 0.346846951564011, 'lambda_l2': 0.7149783548509333, 'learning_rate': 0.07838547411322133, 'max_bin': 95, 'max_depth': 9, 'min_data_in_leaf': 21, 'num_iterations': 3273, 'num_leaves': 2350}\n",
      "using km kcat kcatkm resample\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.78763\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.72881\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.71481\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3211]\tvalid_0's rmse_kcatkm: 2.71373\n",
      "valid_records min_index 3210\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.78763\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.72881\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.71481\n",
      "inner_predict 22338\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.9236219485744535, 1.3387879325554193, 0.5787696063136878, 0.7703596921047902), 'logkcat': (2.1213543067875418, 1.4480796558614835, 0.6299636338389192, 0.7940901243524101), 'logkcatkm': (2.713728618707799, 1.9409113549053985, 0.5866159142188203, 0.7662859517466741)} \n",
      " Test {'logkm': (1.9280112623556074, 1.3426327596026255, 0.5862729040659833, 0.7753444297259703), 'logkcat': (2.2081826378370066, 1.510204934000286, 0.6221616771781157, 0.7890849431560413), 'logkcatkm': (2.708499742133502, 1.9550845257596268, 0.569219469440081, 0.7547740359633524)}\n",
      "\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.69372\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.64355\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.63091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3119]\tvalid_0's rmse_kcatkm: 2.62997\n",
      "valid_records min_index 3118\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.69372\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.64355\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.63091\n",
      "inner_predict 22338\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.9763812362646642, 1.366050586400431, 0.5754538490143548, 0.7686876622522489), 'logkcat': (2.069713610265986, 1.4244041533464264, 0.6441369320570733, 0.8031449188006294), 'logkcatkm': (2.629974060012215, 1.9006779755806242, 0.6005536438910002, 0.7759284757462501)} \n",
      " Test {'logkm': (1.9169312860034349, 1.3456662621054996, 0.5910144888460185, 0.7776887387345395), 'logkcat': (2.1860443994277765, 1.4990720511646858, 0.6296997716349917, 0.7938384795382988), 'logkcatkm': (2.7078121700347495, 1.9478806618660642, 0.5694381551379777, 0.7551314006190546)}\n",
      "\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.6637\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.60373\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.58901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3273]\tvalid_0's rmse_kcatkm: 2.58722\n",
      "valid_records min_index 3272\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.6637\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.60373\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.58901\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.94457566542453, 1.3642950146436288, 0.5682739767088618, 0.7637340686389493), 'logkcat': (2.1352184694187524, 1.4673136714754809, 0.6309706370412067, 0.7950189832220347), 'logkcatkm': (2.5872181114806634, 1.861786830236093, 0.6037352137443116, 0.7773066670239013)} \n",
      " Test {'logkm': (1.9577911651709228, 1.3654551234554302, 0.5733934094114903, 0.7681109121853777), 'logkcat': (2.1636233979072617, 1.4892541972882452, 0.6372567315840736, 0.7985254482618174), 'logkcatkm': (2.688658066803168, 1.9308576391460448, 0.5755078950157722, 0.7590924782019712)}\n",
      "\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.7258\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.67178\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.65284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3254]\tvalid_0's rmse_kcatkm: 2.6497\n",
      "valid_records min_index 3253\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.7258\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.67178\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.65284\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.8732858735756097, 1.3299746965657329, 0.6053558539365913, 0.7834737451366907), 'logkcat': (2.0241144212289535, 1.420994265916062, 0.6535483700382221, 0.8089927027783272), 'logkcatkm': (2.6496989944814304, 1.929835483198959, 0.5846589215154658, 0.764658149322958)} \n",
      " Test {'logkm': (1.9362516417589444, 1.3540008618297714, 0.5827287817205642, 0.7733904218013148), 'logkcat': (2.1744728578561143, 1.4968829695627444, 0.6336096680575966, 0.7962826232808543), 'logkcatkm': (2.7095476357096615, 1.9432657114307603, 0.5688860749285111, 0.7547411340217652)}\n",
      "\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.72079\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.67262\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.66187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3273]\tvalid_0's rmse_kcatkm: 2.65928\n",
      "valid_records min_index 3272\n",
      "[1000]\tvalid_0's rmse_kcatkm: 2.72079\n",
      "[2000]\tvalid_0's rmse_kcatkm: 2.67262\n",
      "[3000]\tvalid_0's rmse_kcatkm: 2.66187\n",
      "inner_predict 22335\n",
      "inner_predict 27921\n",
      "Val  {'logkm': (1.9091456452494255, 1.3505855385697225, 0.5840445874575017, 0.7750563314581655), 'logkcat': (2.114641525033013, 1.4539534293882745, 0.6481972399823759, 0.8061045516215851), 'logkcatkm': (2.659282670816988, 1.9021406358060864, 0.5937553099653481, 0.7716235332845488)} \n",
      " Test {'logkm': (1.905705431782627, 1.3489824185384178, 0.5957906311390084, 0.7809097938971522), 'logkcat': (2.189556884618951, 1.4988596611817113, 0.6285088360664821, 0.7929228695381), 'logkcatkm': (2.6898364532365986, 1.9440857063899386, 0.5751357202411556, 0.7584956318181282)}\n",
      "\n",
      "logkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  1.9254\t 1.3499\t 0.5824\t 0.7723\t\n",
      "Test 1.9289\t 1.3513\t 0.5858\t 0.7751\t\n",
      "logkcat\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.0930\t 1.4429\t 0.6414\t 0.8015\t\n",
      "Test 2.1844\t 1.4989\t 0.6302\t 0.7941\t\n",
      "logkcatkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.6480\t 1.9071\t 0.5939\t 0.7712\t\n",
      "Test 2.7009\t 1.9442\t 0.5716\t 0.7564\t\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
