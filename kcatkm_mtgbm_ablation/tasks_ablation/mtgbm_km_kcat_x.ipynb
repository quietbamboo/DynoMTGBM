{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1f96913c6945c4",
   "metadata": {},
   "source": [
    "# MTGBM"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:17:18.022014Z",
     "start_time": "2025-03-29T08:34:49.600064Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import lightgbmmt as lgb\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "def return_mtgbm_x_y(df_data, tasks):\n",
    "    y = np.array(df_data[tasks].values)\n",
    "\n",
    "    auxiliary_data = []\n",
    "    if use_t_ph_embedding:\n",
    "        ph = df_data['ph'].values.reshape(-1, 1)\n",
    "        t = df_data['t'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(ph)\n",
    "        auxiliary_data.append(t)\n",
    "\n",
    "    if use_mw_logp:\n",
    "        mw = df_data['mw'].values.reshape(-1, 1)\n",
    "        logp = df_data['logp'].values.reshape(-1, 1)\n",
    "        auxiliary_data.append(mw)\n",
    "        auxiliary_data.append(logp)\n",
    "\n",
    "    protein_data = np.array(df_data[protein_column].tolist())\n",
    "    substrate_data = np.array(df_data[substrate_column].tolist())\n",
    "\n",
    "    x = np.hstack([protein_data, substrate_data] + auxiliary_data)\n",
    "    return x, y\n",
    "\n",
    "def return_scores(y_true, y_pred):\n",
    "    mask = y_true != fill_nan_value\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "    return rmse, mae, r2, pcc\n",
    "\n",
    "def print_scores(task_scores_dict):\n",
    "    for task_name in task_names:\n",
    "        print(f\"{task_name}\\t RMSE\\t MAE\\t R2\\t PCC\\t\")\n",
    "\n",
    "        task_val_scores = task_scores_dict[task_name]['val']\n",
    "        task_test_scores = task_scores_dict[task_name]['test']\n",
    "\n",
    "        val_metrics = [f\"{np.mean(task_val_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                       score_names]\n",
    "        print(\"Val  \" + \" \".join(val_metrics))\n",
    "\n",
    "        test_metrics = [f\"{np.mean(task_test_scores[metric_name]):.4f}\\t\" for metric_name in\n",
    "                        score_names]\n",
    "        print(\"Test \" + \" \".join(test_metrics))\n",
    "        print()\n",
    "\n",
    "def self_kcatkm_rmse(preds, train_data):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device)\n",
    "    preds = torch.tensor(preds, device=device)\n",
    "\n",
    "    # extract values\n",
    "    labels = labels.view(num_tasks, -1).T\n",
    "    preds = preds.view(num_tasks, -1).T\n",
    "\n",
    "    # km mask\n",
    "    km_label = labels[:, 0]\n",
    "    km_pred = preds[:, 0]\n",
    "    km_valid_mask = km_label != fill_nan_value\n",
    "    km_valid_label = km_label[km_valid_mask]\n",
    "    km_valid_pred = km_pred[km_valid_mask]\n",
    "    km_rmse = torch.sqrt(torch.mean((km_valid_label - km_valid_pred) ** 2))\n",
    "\n",
    "    # kcat mask\n",
    "    kcat_label = labels[:, 1]\n",
    "    kcat_pred = preds[:, 1]\n",
    "    kcat_valid_mask = kcat_label != fill_nan_value\n",
    "    kcat_valid_label = kcat_label[kcat_valid_mask]\n",
    "    kcat_valid_pred = kcat_pred[kcat_valid_mask]\n",
    "    kcat_rmse = torch.sqrt(torch.mean((kcat_valid_label - kcat_valid_pred) ** 2))\n",
    "\n",
    "    return 'rmse_mean', ((km_rmse+kcat_rmse)/2).item(), False\n",
    "\n",
    "\n",
    "def cal_grad(preds, train_data, ep=0):\n",
    "    labels = torch.tensor(train_data.get_label(), device=device).view(num_tasks, -1).T\n",
    "    preds = torch.tensor(preds, device=device).view(num_tasks, -1).T\n",
    "\n",
    "    # mask\n",
    "    valid_mask = labels != fill_nan_value\n",
    "    grad = torch.zeros_like(preds)\n",
    "    grad[valid_mask] = preds[valid_mask] - labels[valid_mask]\n",
    "\n",
    "    # sum  select km kcat\n",
    "    grad_final = grad.mean(dim=1)\n",
    "\n",
    "    # Hessian\n",
    "    grad_flattened = grad.T.flatten()\n",
    "    hess = torch.ones_like(grad_final)\n",
    "    hess2 = torch.ones_like(grad_flattened)\n",
    "\n",
    "    return grad_final.cpu().numpy(), hess.cpu().numpy(), grad_flattened.cpu().numpy(), hess2.cpu().numpy()\n",
    "\n",
    "\n",
    "# TODO Train model\n",
    "def train_mtgbm(params):\n",
    "    temp_params = deepcopy(params)\n",
    "    temp_params.update({\"verbosity\": -1, \"objective\": \"custom\", \"num_labels\": num_tasks, \"tree_learner\": 'serial2', \"num_threads\": num_threads})\n",
    "    num_iterations = temp_params.pop(\"num_iterations\")\n",
    "\n",
    "    task_scores_dict = {task_name: {'val': {name: [] for name in score_names}, 'test': {name: [] for name in score_names}} for task_name in task_names}\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(train_val_x), start=1):\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        # split dataset\n",
    "        train_x, val_x = train_val_x[train_index], train_val_x[val_index]\n",
    "        train_y, val_y = train_val_y[train_index, :2], train_val_y[val_index, :2]\n",
    "        val_y_kcatkm = train_val_y[val_index, 2]\n",
    "\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # get the best epoch number\n",
    "        evals_result_mt = {}\n",
    "        lgb.train(temp_params, train_data, num_iterations, valid_sets=[val_data],\n",
    "                  fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000, evals_result=evals_result_mt,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=500)])\n",
    "        valid_records = evals_result_mt['valid_0']['rmse_mean']\n",
    "        min_index = np.argmin(np.array(valid_records))\n",
    "        print(f\"valid_records min_index {min_index}\")\n",
    "\n",
    "        # train model for all scores of validation and test\n",
    "        train_data = lgb.Dataset(train_x, label=train_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "        evals_result_mt = {}\n",
    "        model = lgb.train(temp_params, train_data, min_index + 1, valid_sets=[val_data],\n",
    "                          fobj=cal_grad, feval=self_kcatkm_rmse, verbose_eval=1000,\n",
    "                          evals_result=evals_result_mt)\n",
    "        model.set_num_labels(num_tasks)\n",
    "\n",
    "        # validation predict\n",
    "        val_predicted = model.predict(val_x)\n",
    "        val_kcatkm_pred = val_predicted[:, 1] - val_predicted[:, 0]\n",
    "        val_scores = {task_name: return_scores(val_y[:, idx], val_predicted[:, idx]) for idx, task_name in enumerate(task_names[:2])}\n",
    "        val_scores['logkcatkm'] = return_scores(val_y_kcatkm, val_kcatkm_pred)\n",
    "\n",
    "        # test predict\n",
    "        test_predicted = model.predict(test_x)\n",
    "        test_kcatkm_pred = test_predicted[:, 1] - test_predicted[:, 0]\n",
    "        test_scores = {task_name: return_scores(test_y[:, idx], test_predicted[:, idx]) for idx, task_name in enumerate(task_names[:2])}\n",
    "        test_scores['logkcatkm'] = return_scores(test_y_kcatkm, test_kcatkm_pred)\n",
    "\n",
    "        # record\n",
    "        for task_name in task_names:\n",
    "            for score_idx, score_name in enumerate(score_names):\n",
    "                task_scores_dict[task_name]['val'][score_name].append(val_scores[task_name][score_idx])\n",
    "                task_scores_dict[task_name]['test'][score_name].append(test_scores[task_name][score_idx])\n",
    "        print(f\"Val  {val_scores} \\n Test {test_scores}\\n\")\n",
    "\n",
    "    print_scores(task_scores_dict)\n",
    "\n",
    "\n",
    "# init seed\n",
    "random_state = 66\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "\n",
    "# config\n",
    "protein_column,  substrate_column = 'prott5', 'molebert'\n",
    "input_model = 'mtgbm_km_kcat_kcatkm'\n",
    "dataset_path = f'{current_dir}/../../data_process/dataset/df_all_log_transformed.pkl'\n",
    "params_json_path = f'{current_dir}/../{input_model}_params.json'\n",
    "use_t_ph_embedding = True\n",
    "use_mw_logp = True\n",
    "num_threads = 32\n",
    "search_max_evals = 60\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is {device}\")\n",
    "\n",
    "# input\n",
    "score_names = ['rmse', 'mae', 'r2', 'pcc']\n",
    "task_names = ['logkm', 'logkcat', 'logkcatkm']\n",
    "num_tasks = len(task_names) - 1\n",
    "df_input = pd.read_pickle(dataset_path)\n",
    "fill_nan_value = -100\n",
    "df_input = df_input.fillna(fill_nan_value)\n",
    "\n",
    "# split dataset\n",
    "df_train_val, df_test = train_test_split(df_input, test_size=0.2, random_state=random_state)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "train_val_x, train_val_y = return_mtgbm_x_y(df_train_val, task_names)\n",
    "test_x, test_y = return_mtgbm_x_y(df_test, task_names)\n",
    "test_y_kcatkm = test_y[:, 2]\n",
    "test_y = test_y[:, :2]\n",
    "\n",
    "if os.path.exists(params_json_path):\n",
    "    with open(params_json_path, 'r') as json_file:\n",
    "        best_params = json.load(json_file)\n",
    "\n",
    "    print('best_params:', best_params)\n",
    "    print('using km kcat resample')\n",
    "    train_mtgbm(best_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cuda:0\n",
      "best_params: {'bagging_fraction': 0.729611058732434, 'feature_fraction': 0.6643005188332146, 'lambda_l1': 0.346846951564011, 'lambda_l2': 0.7149783548509333, 'learning_rate': 0.07838547411322133, 'max_bin': 95, 'max_depth': 9, 'min_data_in_leaf': 21, 'num_iterations': 3273, 'num_leaves': 2350}\n",
      "using km kcat resample\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_mean: 1.97406\n",
      "[2000]\tvalid_0's rmse_mean: 1.94527\n",
      "[3000]\tvalid_0's rmse_mean: 1.93866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3247]\tvalid_0's rmse_mean: 1.93807\n",
      "valid_records min_index 3246\n",
      "[1000]\tvalid_0's rmse_mean: 1.97406\n",
      "[2000]\tvalid_0's rmse_mean: 1.94527\n",
      "[3000]\tvalid_0's rmse_mean: 1.93866\n",
      "inner_predict 14892\n",
      "inner_predict 18614\n",
      "Val  {'logkm': (1.7376440074738337, 1.2201376745207815, 0.6562823242333597, 0.8123781466527026), 'logkcat': (2.1384983107695614, 1.4614620354945693, 0.6239584705657739, 0.7905975676401539), 'logkcatkm': (3.340195164864026, 2.286626385966787, 0.3737256713976046, 0.6247734115466826)} \n",
      " Test {'logkm': (1.7310584463606595, 1.2193880890682656, 0.6664827550958761, 0.8182079760967023), 'logkcat': (2.2089238260248627, 1.5113050789445013, 0.6219079877440892, 0.7889743980895771), 'logkcatkm': (3.257356863773217, 2.217314244783375, 0.3769410321024832, 0.6282632012373779)}\n",
      "\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_mean: 1.96832\n",
      "[2000]\tvalid_0's rmse_mean: 1.93795\n",
      "[3000]\tvalid_0's rmse_mean: 1.93202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3271]\tvalid_0's rmse_mean: 1.9316\n",
      "valid_records min_index 3270\n",
      "[1000]\tvalid_0's rmse_mean: 1.96832\n",
      "[2000]\tvalid_0's rmse_mean: 1.93795\n",
      "[3000]\tvalid_0's rmse_mean: 1.93202\n",
      "inner_predict 14892\n",
      "inner_predict 18614\n",
      "Val  {'logkm': (1.759462550084374, 1.2274928026813554, 0.6635321922870644, 0.8159770531171651), 'logkcat': (2.1037282524241383, 1.4448921410529538, 0.6323439759560792, 0.7957959111942776), 'logkcatkm': (3.218370386925204, 2.2040438564995517, 0.4018259330658359, 0.6485198924708371)} \n",
      " Test {'logkm': (1.723831163393528, 1.2163443748967706, 0.6692618544035817, 0.819750454207391), 'logkcat': (2.214374793792807, 1.5106927036046054, 0.6200396478082253, 0.787871939131836), 'logkcatkm': (3.277629362907172, 2.208660761320697, 0.36916155446409804, 0.6230233788733042)}\n",
      "\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_mean: 1.97051\n",
      "[2000]\tvalid_0's rmse_mean: 1.94163\n",
      "[3000]\tvalid_0's rmse_mean: 1.93343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3272]\tvalid_0's rmse_mean: 1.93261\n",
      "valid_records min_index 3271\n",
      "[1000]\tvalid_0's rmse_mean: 1.97051\n",
      "[2000]\tvalid_0's rmse_mean: 1.94163\n",
      "[3000]\tvalid_0's rmse_mean: 1.93343\n",
      "inner_predict 14890\n",
      "inner_predict 18614\n",
      "Val  {'logkm': (1.7171850878090644, 1.2199560356748342, 0.6633390450414876, 0.8155211049522865), 'logkcat': (2.148025534610894, 1.4766962470634182, 0.6265304759731701, 0.7927539949280252), 'logkcatkm': (3.3764412312187764, 2.235840676371972, 0.32510255311530534, 0.5949617820346087)} \n",
      " Test {'logkm': (1.7362689784721974, 1.2265956355436969, 0.6644719417306191, 0.8168393698447964), 'logkcat': (2.176384264959935, 1.4953571299350583, 0.6329652554321168, 0.7958839944029913), 'logkcatkm': (3.272181720726594, 2.2030716522234677, 0.37125680431001884, 0.6249345108653455)}\n",
      "\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_mean: 1.92721\n",
      "[2000]\tvalid_0's rmse_mean: 1.90044\n",
      "[3000]\tvalid_0's rmse_mean: 1.89385\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3261]\tvalid_0's rmse_mean: 1.89316\n",
      "valid_records min_index 3260\n",
      "[1000]\tvalid_0's rmse_mean: 1.92721\n",
      "[2000]\tvalid_0's rmse_mean: 1.90044\n",
      "[3000]\tvalid_0's rmse_mean: 1.89385\n",
      "inner_predict 14890\n",
      "inner_predict 18614\n",
      "Val  {'logkm': (1.717601884985828, 1.2139602734211905, 0.6682258349098293, 0.8186145819012539), 'logkcat': (2.0687136802122565, 1.4409664318826094, 0.6381127656785445, 0.7999492719249742), 'logkcatkm': (3.3722467324098298, 2.261901677455481, 0.32725498329403, 0.5960735932606188)} \n",
      " Test {'logkm': (1.725614152812949, 1.2218087036807248, 0.6685773238106678, 0.8194476499652328), 'logkcat': (2.1879098012320344, 1.5078462917707622, 0.6290675306481079, 0.7935641989773691), 'logkcatkm': (3.270697511447047, 2.214367502451802, 0.37182705066299815, 0.6251911909011382)}\n",
      "\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\tvalid_0's rmse_mean: 1.96166\n",
      "[2000]\tvalid_0's rmse_mean: 1.93387\n",
      "[3000]\tvalid_0's rmse_mean: 1.92798\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3270]\tvalid_0's rmse_mean: 1.92746\n",
      "valid_records min_index 3269\n",
      "[1000]\tvalid_0's rmse_mean: 1.96166\n",
      "[2000]\tvalid_0's rmse_mean: 1.93387\n",
      "[3000]\tvalid_0's rmse_mean: 1.92797\n",
      "inner_predict 14890\n",
      "inner_predict 18614\n",
      "Val  {'logkm': (1.7279939643141478, 1.2183898044670902, 0.6592364767660941, 0.8150373547129858), 'logkcat': (2.1269133500976682, 1.4664498430000803, 0.6441021827498583, 0.8039903133392398), 'logkcatkm': (3.347621625462378, 2.277320215086273, 0.35622898405997006, 0.6252812934181813)} \n",
      " Test {'logkm': (1.7228740133218818, 1.220211998819865, 0.6696290343925353, 0.8201413989506856), 'logkcat': (2.1881428954047912, 1.5010113684087234, 0.628988490092806, 0.7933927363245352), 'logkcatkm': (3.284715585020318, 2.2245020558705573, 0.36643086518167745, 0.6225030486501788)}\n",
      "\n",
      "logkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  1.7320\t 1.2200\t 0.6621\t 0.8155\t\n",
      "Test 1.7279\t 1.2209\t 0.6677\t 0.8189\t\n",
      "\n",
      "logkcat\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  2.1172\t 1.4581\t 0.6330\t 0.7966\t\n",
      "Test 2.1951\t 1.5052\t 0.6266\t 0.7919\t\n",
      "\n",
      "logkcatkm\t RMSE\t MAE\t R2\t PCC\t\n",
      "Val  3.3310\t 2.2531\t 0.3568\t 0.6179\t\n",
      "Test 3.2725\t 2.2136\t 0.3711\t 0.6248\t\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynoMTGBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db0e6cebfd42dbe7de32cf1b0daf517db5c30eda4a99fad3eb7c5d8b4a7bde0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
